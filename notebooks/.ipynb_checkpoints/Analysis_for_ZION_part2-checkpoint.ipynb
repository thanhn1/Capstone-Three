{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae577fa",
   "metadata": {},
   "source": [
    "# Analysis_for_ZION_part1\n",
    "- We will do .....\n",
    "- Then we will do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14774b2",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "## Step4: Preprocessing\n",
    "4.1) Import necessary packages  \n",
    "4.2) Load data from hard disk \n",
    "4.3) Prepare train and test sets\n",
    "4.4) Explore different models\n",
    "\n",
    "## Step5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c1ac5",
   "metadata": {},
   "source": [
    "# Step4: Preprocessing\n",
    "Ignore 4.4) (we just do some exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e16408",
   "metadata": {},
   "source": [
    "## 4.1) Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e10f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from sklearn.linear_model import (LinearRegression, Ridge)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,  r2_score, mean_absolute_error\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d88f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (GridSearchCV, cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f57289bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5717bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6812080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "69ce5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "56304cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fb17985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a17bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cf80dfd",
   "metadata": {},
   "source": [
    "## 4.2) Load data from hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37af5c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data back after restart computer.\n",
    "zion_1 = pd.read_csv('../data/zion_1.csv',\n",
    "                 header=0,\n",
    "                 parse_dates=['Date'],\n",
    "                 index_col=0,\n",
    "                 infer_datetime_format= True)\n",
    "# Now we will have index as DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a15644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>...</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>1d_future_month</th>\n",
       "      <th>1d_future_month_sin</th>\n",
       "      <th>1d_future_month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>59.03</td>\n",
       "      <td>59.12</td>\n",
       "      <td>53.44</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1199600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.614284</td>\n",
       "      <td>46.685355</td>\n",
       "      <td>42.200023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>54.63</td>\n",
       "      <td>55.00</td>\n",
       "      <td>52.50</td>\n",
       "      <td>52.81</td>\n",
       "      <td>816100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.139731</td>\n",
       "      <td>43.431910</td>\n",
       "      <td>41.457732</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>52.75</td>\n",
       "      <td>53.25</td>\n",
       "      <td>51.06</td>\n",
       "      <td>53.06</td>\n",
       "      <td>1124700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.655150</td>\n",
       "      <td>42.049985</td>\n",
       "      <td>40.320606</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>52.75</td>\n",
       "      <td>54.94</td>\n",
       "      <td>52.38</td>\n",
       "      <td>53.50</td>\n",
       "      <td>1112100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.655150</td>\n",
       "      <td>43.384529</td>\n",
       "      <td>41.362971</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>53.75</td>\n",
       "      <td>54.25</td>\n",
       "      <td>53.31</td>\n",
       "      <td>53.63</td>\n",
       "      <td>782000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.444821</td>\n",
       "      <td>42.839656</td>\n",
       "      <td>42.097366</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close     Volume  Ex-Dividend  Split Ratio  \\\n",
       "Date                                                                          \n",
       "2000-01-03  59.03  59.12  53.44  55.50  1199600.0          0.0          1.0   \n",
       "2000-01-04  54.63  55.00  52.50  52.81   816100.0          0.0          1.0   \n",
       "2000-01-05  52.75  53.25  51.06  53.06  1124700.0          0.0          1.0   \n",
       "2000-01-06  52.75  54.94  52.38  53.50  1112100.0          0.0          1.0   \n",
       "2000-01-07  53.75  54.25  53.31  53.63   782000.0          0.0          1.0   \n",
       "\n",
       "            Adj. Open  Adj. High   Adj. Low  ...  log_rtn_lag_11  \\\n",
       "Date                                         ...                   \n",
       "2000-01-03  46.614284  46.685355  42.200023  ...             NaN   \n",
       "2000-01-04  43.139731  43.431910  41.457732  ...             NaN   \n",
       "2000-01-05  41.655150  42.049985  40.320606  ...             NaN   \n",
       "2000-01-06  41.655150  43.384529  41.362971  ...             NaN   \n",
       "2000-01-07  42.444821  42.839656  42.097366  ...             NaN   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  month  month_sin  \\\n",
       "Date                                                                           \n",
       "2000-01-03             NaN             NaN             NaN      1        0.5   \n",
       "2000-01-04             NaN             NaN             NaN      1        0.5   \n",
       "2000-01-05             NaN             NaN             NaN      1        0.5   \n",
       "2000-01-06             NaN             NaN             NaN      1        0.5   \n",
       "2000-01-07             NaN             NaN             NaN      1        0.5   \n",
       "\n",
       "            month_cos  1d_future_month  1d_future_month_sin  \\\n",
       "Date                                                          \n",
       "2000-01-03   0.866025              1.0                  0.5   \n",
       "2000-01-04   0.866025              1.0                  0.5   \n",
       "2000-01-05   0.866025              1.0                  0.5   \n",
       "2000-01-06   0.866025              1.0                  0.5   \n",
       "2000-01-07   0.866025              1.0                  0.5   \n",
       "\n",
       "            1d_future_month_cos  \n",
       "Date                             \n",
       "2000-01-03             0.866025  \n",
       "2000-01-04             0.866025  \n",
       "2000-01-05             0.866025  \n",
       "2000-01-06             0.866025  \n",
       "2000-01-07             0.866025  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zion_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1446dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>...</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>1d_future_month</th>\n",
       "      <th>1d_future_month_sin</th>\n",
       "      <th>1d_future_month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>54.94</td>\n",
       "      <td>55.78</td>\n",
       "      <td>54.39</td>\n",
       "      <td>55.10</td>\n",
       "      <td>1992966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.94</td>\n",
       "      <td>55.78</td>\n",
       "      <td>54.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>-0.010791</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>54.53</td>\n",
       "      <td>54.70</td>\n",
       "      <td>52.97</td>\n",
       "      <td>53.07</td>\n",
       "      <td>2578239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.53</td>\n",
       "      <td>54.70</td>\n",
       "      <td>52.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>53.22</td>\n",
       "      <td>53.55</td>\n",
       "      <td>51.17</td>\n",
       "      <td>51.23</td>\n",
       "      <td>3378671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.22</td>\n",
       "      <td>53.55</td>\n",
       "      <td>51.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014687</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>52.20</td>\n",
       "      <td>53.41</td>\n",
       "      <td>51.90</td>\n",
       "      <td>53.24</td>\n",
       "      <td>2357767.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.20</td>\n",
       "      <td>53.41</td>\n",
       "      <td>51.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.014687</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>53.25</td>\n",
       "      <td>53.71</td>\n",
       "      <td>51.62</td>\n",
       "      <td>52.02</td>\n",
       "      <td>2214940.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.25</td>\n",
       "      <td>53.71</td>\n",
       "      <td>51.62</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008097</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.014687</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close     Volume  Ex-Dividend  Split Ratio  \\\n",
       "Date                                                                          \n",
       "2018-03-21  54.94  55.78  54.39  55.10  1992966.0          0.0          1.0   \n",
       "2018-03-22  54.53  54.70  52.97  53.07  2578239.0          0.0          1.0   \n",
       "2018-03-23  53.22  53.55  51.17  51.23  3378671.0          0.0          1.0   \n",
       "2018-03-26  52.20  53.41  51.90  53.24  2357767.0          0.0          1.0   \n",
       "2018-03-27  53.25  53.71  51.62  52.02  2214940.0          0.0          1.0   \n",
       "\n",
       "            Adj. Open  Adj. High  Adj. Low  ...  log_rtn_lag_11  \\\n",
       "Date                                        ...                   \n",
       "2018-03-21      54.94      55.78     54.39  ...        0.014789   \n",
       "2018-03-22      54.53      54.70     52.97  ...        0.006874   \n",
       "2018-03-23      53.22      53.55     51.17  ...       -0.014687   \n",
       "2018-03-26      52.20      53.41     51.90  ...        0.016617   \n",
       "2018-03-27      53.25      53.71     51.62  ...       -0.008097   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  month  month_sin  \\\n",
       "Date                                                                           \n",
       "2018-03-21        0.016287        0.007876       -0.010791      3        1.0   \n",
       "2018-03-22        0.014789        0.016287        0.007876      3        1.0   \n",
       "2018-03-23        0.006874        0.014789        0.016287      3        1.0   \n",
       "2018-03-26       -0.014687        0.006874        0.014789      3        1.0   \n",
       "2018-03-27        0.016617       -0.014687        0.006874      3        1.0   \n",
       "\n",
       "               month_cos  1d_future_month  1d_future_month_sin  \\\n",
       "Date                                                             \n",
       "2018-03-21  6.123234e-17              3.0                  1.0   \n",
       "2018-03-22  6.123234e-17              3.0                  1.0   \n",
       "2018-03-23  6.123234e-17              3.0                  1.0   \n",
       "2018-03-26  6.123234e-17              3.0                  1.0   \n",
       "2018-03-27  6.123234e-17              NaN                  NaN   \n",
       "\n",
       "            1d_future_month_cos  \n",
       "Date                             \n",
       "2018-03-21         6.123234e-17  \n",
       "2018-03-22         6.123234e-17  \n",
       "2018-03-23         6.123234e-17  \n",
       "2018-03-26         6.123234e-17  \n",
       "2018-03-27                  NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zion_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf229dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4586 entries, 2000-01-03 to 2018-03-27\n",
      "Data columns (total 43 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Open                 4586 non-null   float64\n",
      " 1   High                 4586 non-null   float64\n",
      " 2   Low                  4586 non-null   float64\n",
      " 3   Close                4586 non-null   float64\n",
      " 4   Volume               4586 non-null   float64\n",
      " 5   Ex-Dividend          4586 non-null   float64\n",
      " 6   Split Ratio          4586 non-null   float64\n",
      " 7   Adj. Open            4586 non-null   float64\n",
      " 8   Adj. High            4586 non-null   float64\n",
      " 9   Adj. Low             4586 non-null   float64\n",
      " 10  Adj. Close           4586 non-null   float64\n",
      " 11  Adj. Volume          4586 non-null   float64\n",
      " 12  log_rtn              4585 non-null   float64\n",
      " 13  ma14                 4573 non-null   float64\n",
      " 14  rsi14                4572 non-null   float64\n",
      " 15  ma50                 4537 non-null   float64\n",
      " 16  rsi50                4536 non-null   float64\n",
      " 17  ma200                4387 non-null   float64\n",
      " 18  rsi200               4386 non-null   float64\n",
      " 19  vol_1d_change        4585 non-null   float64\n",
      " 20  vol_1d_change_ma10   4576 non-null   float64\n",
      " 21  1d_future_log_rtn    4585 non-null   float64\n",
      " 22  log_rtn_lag_0        4585 non-null   float64\n",
      " 23  log_rtn_lag_1        4584 non-null   float64\n",
      " 24  log_rtn_lag_2        4583 non-null   float64\n",
      " 25  log_rtn_lag_3        4582 non-null   float64\n",
      " 26  log_rtn_lag_4        4581 non-null   float64\n",
      " 27  log_rtn_lag_5        4580 non-null   float64\n",
      " 28  log_rtn_lag_6        4579 non-null   float64\n",
      " 29  log_rtn_lag_7        4578 non-null   float64\n",
      " 30  log_rtn_lag_8        4577 non-null   float64\n",
      " 31  log_rtn_lag_9        4576 non-null   float64\n",
      " 32  log_rtn_lag_10       4575 non-null   float64\n",
      " 33  log_rtn_lag_11       4574 non-null   float64\n",
      " 34  log_rtn_lag_12       4573 non-null   float64\n",
      " 35  log_rtn_lag_13       4572 non-null   float64\n",
      " 36  log_rtn_lag_14       4571 non-null   float64\n",
      " 37  month                4586 non-null   int64  \n",
      " 38  month_sin            4586 non-null   float64\n",
      " 39  month_cos            4586 non-null   float64\n",
      " 40  1d_future_month      4585 non-null   float64\n",
      " 41  1d_future_month_sin  4585 non-null   float64\n",
      " 42  1d_future_month_cos  4585 non-null   float64\n",
      "dtypes: float64(42), int64(1)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "zion_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e3e99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-03', '2000-01-04', '2000-01-05', '2000-01-06',\n",
       "               '2000-01-07', '2000-01-10', '2000-01-11', '2000-01-12',\n",
       "               '2000-01-13', '2000-01-14',\n",
       "               ...\n",
       "               '2018-03-14', '2018-03-15', '2018-03-16', '2018-03-19',\n",
       "               '2018-03-20', '2018-03-21', '2018-03-22', '2018-03-23',\n",
       "               '2018-03-26', '2018-03-27'],\n",
       "              dtype='datetime64[ns]', name='Date', length=4586, freq=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zion_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9717f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>4.247692e+01</td>\n",
       "      <td>2.022398e+01</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>25.012500</td>\n",
       "      <td>4.150000e+01</td>\n",
       "      <td>5.693750e+01</td>\n",
       "      <td>8.827000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>4.301802e+01</td>\n",
       "      <td>2.031932e+01</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>25.422500</td>\n",
       "      <td>4.235500e+01</td>\n",
       "      <td>5.749500e+01</td>\n",
       "      <td>1.075900e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>4.191482e+01</td>\n",
       "      <td>2.014377e+01</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>24.617500</td>\n",
       "      <td>4.075500e+01</td>\n",
       "      <td>5.631000e+01</td>\n",
       "      <td>8.781000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>4.247297e+01</td>\n",
       "      <td>2.023162e+01</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>25.150000</td>\n",
       "      <td>4.155000e+01</td>\n",
       "      <td>5.698000e+01</td>\n",
       "      <td>8.828000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>2.218395e+06</td>\n",
       "      <td>2.280179e+06</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>544300.000000</td>\n",
       "      <td>1.655200e+06</td>\n",
       "      <td>3.035258e+06</td>\n",
       "      <td>2.633310e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>2.673354e-03</td>\n",
       "      <td>2.823574e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.300000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split Ratio</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. Open</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>3.815980e+01</td>\n",
       "      <td>1.705589e+01</td>\n",
       "      <td>6.109201</td>\n",
       "      <td>24.296965</td>\n",
       "      <td>3.555373e+01</td>\n",
       "      <td>4.822746e+01</td>\n",
       "      <td>7.958553e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. High</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>3.865011e+01</td>\n",
       "      <td>1.712845e+01</td>\n",
       "      <td>7.095483</td>\n",
       "      <td>24.743015</td>\n",
       "      <td>3.619438e+01</td>\n",
       "      <td>4.864645e+01</td>\n",
       "      <td>1.019509e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. Low</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>3.765131e+01</td>\n",
       "      <td>1.700249e+01</td>\n",
       "      <td>5.649575</td>\n",
       "      <td>23.827051</td>\n",
       "      <td>3.489470e+01</td>\n",
       "      <td>4.759229e+01</td>\n",
       "      <td>7.917079e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. Close</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>3.815598e+01</td>\n",
       "      <td>1.706162e+01</td>\n",
       "      <td>6.204957</td>\n",
       "      <td>24.358327</td>\n",
       "      <td>3.557194e+01</td>\n",
       "      <td>4.826088e+01</td>\n",
       "      <td>7.959455e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj. Volume</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>2.218395e+06</td>\n",
       "      <td>2.280179e+06</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>544300.000000</td>\n",
       "      <td>1.655200e+06</td>\n",
       "      <td>3.035258e+06</td>\n",
       "      <td>2.633310e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>3.737928e-05</td>\n",
       "      <td>2.885841e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010401</td>\n",
       "      <td>3.173092e-04</td>\n",
       "      <td>1.072281e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma14</th>\n",
       "      <td>4573.0</td>\n",
       "      <td>3.812831e+01</td>\n",
       "      <td>1.703354e+01</td>\n",
       "      <td>8.149478</td>\n",
       "      <td>24.419873</td>\n",
       "      <td>3.538644e+01</td>\n",
       "      <td>4.795399e+01</td>\n",
       "      <td>7.807983e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsi14</th>\n",
       "      <td>4572.0</td>\n",
       "      <td>5.161658e+01</td>\n",
       "      <td>1.156511e+01</td>\n",
       "      <td>11.324146</td>\n",
       "      <td>43.923947</td>\n",
       "      <td>5.177880e+01</td>\n",
       "      <td>5.943308e+01</td>\n",
       "      <td>8.428460e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma50</th>\n",
       "      <td>4537.0</td>\n",
       "      <td>3.804394e+01</td>\n",
       "      <td>1.697258e+01</td>\n",
       "      <td>9.863775</td>\n",
       "      <td>24.488731</td>\n",
       "      <td>3.535208e+01</td>\n",
       "      <td>4.764580e+01</td>\n",
       "      <td>7.688606e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsi50</th>\n",
       "      <td>4536.0</td>\n",
       "      <td>5.131127e+01</td>\n",
       "      <td>6.077448e+00</td>\n",
       "      <td>29.641715</td>\n",
       "      <td>47.461911</td>\n",
       "      <td>5.115370e+01</td>\n",
       "      <td>5.548847e+01</td>\n",
       "      <td>7.261493e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma200</th>\n",
       "      <td>4387.0</td>\n",
       "      <td>3.789058e+01</td>\n",
       "      <td>1.678506e+01</td>\n",
       "      <td>13.173341</td>\n",
       "      <td>24.037097</td>\n",
       "      <td>3.662084e+01</td>\n",
       "      <td>4.784450e+01</td>\n",
       "      <td>7.366689e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsi200</th>\n",
       "      <td>4386.0</td>\n",
       "      <td>5.077637e+01</td>\n",
       "      <td>3.151615e+00</td>\n",
       "      <td>40.518763</td>\n",
       "      <td>48.900527</td>\n",
       "      <td>5.087816e+01</td>\n",
       "      <td>5.319070e+01</td>\n",
       "      <td>5.902838e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_1d_change</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>1.337486e-04</td>\n",
       "      <td>4.512622e-01</td>\n",
       "      <td>-2.630975</td>\n",
       "      <td>-0.283487</td>\n",
       "      <td>-1.128560e-02</td>\n",
       "      <td>2.703758e-01</td>\n",
       "      <td>3.516017e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <td>4576.0</td>\n",
       "      <td>2.510353e-04</td>\n",
       "      <td>6.183082e-02</td>\n",
       "      <td>-0.416370</td>\n",
       "      <td>-0.038191</td>\n",
       "      <td>-1.861794e-03</td>\n",
       "      <td>3.880488e-02</td>\n",
       "      <td>3.749396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d_future_log_rtn</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>3.737928e-05</td>\n",
       "      <td>2.885841e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010401</td>\n",
       "      <td>3.173092e-04</td>\n",
       "      <td>1.072281e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>3.737928e-05</td>\n",
       "      <td>2.885841e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010401</td>\n",
       "      <td>3.173092e-04</td>\n",
       "      <td>1.072281e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <td>4584.0</td>\n",
       "      <td>4.244453e-05</td>\n",
       "      <td>2.885952e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>3.199710e-04</td>\n",
       "      <td>1.072519e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <td>4583.0</td>\n",
       "      <td>3.405652e-05</td>\n",
       "      <td>2.885708e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>3.173092e-04</td>\n",
       "      <td>1.071056e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <td>4582.0</td>\n",
       "      <td>4.176507e-05</td>\n",
       "      <td>2.885551e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010374</td>\n",
       "      <td>3.199710e-04</td>\n",
       "      <td>1.071669e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <td>4581.0</td>\n",
       "      <td>4.996845e-05</td>\n",
       "      <td>2.885331e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010365</td>\n",
       "      <td>3.226327e-04</td>\n",
       "      <td>1.072281e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <td>4580.0</td>\n",
       "      <td>4.878732e-05</td>\n",
       "      <td>2.885635e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010368</td>\n",
       "      <td>3.199710e-04</td>\n",
       "      <td>1.072519e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <td>4579.0</td>\n",
       "      <td>4.955385e-05</td>\n",
       "      <td>2.885946e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010371</td>\n",
       "      <td>3.226327e-04</td>\n",
       "      <td>1.072757e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <td>4578.0</td>\n",
       "      <td>5.165991e-05</td>\n",
       "      <td>2.886226e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010374</td>\n",
       "      <td>3.244751e-04</td>\n",
       "      <td>1.072994e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <td>4577.0</td>\n",
       "      <td>4.861986e-05</td>\n",
       "      <td>2.886468e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010377</td>\n",
       "      <td>3.226327e-04</td>\n",
       "      <td>1.072281e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <td>4576.0</td>\n",
       "      <td>4.875020e-05</td>\n",
       "      <td>2.886783e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>3.244751e-04</td>\n",
       "      <td>1.072519e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <td>4575.0</td>\n",
       "      <td>5.259741e-05</td>\n",
       "      <td>2.886981e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010371</td>\n",
       "      <td>3.263175e-04</td>\n",
       "      <td>1.072757e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <td>4574.0</td>\n",
       "      <td>5.583982e-05</td>\n",
       "      <td>2.887214e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010362</td>\n",
       "      <td>3.285847e-04</td>\n",
       "      <td>1.072994e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <td>4573.0</td>\n",
       "      <td>5.762268e-05</td>\n",
       "      <td>2.887504e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010365</td>\n",
       "      <td>3.308519e-04</td>\n",
       "      <td>1.073232e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <td>4572.0</td>\n",
       "      <td>5.400078e-05</td>\n",
       "      <td>2.887716e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010368</td>\n",
       "      <td>3.285847e-04</td>\n",
       "      <td>1.072519e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "      <td>4571.0</td>\n",
       "      <td>5.722559e-05</td>\n",
       "      <td>2.887950e-02</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>-0.010360</td>\n",
       "      <td>3.308519e-04</td>\n",
       "      <td>1.072757e-02</td>\n",
       "      <td>2.433917e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>6.483428e+00</td>\n",
       "      <td>3.444314e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_sin</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>1.673016e-03</td>\n",
       "      <td>7.088761e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_cos</th>\n",
       "      <td>4586.0</td>\n",
       "      <td>-3.989147e-03</td>\n",
       "      <td>7.054743e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d_future_month</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>6.484624e+00</td>\n",
       "      <td>3.443738e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d_future_month_sin</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>1.564329e-03</td>\n",
       "      <td>7.089152e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d_future_month_cos</th>\n",
       "      <td>4585.0</td>\n",
       "      <td>-4.178899e-03</td>\n",
       "      <td>7.054342e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count          mean           std           min  \\\n",
       "Open                 4586.0  4.247692e+01  2.022398e+01      6.380000   \n",
       "High                 4586.0  4.301802e+01  2.031932e+01      7.410000   \n",
       "Low                  4586.0  4.191482e+01  2.014377e+01      5.900000   \n",
       "Close                4586.0  4.247297e+01  2.023162e+01      6.480000   \n",
       "Volume               4586.0  2.218395e+06  2.280179e+06  66000.000000   \n",
       "Ex-Dividend          4586.0  2.673354e-03  2.823574e-02      0.000000   \n",
       "Split Ratio          4586.0  1.000000e+00  0.000000e+00      1.000000   \n",
       "Adj. Open            4586.0  3.815980e+01  1.705589e+01      6.109201   \n",
       "Adj. High            4586.0  3.865011e+01  1.712845e+01      7.095483   \n",
       "Adj. Low             4586.0  3.765131e+01  1.700249e+01      5.649575   \n",
       "Adj. Close           4586.0  3.815598e+01  1.706162e+01      6.204957   \n",
       "Adj. Volume          4586.0  2.218395e+06  2.280179e+06  66000.000000   \n",
       "log_rtn              4585.0  3.737928e-05  2.885841e-02     -0.281738   \n",
       "ma14                 4573.0  3.812831e+01  1.703354e+01      8.149478   \n",
       "rsi14                4572.0  5.161658e+01  1.156511e+01     11.324146   \n",
       "ma50                 4537.0  3.804394e+01  1.697258e+01      9.863775   \n",
       "rsi50                4536.0  5.131127e+01  6.077448e+00     29.641715   \n",
       "ma200                4387.0  3.789058e+01  1.678506e+01     13.173341   \n",
       "rsi200               4386.0  5.077637e+01  3.151615e+00     40.518763   \n",
       "vol_1d_change        4585.0  1.337486e-04  4.512622e-01     -2.630975   \n",
       "vol_1d_change_ma10   4576.0  2.510353e-04  6.183082e-02     -0.416370   \n",
       "1d_future_log_rtn    4585.0  3.737928e-05  2.885841e-02     -0.281738   \n",
       "log_rtn_lag_0        4585.0  3.737928e-05  2.885841e-02     -0.281738   \n",
       "log_rtn_lag_1        4584.0  4.244453e-05  2.885952e-02     -0.281738   \n",
       "log_rtn_lag_2        4583.0  3.405652e-05  2.885708e-02     -0.281738   \n",
       "log_rtn_lag_3        4582.0  4.176507e-05  2.885551e-02     -0.281738   \n",
       "log_rtn_lag_4        4581.0  4.996845e-05  2.885331e-02     -0.281738   \n",
       "log_rtn_lag_5        4580.0  4.878732e-05  2.885635e-02     -0.281738   \n",
       "log_rtn_lag_6        4579.0  4.955385e-05  2.885946e-02     -0.281738   \n",
       "log_rtn_lag_7        4578.0  5.165991e-05  2.886226e-02     -0.281738   \n",
       "log_rtn_lag_8        4577.0  4.861986e-05  2.886468e-02     -0.281738   \n",
       "log_rtn_lag_9        4576.0  4.875020e-05  2.886783e-02     -0.281738   \n",
       "log_rtn_lag_10       4575.0  5.259741e-05  2.886981e-02     -0.281738   \n",
       "log_rtn_lag_11       4574.0  5.583982e-05  2.887214e-02     -0.281738   \n",
       "log_rtn_lag_12       4573.0  5.762268e-05  2.887504e-02     -0.281738   \n",
       "log_rtn_lag_13       4572.0  5.400078e-05  2.887716e-02     -0.281738   \n",
       "log_rtn_lag_14       4571.0  5.722559e-05  2.887950e-02     -0.281738   \n",
       "month                4586.0  6.483428e+00  3.444314e+00      1.000000   \n",
       "month_sin            4586.0  1.673016e-03  7.088761e-01     -1.000000   \n",
       "month_cos            4586.0 -3.989147e-03  7.054743e-01     -1.000000   \n",
       "1d_future_month      4585.0  6.484624e+00  3.443738e+00      1.000000   \n",
       "1d_future_month_sin  4585.0  1.564329e-03  7.089152e-01     -1.000000   \n",
       "1d_future_month_cos  4585.0 -4.178899e-03  7.054342e-01     -1.000000   \n",
       "\n",
       "                               25%           50%           75%           max  \n",
       "Open                     25.012500  4.150000e+01  5.693750e+01  8.827000e+01  \n",
       "High                     25.422500  4.235500e+01  5.749500e+01  1.075900e+02  \n",
       "Low                      24.617500  4.075500e+01  5.631000e+01  8.781000e+01  \n",
       "Close                    25.150000  4.155000e+01  5.698000e+01  8.828000e+01  \n",
       "Volume               544300.000000  1.655200e+06  3.035258e+06  2.633310e+07  \n",
       "Ex-Dividend               0.000000  0.000000e+00  0.000000e+00  4.300000e-01  \n",
       "Split Ratio               1.000000  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "Adj. Open                24.296965  3.555373e+01  4.822746e+01  7.958553e+01  \n",
       "Adj. High                24.743015  3.619438e+01  4.864645e+01  1.019509e+02  \n",
       "Adj. Low                 23.827051  3.489470e+01  4.759229e+01  7.917079e+01  \n",
       "Adj. Close               24.358327  3.557194e+01  4.826088e+01  7.959455e+01  \n",
       "Adj. Volume          544300.000000  1.655200e+06  3.035258e+06  2.633310e+07  \n",
       "log_rtn                  -0.010401  3.173092e-04  1.072281e-02  2.433917e-01  \n",
       "ma14                     24.419873  3.538644e+01  4.795399e+01  7.807983e+01  \n",
       "rsi14                    43.923947  5.177880e+01  5.943308e+01  8.428460e+01  \n",
       "ma50                     24.488731  3.535208e+01  4.764580e+01  7.688606e+01  \n",
       "rsi50                    47.461911  5.115370e+01  5.548847e+01  7.261493e+01  \n",
       "ma200                    24.037097  3.662084e+01  4.784450e+01  7.366689e+01  \n",
       "rsi200                   48.900527  5.087816e+01  5.319070e+01  5.902838e+01  \n",
       "vol_1d_change            -0.283487 -1.128560e-02  2.703758e-01  3.516017e+00  \n",
       "vol_1d_change_ma10       -0.038191 -1.861794e-03  3.880488e-02  3.749396e-01  \n",
       "1d_future_log_rtn        -0.010401  3.173092e-04  1.072281e-02  2.433917e-01  \n",
       "log_rtn_lag_0            -0.010401  3.173092e-04  1.072281e-02  2.433917e-01  \n",
       "log_rtn_lag_1            -0.010383  3.199710e-04  1.072519e-02  2.433917e-01  \n",
       "log_rtn_lag_2            -0.010389  3.173092e-04  1.071056e-02  2.433917e-01  \n",
       "log_rtn_lag_3            -0.010374  3.199710e-04  1.071669e-02  2.433917e-01  \n",
       "log_rtn_lag_4            -0.010365  3.226327e-04  1.072281e-02  2.433917e-01  \n",
       "log_rtn_lag_5            -0.010368  3.199710e-04  1.072519e-02  2.433917e-01  \n",
       "log_rtn_lag_6            -0.010371  3.226327e-04  1.072757e-02  2.433917e-01  \n",
       "log_rtn_lag_7            -0.010374  3.244751e-04  1.072994e-02  2.433917e-01  \n",
       "log_rtn_lag_8            -0.010377  3.226327e-04  1.072281e-02  2.433917e-01  \n",
       "log_rtn_lag_9            -0.010383  3.244751e-04  1.072519e-02  2.433917e-01  \n",
       "log_rtn_lag_10           -0.010371  3.263175e-04  1.072757e-02  2.433917e-01  \n",
       "log_rtn_lag_11           -0.010362  3.285847e-04  1.072994e-02  2.433917e-01  \n",
       "log_rtn_lag_12           -0.010365  3.308519e-04  1.073232e-02  2.433917e-01  \n",
       "log_rtn_lag_13           -0.010368  3.285847e-04  1.072519e-02  2.433917e-01  \n",
       "log_rtn_lag_14           -0.010360  3.308519e-04  1.072757e-02  2.433917e-01  \n",
       "month                     3.000000  6.000000e+00  9.000000e+00  1.200000e+01  \n",
       "month_sin                -0.866025  1.224647e-16  8.660254e-01  1.000000e+00  \n",
       "month_cos                -0.500000  6.123234e-17  5.000000e-01  1.000000e+00  \n",
       "1d_future_month           3.000000  6.000000e+00  9.000000e+00  1.200000e+01  \n",
       "1d_future_month_sin      -0.866025  1.224647e-16  8.660254e-01  1.000000e+00  \n",
       "1d_future_month_cos      -0.500000  6.123234e-17  5.000000e-01  1.000000e+00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zion_1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f76e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d0e77e7",
   "metadata": {},
   "source": [
    "## 4.3) Prepare train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "914e313f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Ex-Dividend', 'Split Ratio',\n",
       "       'Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume',\n",
       "       'log_rtn', 'ma14', 'rsi14', 'ma50', 'rsi50', 'ma200', 'rsi200',\n",
       "       'vol_1d_change', 'vol_1d_change_ma10', '1d_future_log_rtn',\n",
       "       'log_rtn_lag_0', 'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3',\n",
       "       'log_rtn_lag_4', 'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7',\n",
       "       'log_rtn_lag_8', 'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11',\n",
       "       'log_rtn_lag_12', 'log_rtn_lag_13', 'log_rtn_lag_14', 'month',\n",
       "       'month_sin', 'month_cos', '1d_future_month', '1d_future_month_sin',\n",
       "       '1d_future_month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zion_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "706d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10',\n",
    "       'log_rtn_lag_0', 'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3',\n",
    "       'log_rtn_lag_4', 'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7',\n",
    "       'log_rtn_lag_8', 'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11',\n",
    "       'log_rtn_lag_12', 'log_rtn_lag_13', 'log_rtn_lag_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5114a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 19) (1508,)\n"
     ]
    }
   ],
   "source": [
    "# Take X_train and y_train \n",
    "X_train = zion_1.loc[\"2012\":\"2017\", col_list].copy()\n",
    "y_train = zion_1.loc[\"2012\":\"2017\", '1d_future_log_rtn'].copy()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b34c573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 19) (25,)\n"
     ]
    }
   ],
   "source": [
    "# Take X_test and y_test \n",
    "X_test = zion_1.loc[\"2018-01-02\":\"2018-02-06\", col_list].copy()\n",
    "y_test = zion_1.loc[\"2018-01-02\":\"2018-02-06\", '1d_future_log_rtn'].copy()\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8e4720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-01-03', '2012-01-04', '2012-01-05', '2012-01-06',\n",
       "               '2012-01-09', '2012-01-10', '2012-01-11', '2012-01-12',\n",
       "               '2012-01-13', '2012-01-17',\n",
       "               ...\n",
       "               '2017-12-15', '2017-12-18', '2017-12-19', '2017-12-20',\n",
       "               '2017-12-21', '2017-12-22', '2017-12-26', '2017-12-27',\n",
       "               '2017-12-28', '2017-12-29'],\n",
       "              dtype='datetime64[ns]', name='Date', length=1508, freq=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0df6573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma50</th>\n",
       "      <th>rsi50</th>\n",
       "      <th>vol_1d_change</th>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>15.644056</td>\n",
       "      <td>49.585339</td>\n",
       "      <td>1.133309</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "      <td>-0.013866</td>\n",
       "      <td>-0.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>15.647345</td>\n",
       "      <td>50.466020</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "      <td>-0.013866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>15.640614</td>\n",
       "      <td>51.570992</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>15.658562</td>\n",
       "      <td>51.616880</td>\n",
       "      <td>-0.505657</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>15.677284</td>\n",
       "      <td>52.171810</td>\n",
       "      <td>-0.365039</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ma50      rsi50  vol_1d_change  vol_1d_change_ma10  \\\n",
       "Date                                                                  \n",
       "2012-01-03  15.644056  49.585339       1.133309           -0.057175   \n",
       "2012-01-04  15.647345  50.466020       0.010460            0.011020   \n",
       "2012-01-05  15.640614  51.570992       0.355847            0.030275   \n",
       "2012-01-06  15.658562  51.616880      -0.505657            0.026015   \n",
       "2012-01-09  15.677284  52.171810      -0.365039           -0.016649   \n",
       "\n",
       "            log_rtn_lag_0  log_rtn_lag_1  log_rtn_lag_2  log_rtn_lag_3  \\\n",
       "Date                                                                     \n",
       "2012-01-03       0.029356      -0.012210       0.023950      -0.019083   \n",
       "2012-01-04       0.022122       0.029356      -0.012210       0.023950   \n",
       "2012-01-05       0.027620       0.022122       0.029356      -0.012210   \n",
       "2012-01-06       0.001134       0.027620       0.022122       0.029356   \n",
       "2012-01-09       0.013514       0.001134       0.027620       0.022122   \n",
       "\n",
       "            log_rtn_lag_4  log_rtn_lag_5  log_rtn_lag_6  log_rtn_lag_7  \\\n",
       "Date                                                                     \n",
       "2012-01-03       0.004277       0.011084       0.034008       0.016796   \n",
       "2012-01-04      -0.019083       0.004277       0.011084       0.034008   \n",
       "2012-01-05       0.023950      -0.019083       0.004277       0.011084   \n",
       "2012-01-06      -0.012210       0.023950      -0.019083       0.004277   \n",
       "2012-01-09       0.029356      -0.012210       0.023950      -0.019083   \n",
       "\n",
       "            log_rtn_lag_8  log_rtn_lag_9  log_rtn_lag_10  log_rtn_lag_11  \\\n",
       "Date                                                                       \n",
       "2012-01-03       0.048041      -0.029632        0.010674        0.002014   \n",
       "2012-01-04       0.016796       0.048041       -0.029632        0.010674   \n",
       "2012-01-05       0.034008       0.016796        0.048041       -0.029632   \n",
       "2012-01-06       0.011084       0.034008        0.016796        0.048041   \n",
       "2012-01-09       0.004277       0.011084        0.034008        0.016796   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  \n",
       "Date                                                        \n",
       "2012-01-03       -0.010695       -0.013866       -0.016261  \n",
       "2012-01-04        0.002014       -0.010695       -0.013866  \n",
       "2012-01-05        0.010674        0.002014       -0.010695  \n",
       "2012-01-06       -0.029632        0.010674        0.002014  \n",
       "2012-01-09        0.048041       -0.029632        0.010674  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e199c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2012-01-03    0.022122\n",
       "2012-01-04    0.027620\n",
       "2012-01-05    0.001134\n",
       "2012-01-06    0.013514\n",
       "2012-01-09    0.016089\n",
       "Name: 1d_future_log_rtn, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b92cc4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma50</th>\n",
       "      <th>rsi50</th>\n",
       "      <th>vol_1d_change</th>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>47.8018</td>\n",
       "      <td>58.808517</td>\n",
       "      <td>-0.590183</td>\n",
       "      <td>-0.065383</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "      <td>-0.016761</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>47.8846</td>\n",
       "      <td>57.757435</td>\n",
       "      <td>-0.059625</td>\n",
       "      <td>-0.080472</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "      <td>-0.016761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>47.9668</td>\n",
       "      <td>57.423200</td>\n",
       "      <td>-0.178461</td>\n",
       "      <td>-0.128118</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>48.0578</td>\n",
       "      <td>58.453586</td>\n",
       "      <td>0.274878</td>\n",
       "      <td>-0.088947</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>48.1546</td>\n",
       "      <td>57.307954</td>\n",
       "      <td>0.349522</td>\n",
       "      <td>-0.078281</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ma50      rsi50  vol_1d_change  vol_1d_change_ma10  \\\n",
       "Date                                                                \n",
       "2017-12-22  47.8018  58.808517      -0.590183           -0.065383   \n",
       "2017-12-26  47.8846  57.757435      -0.059625           -0.080472   \n",
       "2017-12-27  47.9668  57.423200      -0.178461           -0.128118   \n",
       "2017-12-28  48.0578  58.453586       0.274878           -0.088947   \n",
       "2017-12-29  48.1546  57.307954       0.349522           -0.078281   \n",
       "\n",
       "            log_rtn_lag_0  log_rtn_lag_1  log_rtn_lag_2  log_rtn_lag_3  \\\n",
       "Date                                                                     \n",
       "2017-12-22      -0.002529       0.014287      -0.003149      -0.001767   \n",
       "2017-12-26      -0.009199      -0.002529       0.014287      -0.003149   \n",
       "2017-12-27      -0.002954      -0.009199      -0.002529       0.014287   \n",
       "2017-12-28       0.012347      -0.002954      -0.009199      -0.002529   \n",
       "2017-12-29      -0.009983       0.012347      -0.002954      -0.009199   \n",
       "\n",
       "            log_rtn_lag_4  log_rtn_lag_5  log_rtn_lag_6  log_rtn_lag_7  \\\n",
       "Date                                                                     \n",
       "2017-12-22       0.019210       0.015923      -0.010911      -0.013969   \n",
       "2017-12-26      -0.001767       0.019210       0.015923      -0.010911   \n",
       "2017-12-27      -0.003149      -0.001767       0.019210       0.015923   \n",
       "2017-12-28       0.014287      -0.003149      -0.001767       0.019210   \n",
       "2017-12-29      -0.002529       0.014287      -0.003149      -0.001767   \n",
       "\n",
       "            log_rtn_lag_8  log_rtn_lag_9  log_rtn_lag_10  log_rtn_lag_11  \\\n",
       "Date                                                                       \n",
       "2017-12-22       0.010359      -0.019630        0.009073        0.010957   \n",
       "2017-12-26      -0.013969       0.010359       -0.019630        0.009073   \n",
       "2017-12-27      -0.010911      -0.013969        0.010359       -0.019630   \n",
       "2017-12-28       0.015923      -0.010911       -0.013969        0.010359   \n",
       "2017-12-29       0.019210       0.015923       -0.010911       -0.013969   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  \n",
       "Date                                                        \n",
       "2017-12-22       -0.019048       -0.016761        0.032609  \n",
       "2017-12-26        0.010957       -0.019048       -0.016761  \n",
       "2017-12-27        0.009073        0.010957       -0.019048  \n",
       "2017-12-28       -0.019630        0.009073        0.010957  \n",
       "2017-12-29        0.010359       -0.019630        0.009073  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b573c3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-12-22   -0.009199\n",
       "2017-12-26   -0.002954\n",
       "2017-12-27    0.012347\n",
       "2017-12-28   -0.009983\n",
       "2017-12-29   -0.002561\n",
       "Name: 1d_future_log_rtn, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f55ada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma50</th>\n",
       "      <th>rsi50</th>\n",
       "      <th>vol_1d_change</th>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>48.2452</td>\n",
       "      <td>57.017292</td>\n",
       "      <td>0.605269</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>48.3370</td>\n",
       "      <td>56.881421</td>\n",
       "      <td>-0.382952</td>\n",
       "      <td>-0.039222</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>48.4188</td>\n",
       "      <td>57.245290</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.104065</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>48.5084</td>\n",
       "      <td>57.280324</td>\n",
       "      <td>-1.001134</td>\n",
       "      <td>-0.029827</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>48.5938</td>\n",
       "      <td>56.687832</td>\n",
       "      <td>0.325694</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ma50      rsi50  vol_1d_change  vol_1d_change_ma10  \\\n",
       "Date                                                                \n",
       "2018-01-02  48.2452  57.017292       0.605269           -0.043837   \n",
       "2018-01-03  48.3370  56.881421      -0.382952           -0.039222   \n",
       "2018-01-04  48.4188  57.245290       0.740234            0.104065   \n",
       "2018-01-05  48.5084  57.280324      -1.001134           -0.029827   \n",
       "2018-01-08  48.5938  56.687832       0.325694            0.008324   \n",
       "\n",
       "            log_rtn_lag_0  log_rtn_lag_1  log_rtn_lag_2  log_rtn_lag_3  \\\n",
       "Date                                                                     \n",
       "2018-01-02      -0.002561      -0.009983       0.012347      -0.002954   \n",
       "2018-01-03      -0.001184      -0.002561      -0.009983       0.012347   \n",
       "2018-01-04       0.004138      -0.001184      -0.002561      -0.009983   \n",
       "2018-01-05       0.000393       0.004138      -0.001184      -0.002561   \n",
       "2018-01-08      -0.004927       0.000393       0.004138      -0.001184   \n",
       "\n",
       "            log_rtn_lag_4  log_rtn_lag_5  log_rtn_lag_6  log_rtn_lag_7  \\\n",
       "Date                                                                     \n",
       "2018-01-02      -0.009199      -0.002529       0.014287      -0.003149   \n",
       "2018-01-03      -0.002954      -0.009199      -0.002529       0.014287   \n",
       "2018-01-04       0.012347      -0.002954      -0.009199      -0.002529   \n",
       "2018-01-05      -0.009983       0.012347      -0.002954      -0.009199   \n",
       "2018-01-08      -0.002561      -0.009983       0.012347      -0.002954   \n",
       "\n",
       "            log_rtn_lag_8  log_rtn_lag_9  log_rtn_lag_10  log_rtn_lag_11  \\\n",
       "Date                                                                       \n",
       "2018-01-02      -0.001767       0.019210        0.015923       -0.010911   \n",
       "2018-01-03      -0.003149      -0.001767        0.019210        0.015923   \n",
       "2018-01-04       0.014287      -0.003149       -0.001767        0.019210   \n",
       "2018-01-05      -0.002529       0.014287       -0.003149       -0.001767   \n",
       "2018-01-08      -0.009199      -0.002529        0.014287       -0.003149   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  \n",
       "Date                                                        \n",
       "2018-01-02       -0.013969        0.010359       -0.019630  \n",
       "2018-01-03       -0.010911       -0.013969        0.010359  \n",
       "2018-01-04        0.015923       -0.010911       -0.013969  \n",
       "2018-01-05        0.019210        0.015923       -0.010911  \n",
       "2018-01-08       -0.001767        0.019210        0.015923  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5221e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2018-01-02   -0.001184\n",
       "2018-01-03    0.004138\n",
       "2018-01-04    0.000393\n",
       "2018-01-05   -0.004927\n",
       "2018-01-08    0.023236\n",
       "Name: 1d_future_log_rtn, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a1253",
   "metadata": {},
   "source": [
    "## 4.4) Explore different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff81c5",
   "metadata": {},
   "source": [
    "#### Linear regression on all train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "166325f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "643136a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005202155358766751 [-3.41042454e-05 -6.59846393e-05  1.10395716e-03 -7.71772506e-04\n",
      "  4.73253053e-02 -2.08821795e-02  1.92429694e-02 -3.26714229e-02\n",
      " -1.09981828e-02 -1.07806726e-02  1.08630030e-02 -1.26853020e-02\n",
      "  9.15146902e-03  2.97111003e-02  1.23541506e-02 -3.17341306e-02\n",
      "  1.17902692e-02  1.93523577e-02 -2.16391730e-02] 0.009227874109663303\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edfd1f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>ma50</th>\n",
       "      <th>rsi50</th>\n",
       "      <th>vol_1d_change</th>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.644056</td>\n",
       "      <td>49.585339</td>\n",
       "      <td>1.133309</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "      <td>-0.013866</td>\n",
       "      <td>-0.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.647345</td>\n",
       "      <td>50.466020</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "      <td>-0.013866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.640614</td>\n",
       "      <td>51.570992</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.010695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.658562</td>\n",
       "      <td>51.616880</td>\n",
       "      <td>-0.505657</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.677284</td>\n",
       "      <td>52.171810</td>\n",
       "      <td>-0.365039</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.027620</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>-0.029632</td>\n",
       "      <td>0.010674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            const       ma50      rsi50  vol_1d_change  vol_1d_change_ma10  \\\n",
       "Date                                                                         \n",
       "2012-01-03    1.0  15.644056  49.585339       1.133309           -0.057175   \n",
       "2012-01-04    1.0  15.647345  50.466020       0.010460            0.011020   \n",
       "2012-01-05    1.0  15.640614  51.570992       0.355847            0.030275   \n",
       "2012-01-06    1.0  15.658562  51.616880      -0.505657            0.026015   \n",
       "2012-01-09    1.0  15.677284  52.171810      -0.365039           -0.016649   \n",
       "\n",
       "            log_rtn_lag_0  log_rtn_lag_1  log_rtn_lag_2  log_rtn_lag_3  \\\n",
       "Date                                                                     \n",
       "2012-01-03       0.029356      -0.012210       0.023950      -0.019083   \n",
       "2012-01-04       0.022122       0.029356      -0.012210       0.023950   \n",
       "2012-01-05       0.027620       0.022122       0.029356      -0.012210   \n",
       "2012-01-06       0.001134       0.027620       0.022122       0.029356   \n",
       "2012-01-09       0.013514       0.001134       0.027620       0.022122   \n",
       "\n",
       "            log_rtn_lag_4  log_rtn_lag_5  log_rtn_lag_6  log_rtn_lag_7  \\\n",
       "Date                                                                     \n",
       "2012-01-03       0.004277       0.011084       0.034008       0.016796   \n",
       "2012-01-04      -0.019083       0.004277       0.011084       0.034008   \n",
       "2012-01-05       0.023950      -0.019083       0.004277       0.011084   \n",
       "2012-01-06      -0.012210       0.023950      -0.019083       0.004277   \n",
       "2012-01-09       0.029356      -0.012210       0.023950      -0.019083   \n",
       "\n",
       "            log_rtn_lag_8  log_rtn_lag_9  log_rtn_lag_10  log_rtn_lag_11  \\\n",
       "Date                                                                       \n",
       "2012-01-03       0.048041      -0.029632        0.010674        0.002014   \n",
       "2012-01-04       0.016796       0.048041       -0.029632        0.010674   \n",
       "2012-01-05       0.034008       0.016796        0.048041       -0.029632   \n",
       "2012-01-06       0.011084       0.034008        0.016796        0.048041   \n",
       "2012-01-09       0.004277       0.011084        0.034008        0.016796   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  \n",
       "Date                                                        \n",
       "2012-01-03       -0.010695       -0.013866       -0.016261  \n",
       "2012-01-04        0.002014       -0.010695       -0.013866  \n",
       "2012-01-05        0.010674        0.002014       -0.010695  \n",
       "2012-01-06       -0.029632        0.010674        0.002014  \n",
       "2012-01-09        0.048041       -0.029632        0.010674  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression with Statsmodels\n",
    "linear_X_train = sm.add_constant(X_train)\n",
    "linear_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef16a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, linear_X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a077dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      1d_future_log_rtn   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.7294\n",
      "Date:                Fri, 10 Mar 2023   Prob (F-statistic):              0.791\n",
      "Time:                        09:51:39   Log-Likelihood:                 4025.3\n",
      "No. Observations:                1508   AIC:                            -8011.\n",
      "Df Residuals:                    1488   BIC:                            -7904.\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.0052      0.005      0.994      0.320      -0.005       0.015\n",
      "ma50                -3.41e-05   5.88e-05     -0.580      0.562      -0.000    8.12e-05\n",
      "rsi50              -6.598e-05      0.000     -0.636      0.525      -0.000       0.000\n",
      "vol_1d_change          0.0011      0.001      0.979      0.328      -0.001       0.003\n",
      "vol_1d_change_ma10    -0.0008      0.008     -0.095      0.924      -0.017       0.015\n",
      "log_rtn_lag_0          0.0473      0.027      1.759      0.079      -0.005       0.100\n",
      "log_rtn_lag_1         -0.0209      0.027     -0.778      0.437      -0.074       0.032\n",
      "log_rtn_lag_2          0.0192      0.027      0.717      0.474      -0.033       0.072\n",
      "log_rtn_lag_3         -0.0327      0.027     -1.224      0.221      -0.085       0.020\n",
      "log_rtn_lag_4         -0.0110      0.027     -0.412      0.681      -0.063       0.041\n",
      "log_rtn_lag_5         -0.0108      0.027     -0.404      0.686      -0.063       0.042\n",
      "log_rtn_lag_6          0.0109      0.027      0.408      0.683      -0.041       0.063\n",
      "log_rtn_lag_7         -0.0127      0.027     -0.478      0.633      -0.065       0.039\n",
      "log_rtn_lag_8          0.0092      0.026      0.346      0.729      -0.043       0.061\n",
      "log_rtn_lag_9          0.0297      0.026      1.124      0.261      -0.022       0.082\n",
      "log_rtn_lag_10         0.0124      0.026      0.469      0.639      -0.039       0.064\n",
      "log_rtn_lag_11        -0.0317      0.026     -1.209      0.227      -0.083       0.020\n",
      "log_rtn_lag_12         0.0118      0.026      0.449      0.654      -0.040       0.063\n",
      "log_rtn_lag_13         0.0194      0.026      0.738      0.461      -0.032       0.071\n",
      "log_rtn_lag_14        -0.0216      0.026     -0.824      0.410      -0.073       0.030\n",
      "==============================================================================\n",
      "Omnibus:                      138.615   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              591.183\n",
      "Skew:                          -0.338   Prob(JB):                    4.23e-129\n",
      "Kurtosis:                       5.992   Cond. No.                     4.93e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.93e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce477c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84331ef1",
   "metadata": {},
   "source": [
    "#### Ridge regression on all train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d433a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression\n",
    "model = Ridge() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d762e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004863206379965456 [-3.62497203e-05 -5.81688916e-05  1.14942022e-03 -9.59784122e-04\n",
      "  1.36349787e-02 -6.08119531e-03  5.17037669e-03 -9.42726764e-03\n",
      " -4.75417906e-03 -3.41007270e-03  2.84595587e-03 -3.42922648e-03\n",
      "  2.48079306e-03  9.43970432e-03  3.90862869e-03 -9.60658534e-03\n",
      "  3.13050081e-03  5.61116982e-03 -7.02831253e-03] 0.00546435415678459\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db86a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score -0.042872384586940315\n"
     ]
    }
   ],
   "source": [
    "print('test score', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b4772d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.00546435415678459\n",
      "Train mean_squared_error          : 0.00028227053574506153\n",
      "Train roof of mean_squared_error  : 0.016800908777356703\n",
      "Train mean_absolute_error         : 0.01245732688285812\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = model.predict(X_train)\n",
    "print('Train r-square                    :', r2_score(y_train, y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train, y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83407ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.042872384586940315\n",
      "Test mean_squared_error          : 0.00021473871497203559\n",
      "Test roof of mean_squared_error  : 0.014653965844508973\n",
      "Test mean_absolute_error         : 0.011215445904034966\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = model.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6552536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9fada16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy predictor of 0% return (random walk)\n",
    "y_dummy = pd.DataFrame(np.zeros((len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66c9e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy r-square                    : -0.03126142926896236\n",
      "Dummy mean_squared_error          : 0.00021234789356240752\n",
      "Dummy roof of mean_squared_error  : 0.014572161595398519\n",
      "Dummy mean_absolute_error         : 0.011004664925178065\n"
     ]
    }
   ],
   "source": [
    "# Dummy performance \n",
    "print('Dummy r-square                    :', r2_score(y_test, y_dummy))\n",
    "print('Dummy mean_squared_error          :', mean_squared_error(y_test, y_dummy))\n",
    "print('Dummy roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_dummy)))\n",
    "print('Dummy mean_absolute_error         :', mean_absolute_error(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797cb33",
   "metadata": {},
   "source": [
    "#### Ridge regression on all train set with month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acf8ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month sine and cosine to feature list\n",
    "col_list = ['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10',\n",
    "       'log_rtn_lag_0', 'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3',\n",
    "       'log_rtn_lag_4', 'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7',\n",
    "       'log_rtn_lag_8', 'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11',\n",
    "       'log_rtn_lag_12', 'log_rtn_lag_13', 'log_rtn_lag_14', '1d_future_month_sin', '1d_future_month_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dca4b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 21)\n"
     ]
    }
   ],
   "source": [
    "# Take new X_train\n",
    "X_train = zion_1.loc[\"2012\":\"2017\", col_list].copy()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c64a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 21)\n"
     ]
    }
   ],
   "source": [
    "# Take new X_test\n",
    "X_test = zion_1.loc[\"2018-01-02\":\"2018-02-06\", col_list].copy()\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f986a370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression\n",
    "model = Ridge() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37001435",
   "metadata": {},
   "source": [
    "We could create a function to output all performance measures.\n",
    "https://stackoverflow.com/questions/26319259/how-to-get-a-regression-summary-in-scikit-learn-like-r-does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b1108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9f95cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.005468001922650068\n",
      "Train mean_squared_error          : 0.0002822695004309132\n",
      "Train roof of mean_squared_error  : 0.01680087796607407\n",
      "Train mean_absolute_error         : 0.012457477642674492\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = model.predict(X_train)\n",
    "print('Train r-square                    :', r2_score(y_train, y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train, y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e5ad563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.041751168532686345\n",
      "Test mean_squared_error          : 0.00021450784444726674\n",
      "Test roof of mean_squared_error  : 0.014646086318442436\n",
      "Test mean_absolute_error         : 0.011207994397116332\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = model.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fddb2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy predictor of 0% return (random walk)\n",
    "y_dummy = pd.DataFrame(np.zeros((len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "536bbc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy r-square                    : -0.03126142926896236\n",
      "Dummy mean_squared_error          : 0.00021234789356240752\n",
      "Dummy roof of mean_squared_error  : 0.014572161595398519\n",
      "Dummy mean_absolute_error         : 0.011004664925178065\n"
     ]
    }
   ],
   "source": [
    "# Dummy performance \n",
    "print('Dummy r-square                    :', r2_score(y_test, y_dummy))\n",
    "print('Dummy mean_squared_error          :', mean_squared_error(y_test, y_dummy))\n",
    "print('Dummy roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_dummy)))\n",
    "print('Dummy mean_absolute_error         :', mean_absolute_error(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2daa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a309f7b0",
   "metadata": {},
   "source": [
    "#### GridSearchCV and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52b7926b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ----\n",
      "Train indices: [ 123  124  125 ... 1380 1381 1382]\n",
      "Valid indices: [1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396\n",
      " 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407]\n",
      "Fold 1 ----\n",
      "Train indices: [ 148  149  150 ... 1405 1406 1407]\n",
      "Valid indices: [1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421\n",
      " 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432]\n",
      "Fold 2 ----\n",
      "Train indices: [ 173  174  175 ... 1430 1431 1432]\n",
      "Valid indices: [1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446\n",
      " 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457]\n",
      "Fold 3 ----\n",
      "Train indices: [ 198  199  200 ... 1455 1456 1457]\n",
      "Valid indices: [1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471\n",
      " 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482]\n",
      "Fold 4 ----\n",
      "Train indices: [ 223  224  225 ... 1480 1481 1482]\n",
      "Valid indices: [1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507]\n"
     ]
    }
   ],
   "source": [
    "# Code modified from book \"Python for Finance\"\n",
    "# Define the sliding window validation and print the indices of the folds\n",
    "sliding_cv = TimeSeriesSplit(n_splits=5, test_size=25, max_train_size=1260)\n",
    "\n",
    "for fold, (main_ind, valid_ind) in enumerate(sliding_cv.split(X_train)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Train indices: {main_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb2639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bd93fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores_mse: [8.4728790025538e-05, 0.0002333160609526264, 0.00011322703187937467, 0.00019861465419386507, 0.00024248859108109652]\n",
      "Avg. score_mse: 0.00017447502562650013\n",
      "Scores_r2: [-0.024746058781176306, -0.029313425117613257, -0.13418995960939584, -0.0023647783830367253, -0.048414500206315214]\n",
      "Avg. score_r2: -0.04780574441950747\n"
     ]
    }
   ],
   "source": [
    "# Write your own loop for cross-validataion\n",
    "scores_mse = [] \n",
    "scores_r2 = []\n",
    "\n",
    "for main_ind, valid_ind in sliding_cv.split(X_train):\n",
    "    model = Ridge()\n",
    "    model.fit(X_train.iloc[main_ind], y_train.iloc[main_ind])\n",
    "    y_valid_pred = model.predict(X_train.iloc[valid_ind])\n",
    "    scores_mse.append(mean_squared_error(y_train.iloc[valid_ind], y_valid_pred))\n",
    "    scores_r2.append(r2_score(y_train.iloc[valid_ind], y_valid_pred))\n",
    "print(f\"Scores_mse: {scores_mse}\")\n",
    "print(f\"Avg. score_mse: {np.mean(scores_mse)}\")\n",
    "print(f\"Scores_r2: {scores_r2}\")\n",
    "print(f\"Avg. score_r2: {np.mean(scores_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84299b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.024746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.029313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.134190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.048415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error   test_r2\n",
       "0  0.002992    0.000997                    -0.000085 -0.024746\n",
       "1  0.001995    0.000998                    -0.000233 -0.029313\n",
       "2  0.000998    0.000997                    -0.000113 -0.134190\n",
       "3  0.000997    0.000998                    -0.000199 -0.002365\n",
       "4  0.001994    0.000997                    -0.000242 -0.048415"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_validate() for cross-validation:\n",
    "cv_scores = cross_validate(\n",
    "    Ridge(), \n",
    "    X_train, y_train, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_squared_error\", \n",
    "             \"r2\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205a2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0a6b5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034655</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.021302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.044550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.128727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.012946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.023222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error   test_r2\n",
       "0  0.034655    0.015622                    -0.000084 -0.021302\n",
       "1  0.001997    0.000997                    -0.000237 -0.044550\n",
       "2  0.001995    0.000997                    -0.000113 -0.128727\n",
       "3  0.000997    0.000997                    -0.000201 -0.012946\n",
       "4  0.001995    0.000997                    -0.000237 -0.023222"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "sliding_cv = TimeSeriesSplit(n_splits=5, test_size=25, max_train_size=756)\n",
    "\n",
    "# Using cross_validate() for cross-validation:\n",
    "cv_scores = cross_validate(\n",
    "    Ridge(), \n",
    "    X_train, y_train, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_squared_error\", \n",
    "             \"r2\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca50c824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04614938791627217"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "pd.DataFrame(cv_scores)['test_r2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "851e5661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0001742537013882123"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "pd.DataFrame(cv_scores)['test_neg_mean_squared_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a963f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5c3d0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.44440017e-05, -2.36769801e-04, -1.12681708e-04, -2.00711194e-04,\n",
       "       -2.36661803e-04])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "# Use cross_val_score(). This one can take only one scoring. \n",
    "cross_val_score(Ridge(), X_train, y_train, cv=sliding_cv, scoring=\"neg_mean_squared_error\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a68d43c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02130171, -0.04455019, -0.12872747, -0.01294555, -0.02322202])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "# Use cross_val_score(). This one can take only one scoring.\n",
    "cross_val_score(Ridge(), X_train, y_train, cv=sliding_cv, scoring=\"r2\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367c4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93f572be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.237808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-0.021302</td>\n",
       "      <td>-0.04455</td>\n",
       "      <td>-0.128727</td>\n",
       "      <td>-0.012946</td>\n",
       "      <td>-0.023222</td>\n",
       "      <td>-0.046149</td>\n",
       "      <td>0.042585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.237808           0.0              0.0             0.0           1   \n",
       "\n",
       "         params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 1}          -0.021302           -0.04455          -0.128727   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.012946          -0.023222        -0.046149        0.042585   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using only three year for training\n",
    "# GridSearchCV with default hyperparameters\n",
    "param = {'alpha': [1]}\n",
    "\n",
    "gs = GridSearchCV(Ridge(), param, cv=sliding_cv, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Yes, the numbers are close to original cross-validation that I had above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daf854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591d8d93",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dad1ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create timeseries of returns\n",
    "ts = zion_1.loc[\"2012\":\"2017\", \"log_rtn\"].copy\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a1d72ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2012-01-03    0.029356\n",
       "2012-01-04    0.022122\n",
       "2012-01-05    0.027620\n",
       "2012-01-06    0.001134\n",
       "2012-01-09    0.013514\n",
       "Name: log_rtn, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66a6da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                log_rtn   No. Observations:                 1508\n",
      "Model:                 ARIMA(1, 0, 1)   Log Likelihood                4019.153\n",
      "Date:                Fri, 10 Mar 2023   AIC                          -8030.307\n",
      "Time:                        21:46:48   BIC                          -8009.033\n",
      "Sample:                             0   HQIC                         -8022.383\n",
      "                               - 1508                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0008      0.000      1.727      0.084      -0.000       0.002\n",
      "ar.L1         -0.6185      0.291     -2.128      0.033      -1.188      -0.049\n",
      "ma.L1          0.6575      0.282      2.331      0.020       0.105       1.210\n",
      "sigma2         0.0003   6.63e-06     42.734      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.02   Jarque-Bera (JB):               586.86\n",
      "Prob(Q):                              0.90   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.11   Skew:                            -0.31\n",
      "Prob(H) (two-sided):                  0.26   Kurtosis:                         5.99\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "model = ARIMA(ts, order=(1,0,1))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1090845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# Out-of-sample forecast\n",
    "forecast = results.get_forecast(steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd4397a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast.predicted_mean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4ff25e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.resid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f24a0477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHFCAYAAADMqpylAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAADXEklEQVR4nOydd3hUxdeA391NsumNEJJASEJHem8CAaSDKKAoKKBUARUQEdCfFFGqiB9SLCA2igVQ6UgTJPQqHSSEkhAIpJCQZMt8fyxZsslusqmbMu/z3CfZuXPnnju3nXvOmTMKIYRAIpFIJBKJRFIoKG0tgEQikUgkEklpQipfEolEIpFIJIWIVL4kEolEIpFIChGpfEkkEolEIpEUIlL5kkgkEolEIilEpPIlkUgkEolEUohI5UsikUgkEomkEJHKl0QikUgkEkkhIpUviUQikUgkkkJEKl8WOHToEM8//zwVK1ZErVZTrlw5WrRowTvvvGNSb8mSJaxcudI2Qj5m2rRpKBSKQtlXeHg4CoXC5JgLc//pCQ0NJTQ0tND3a46VK1eiUCgIDw/Ptm5hyJ0TedauXUutWrVwcnJCoVBw8uTJApNrz549RrnSrqU9e/YY15u7lkJDQxk8eDAAgwcPzlPfpfXL0aNHza7v0aMHwcHBJmXBwcHG/VvLgQMHmDZtGrGxsbkTtBSSm34uSqxatYqFCxeaXadQKJg2bVqhypNGQb6j8nJcac+C9Pe/LTD3TiuM+1cqX2bYtGkTLVu2JD4+nrlz57J9+3Y+//xzWrVqxdq1a03qFgXly9YMHTqUsLAwW4thU7p3705YWBj+/v62FiVH3L17l1dffZXKlSuzdetWwsLCqFatmq3FKlKsX7+e//3vfzna5sCBA0yfPl0qX6WIrJSvsLAwhg4dWrgCPUa+o7LG39+fsLAwunfvbiwrjPvXrsBaLsbMnTuXkJAQtm3bhp3dky566aWXmDt3rg0lKxySkpJwdna2un6FChWoUKFCAUqUvwghSE5OxsnJKd/aLFu2LGXLls239gqLS5cuodFoeOWVV2jbtm2+tJnT66eo06BBA1uLkGM0Gg0KhcLk+SWxHc2bN7e1CBILqNVqm5wfafkyQ0xMDD4+PmYfXErlky4LDg7m7Nmz7N27F4VCgUKhMLoskpOTeeedd6hfvz4eHh54e3vTokULfv/990xtKhQKxowZww8//EDNmjVxdnamXr16bNy4MVPdTZs2Ub9+fdRqNSEhIcyfP9/sMSxevJg2bdrg6+uLi4sLderUYe7cuWg0GpN6oaGh1K5dm7///puWLVvi7OzM66+/DsDt27d58cUXcXNzw8PDg379+hEVFZVpXxldRWmuHXNLepeREIIlS5ZQv359nJyc8PLyom/fvvz3338m7QshmDt3LkFBQTg6OtKwYUO2bNli9rjNkda/y5Yto2bNmqjVar777jsALl++TP/+/fH19UWtVlOzZk0WL15ssr1er2fmzJlUr14dJycnPD09qVu3Lp9//nmmY07v5rNWbksuQnNm+R07dtCrVy8qVKiAo6MjVapUYcSIEdy7d8/q/khj8ODBPP300wD069cv0/n5448/aNGiBc7Ozri5udGxY8dMFs60c3/8+HH69u2Ll5cXlStXzrEsRZmM7rDsrodp06bx7rvvAhASEmK89tPOo16vZ+7cudSoUQO1Wo2vry8DBw7k5s2bJvsVQvDJJ58Yr5/GjRuzY8eOTG7rtOvkhx9+4J133qF8+fKo1WquXLnC3bt3GTVqFE899RSurq74+vrSvn179u3bZ7KvNNfLvHnzmDNnDsHBwTg5OREaGmpU0CdNmkRAQAAeHh48//zzREdHZ9t3gwcPxtXVlbNnz9KhQwdcXFwoW7YsY8aMISkpKcttc3JfnDhxgh49ehjv44CAALp3756pT83x119/0aFDB9zd3XF2dqZVq1bs3LnTpM7du3cZPnw4gYGBqNVqypYtS6tWrfjrr78Aw3N006ZNXL9+3eR5l0ZG91zase3atYthw4ZRpkwZ3N3dGThwIImJiURFRfHiiy/i6emJv78/EyZMyPTsnj59Os2aNcPb2xt3d3caNmzI8uXLEUIY62T1jgKIj49nwoQJhISE4ODgQPny5Rk7diyJiYkm+4qPjzfK6erqSpcuXbh06VK2fZvGhQsX6NKlC87Ozvj4+DBy5EgSEhJyfT7Snjtnz57l5ZdfxsPDg3LlyvH6668TFxdnUveXX36hWbNmeHh44OzsTKVKlYzvOMjsdszq/h0yZAje3t5mr9327dtTq1Ytq/tEfhaZoUWLFnzzzTe89dZbDBgwgIYNG2Jvb5+p3vr16+nbty8eHh4sWbIEMGjRACkpKdy/f58JEyZQvnx5UlNT+euvv+jduzfffvstAwcONGlr06ZNHDlyhBkzZuDq6srcuXN5/vnnuXjxIpUqVQJg586d9OrVixYtWrBmzRp0Oh1z587lzp07mWS7evUq/fv3N95Up06d4uOPP+bChQusWLHCpG5kZCSvvPIKEydO5JNPPkGpVPLo0SOeeeYZbt++zaxZs6hWrRqbNm2iX79+2fZfmgsuPWFhYYwfP97k4hwxYgQrV67krbfeYs6cOdy/f58ZM2bQsmVLTp06Rbly5QDDQ2b69OkMGTKEvn37cuPGDYYNG4ZOp6N69erZygOwYcMG9u3bx4cffoifnx++vr6cO3eOli1bUrFiRT799FP8/PzYtm0bb731Fvfu3WPq1KmAwRI6bdo0PvjgA9q0aYNGo+HChQvZmqTzQ+6MXL16lRYtWjB06FA8PDwIDw9nwYIFPP3005w5c8bsdWqJ//3vfzRt2pTRo0fzySef0K5dO9zd3QGDC2XAgAF06tSJ1atXk5KSwty5cwkNDWXnzp1GpS2N3r1789JLLzFy5MhMD+70hIaGmrwc0v9vifQv2fxyn+h0OrRabaZya+TJ7noYOnQo9+/fZ9GiRaxbt87oin7qqacAeOONN/jqq68YM2YMPXr0IDw8nP/973/s2bOH48eP4+PjA8D777/PrFmzGD58OL179+bGjRsMHToUjUZj1jU8efJkWrRowbJly1Aqlfj6+nL37l0Apk6dip+fHw8fPmT9+vXG85gxfm7x4sXUrVuXxYsXExsbyzvvvEPPnj1p1qwZ9vb2rFixguvXrzNhwgSGDh3KH3/8kW1/aTQaunXrxogRI5g0aRIHDhxg5syZXL9+nT///DPb7bMjMTGRjh07EhISwuLFiylXrhxRUVHs3r3b4gs+jR9//JGBAwfSq1cvvvvuO+zt7fnyyy/p3Lkz27Zto0OHDgC8+uqrHD9+nI8//phq1aoRGxvL8ePHiYmJAQyuveHDh3P16lXWr19vtexDhw6ld+/erFmzhhMnTjBlyhS0Wi0XL16kd+/eDB8+nL/++os5c+YQEBDA+PHjjduGh4czYsQIKlasCMDBgwd58803uXXrFh9++CGQ9TsqKSmJtm3bcvPmTaZMmULdunU5e/YsH374IWfOnOGvv/5CoVAghOC5557jwIEDfPjhhzRp0oR//vmHrl27WnWMd+7coW3bttjb27NkyRLKlSvHTz/9xJgxY3J9PtLo06cP/fr1Y8iQIZw5c4bJkycDGN9xYWFh9OvXj379+jFt2jQcHR25fv06u3btyvKcWLp/vb29WbFiBatWrTJxI587d47du3dn+nDPEiHJxL1798TTTz8tAAEIe3t70bJlSzFr1iyRkJBgUrdWrVqibdu22bap1WqFRqMRQ4YMEQ0aNDBZB4hy5cqJ+Ph4Y1lUVJRQKpVi1qxZxrJmzZqJgIAA8ejRI2NZfHy88Pb2FlmdSp1OJzQajfj++++FSqUS9+/fN65r27atAMTOnTtNtlm6dKkAxO+//25SPmzYMAGIb7/91lg2derULPd/4cIFUaZMGdGuXTuRkpIihBAiLCxMAOLTTz81qXvjxg3h5OQkJk6cKIQQ4sGDB8LR0VE8//zzJvX++ecfAVjV94Dw8PAwOW4hhOjcubOoUKGCiIuLMykfM2aMcHR0NNbv0aOHqF+/fpb7+PbbbwUgrl27lmO5M26bxu7duwUgdu/ebXafer1eaDQacf369UznylKbGUnbxy+//GIs0+l0IiAgQNSpU0fodDpjeUJCgvD19RUtW7Y0lqWd+w8//DDL/VhLdtdSXknrl6yWoKAgk22CgoLEoEGDjL+tuR7mzZtntv/Pnz8vADFq1CiT8kOHDglATJkyRQghxP3794VarRb9+vUzqZd236S/ftLOYZs2bbI9/rTnUIcOHUyuzWvXrglA1KtXz+ScL1y4UADi2WefNWln7NixAsh072Rk0KBBAhCff/65SfnHH38sALF//35jWcZ+tva+OHr0qADEhg0bsj3+9CQmJgpvb2/Rs2dPk3KdTifq1asnmjZtaixzdXUVY8eOzbK97t27Z7p20gDE1KlTjb/Tju3NN980qffcc88JQCxYsMCkvH79+qJhw4YW9532jJ8xY4YoU6aM0Ov1xnWW3lGzZs0SSqVSHDlyxKT8119/FYDYvHmzEEKILVu2ZHkO0x+XOd577z2hUCjEyZMnTco7duxoch5zcj7SnhNz5841qTtq1Cjh6OhoPP758+cLQMTGxlqUL+3aT/9Os3T/CmF4Z2a8/9944w3h7u6eST/ICul2NEOZMmXYt28fR44cYfbs2fTq1YtLly4xefJk6tSpY7WL55dffqFVq1a4urpiZ2eHvb09y5cv5/z585nqtmvXDjc3N+PvcuXK4evry/Xr1wHD192RI0fo3bs3jo6Oxnpubm707NkzU3snTpzg2WefpUyZMqhUKuzt7Rk4cCA6nS6TudjLy4v27dublO3evRs3NzeeffZZk/L+/ftbdexpREVF0aVLF/z9/Vm/fj0ODg4AbNy4EYVCwSuvvIJWqzUufn5+1KtXz2jtCAsLIzk5mQEDBpi027JlS4KCgqyWo3379nh5eRl/Jycns3PnTp5//nmcnZ1NZOjWrRvJyckcPHgQgKZNm3Lq1ClGjRrFtm3biI+Pz3Z/+SV3RqKjoxk5ciSBgYHGayqtPXPXVW64ePEit2/f5tVXXzVxs7u6utKnTx8OHjyYyezep0+ffNl3YfH9999z5MiRTEtGi545cnM9pLF7926ATKP6mjZtSs2aNY3ulYMHD5KSksKLL75oUq958+aZRmOmYekcLFu2jIYNG+Lo6Gi8Znbu3Gn2eunWrZvJOa9ZsyaASTBy+vKIiAgLR2pKxvsg7TmS1h95oUqVKnh5efHee++xbNkyzp07Z9V2Bw4c4P79+wwaNMjk/tfr9XTp0oUjR44YrbhNmzZl5cqVzJw5k4MHD2ZyAeaWHj16mPzOqr/T3gVp7Nq1i2eeeQYPDw/jM/7DDz8kJibGKpfwxo0bqV27NvXr1zc5/s6dO5u4ddPOkaVzmB27d++mVq1a1KtXL8vtc3I+0sj4fqpbty7JycnG42/SpAkAL774Ij///DO3bt2ySuasePvttzl58iT//PMPYHDJ/vDDDwwaNAhXV1er25HKVxY0btyY9957j19++YXbt28zbtw4wsPDrQq6X7duHS+++CLly5fnxx9/JCwsjCNHjvD666+TnJycqX6ZMmUylanVah49egTAgwcP0Ov1+Pn5ZaqXsSwiIoLWrVtz69YtPv/8c6MimWYSTWszDXMj9GJiYoxuv6z2lRUJCQl069YNjUbDli1b8PDwMK67c+cOQgjKlSuHvb29yXLw4EGjgptm1rfmuLMi4zHGxMSg1WpZtGhRpv1369YNwCjD5MmTmT9/PgcPHqRr166UKVOGDh06WExXkJ9yp0ev19OpUyfWrVvHxIkT2blzJ4cPHzYqiRnPa25Jk93cdREQEIBer+fBgwcm5cVtlGfNmjVp3LhxpiX9NWqJ3FwPaWTXt2nr0/6auwfNlVlqc8GCBbzxxhs0a9aM3377jYMHD3LkyBG6dOli9nrx9vY2+Z32sWSp3NyzLCN2dnaZnm9p90DaceYFDw8P9u7dS/369ZkyZQq1atUiICCAqVOnZqkkpYVr9O3bN9MzYM6cOQghuH//PmBIxzJo0CC++eYbWrRogbe3NwMHDjQbA5sTctLf6fv68OHDdOrUCYCvv/6af/75hyNHjvD+++8D1j0L7ty5w+nTpzMdu5ubG0IIk2dwVucwO2JiYqx6DubkfKSRUaY0l2ra8bdp04YNGzag1WoZOHAgFSpUoHbt2qxevdoq2c3Rq1cvgoODje/TlStXkpiYyOjRo3PUjoz5shJ7e3umTp3KZ599xr///ptt/R9//JGQkBDWrl1rEniZkpKSq/17eXmhUCjM3uwZyzZs2EBiYiLr1q0zsbJYyt9kLkdXmTJlOHz4cLb7soRGo6FPnz5cvXqVffv2ZRoN6ePjg0KhYN++fcYbJj1pZWk3l6XjtmQFyEjGY/Ty8kKlUvHqq69avGlCQkIAw8tj/PjxjB8/ntjYWP766y+mTJlC586duXHjhtmRfTmRO82SmfHayGhh/ffffzl16hQrV65k0KBBxvIrV65YOuxckSZ7ZGRkpnW3b99GqVSaWBHB/DVUUsnN9ZBG+r7NeE/cvn3bGO+VVs9cPKel697cOfjxxx8JDQ1l6dKlJuXZxULlJ1qtlpiYGJMXZdp9Ye6jMw1r7wuAOnXqsGbNGoQQnD59mpUrVzJjxgycnJyYNGmS2fbT+nrRokUWR7ulKbo+Pj4sXLiQhQsXEhERwR9//MGkSZOIjo5m69atFo+hoFizZg329vZs3LjRxBOyYcMGq9vw8fHByckpUwxw+vVgOEdZncPsKFOmjFXvrZycj5zQq1cvevXqRUpKCgcPHmTWrFn079+f4OBgWrRokeP2lEolo0ePZsqUKXz66acsWbKEDh065DiOV1q+zGDupQNP3DoBAQHGsvTWqfQoFAocHBxMHohRUVFmRztag4uLC02bNmXdunUmX0AJCQmZglbT9pleqRFC8PXXX1u9v3bt2pGQkJApoHbVqlVWbT9kyBD27NnDunXrqFu3bqb1PXr0QAjBrVu3zFog6tSpAxjcLI6Ojvz0008m2x84cCCTGT4nODs7065dO06cOEHdunXNymDuxeDp6Unfvn0ZPXo09+/ft5jENCdyp71IT58+bVKese/NnVeAL7/8MtvjzQnVq1enfPnyrFq1yiQAPTExkd9++804AlJi+XrI+AWeRpp7/8cffzQpP3LkCOfPnzcGFDdr1gy1Wp0pr+DBgwdzdN0rFIpM18vp06cLPS9fxvsg7TmSVcJca++L9CgUCurVq8dnn32Gp6cnx48ft1i3VatWeHp6cu7cObP3f+PGjY2WqPRUrFiRMWPG0LFjR5P2Lb0LCoK0NCIqlcpY9ujRI3744YdMdS3J1aNHD65evUqZMmXMHnta/7dr1w6wfA6zo127dpw9e5ZTp05luX1uz4e1qNVq2rZty5w5cwBDaE5WdcGyBXHo0KE4ODgwYMAALl68aHbwQHZIy5cZOnfuTIUKFejZsyc1atRAr9dz8uRJPv30U1xdXXn77beNddO+uNauXUulSpVwdHSkTp069OjRg3Xr1jFq1CjjSLePPvoIf39/Ll++nCu5PvroI7p06ULHjh1555130Ol0zJkzBxcXFxNzbMeOHXFwcODll19m4sSJJCcns3Tp0kyuoqwYOHAgn332GQMHDuTjjz+matWqbN68mW3btmW77bx58/jhhx948803cXFxMbrFANzd3Xnqqado1aoVw4cP57XXXuPo0aO0adMGFxcXIiMj2b9/P3Xq1OGNN97Ay8uLCRMmMHPmTIYOHcoLL7zAjRs3mDZtWq7dd2l8/vnnPP3007Ru3Zo33niD4OBgEhISuHLlCn/++adxREzPnj2pXbs2jRs3pmzZsly/fp2FCxcSFBRE1apVzbadE7mbNGlC9erVmTBhAlqtFi8vL9avX8/+/ftN6tWoUYPKlSszadIkhBB4e3vz559/smPHjjz1Q0aUSiVz585lwIAB9OjRgxEjRpCSksK8efOIjY1l9uzZ+bq/4oY110Pax8Pnn3/OoEGDsLe3p3r16lSvXp3hw4ezaNEilEolXbt2NY52DAwMZNy4cYDB7TR+/HhmzZqFl5cXzz//PDdv3mT69On4+/ubxGVlRY8ePfjoo4+YOnUqbdu25eLFi8yYMYOQkBCzoz0LAgcHBz799FMePnxIkyZNjKMdu3btmmWMnbX3xcaNG1myZAnPPfcclSpVQgjBunXriI2NpWPHjhbbd3V1ZdGiRQwaNIj79+/Tt29f4wjRU6dOcffuXZYuXUpcXBzt2rWjf//+1KhRAzc3N44cOcLWrVvp3bu3sb06deqwbt06li5dSqNGjVAqlTRu3DjvHWiG7t27s2DBAvr378/w4cOJiYlh/vz5Zr0Ilt5RY8eO5bfffqNNmzaMGzeOunXrotfriYiIYPv27bzzzjs0a9aMTp060aZNGyZOnEhiYiKNGzfmn3/+MavomWPs2LGsWLGC7t27M3PmTONoxwsXLpjUs/Z85IQPP/yQmzdv0qFDBypUqEBsbCyff/459vb2WeY1tHT/psVle3p6MnDgQJYuXUpQUJDZuOtssTo0vxSxdu1a0b9/f1G1alXh6uoq7O3tRcWKFcWrr74qzp07Z1I3PDxcdOrUSbi5uWUaKTV79mwRHBws1Gq1qFmzpvj666/NjuYCxOjRozPJkXH0jxBC/PHHH6Ju3brCwcFBVKxYUcyePdtsm3/++aeoV6+ecHR0FOXLlxfvvvuucdRK+tFzbdu2FbVq1TLbDzdv3hR9+vQRrq6uws3NTfTp00ccOHAg29GOaSOczC0ZR92sWLFCNGvWTLi4uAgnJydRuXJlMXDgQHH06FFjHb1eL2bNmiUCAwOFg4ODqFu3rvjzzz9F27ZtrR7taK5/hTCMdHn99ddF+fLlhb29vShbtqxo2bKlmDlzprHOp59+Klq2bCl8fHyM/T5kyBARHh5urGNuZFZO5L506ZLo1KmTcHd3F2XLlhVvvvmm2LRpU6bzde7cOdGxY0fh5uYmvLy8xAsvvCAiIiIsjqbKzWjHNDZs2CCaNWsmHB0dhYuLi+jQoYP4559/TOqknfu7d+9muR9rKazRjhlHeKVhbsRaxvvQmutBCCEmT54sAgIChFKpNDmPOp1OzJkzR1SrVk3Y29sLHx8f8corr4gbN26YbK/X68XMmTNFhQoVjNfPxo0bRb169UxGKmZ1DlNSUsSECRNE+fLlhaOjo2jYsKHYsGGDGDRokMlxpo34mjdvnsn2ltrOrh/TGDRokHBxcRGnT58WoaGhwsnJSXh7e4s33nhDPHz4MMt+FsK6++LChQvi5ZdfFpUrVxZOTk7Cw8NDNG3aVKxcuTJL2dLYu3ev6N69u/D29hb29vaifPnyonv37sZjTk5OFiNHjhR169YV7u7uwsnJSVSvXl1MnTpVJCYmGtu5f/++6Nu3r/D09BQKhcLkOrZ0f2bsP0v3U1o/pmfFihWievXqQq1Wi0qVKolZs2aJ5cuXZ7rvs3pHPXz4UHzwwQeievXqwsHBQXh4eIg6deqIcePGiaioKGO92NhY8frrrwtPT0/h7OwsOnbsKC5cuGDVaEchnjy3HB0dhbe3txgyZIj4/fffzY7mzu58ZNVPGZ97GzduFF27dhXly5cXDg4OwtfXV3Tr1k3s27fPuI250Y5CWL5/09izZ48AxOzZs7M9fnMohLAisY1EIpFIbM61a9eoUaMGU6dOZcqUKbYWJ1sGDx7Mr7/+ysOHD20tikSSr7zzzjssXbqUGzduZBm7aAnpdpRIJJIiyKlTp1i9ejUtW7bE3d2dixcvMnfuXNzd3RkyZIitxZNISiUHDx7k0qVLLFmyhBEjRuRK8QKpfEkkEkmRxMXFhaNHj7J8+XJiY2Px8PAgNDSUjz/+OFejviQSSd5JG3DUo0cPZs6cmet2pNtRIpFIJBKJpBCRqSYkEolEIpFIChGpfEkkEolEIpEUIlL5kkgkEolEIilEZMB9Nuj1em7fvo2bm1upmkJFIikqCCFISEggICDA6uSiRQH57JBIbEtRfnZI5Ssbbt++TWBgoK3FkEhKPTdu3Mg0H2JRRj47JJKiQVF8dkjlKxvSphO4ceMG7u7uNpZGIil9xMfHExgYaLwXiwvy2SGR2Jai/OyQylc2pLkL3N3d5QNUIrEhxc11J58dEknRoCg+O4qWE1QikUgkEomkhCOVL4lEIpFIJJJCRCpfEolEIpFIJIWIjPnKA6laPdfuJVKtnGuR9ClLJJKijV6vJzU11dZilHjs7e1RqVS2FkMiMSKVrzzw+soj7L9yj3l96/JCYzmkXCKRWE9qairXrl1Dr9fbWpRSgaenJ35+fjn/UL6yE7b/D2r3hqfHQxHLFyUpnkjlKw/sv3IPgB8OXpfKl0QisRohBJGRkahUKgIDA4tcAsiShBCCpKQkoqOjAfD397d+4//2wpr+oE2GXWch8hQ8txTUrgUkraS0IJWvfEA6HCUSSU7QarUkJSUREBCAs7OzrcUp8Tg5OQEQHR2Nr6+vdS7I62Gw+iWD4hXQEKLOwPk/IOYqvLwKvIILVmhJiUZ+buUDwtYCSCSSYoVOpwPAwcHBxpKUHtKUXI1Gk33lm0fhpxdAkwSVO8DrW2HwJnDxheiz8FU7uPZ3AUssKclI5UsikUhshByoU3hY3de3T8IPvSE1AYJbQ78fwU4NFZvB8D0Q0AAe3Ycfnoc75wpSZEkJRipfEolEIpEApCYaLF4pcRDYHF5eAw7p3MIe5eG1LVApFPRaOPB/NhNVUrwpNsrXtGnTUCgUJoufn1+W2+zdu5dGjRrh6OhIpUqVWLZsWYHIJr9dJRKJxMDKlSvx9PS0tRi548yvkBgNnhVhwM/mA+vtnaD9h0/qx0cWroySEkGxUb4AatWqRWRkpHE5c+aMxbrXrl2jW7dutG7dmhMnTjBlyhTeeustfvvtt0KUWCKRSKxHpy/cCNKc7m/w4ME899xzmcr37NmDQqEgNjaWfv36cenSJavaK1KKmhBw5BvD/02GgqOH5boVGkHFFqDXwOGvCkc+SYmiWI12tLOzy9balcayZcuoWLEiCxcuBKBmzZocPXqU+fPn06dPnwKUUiKRSHKHSqng7TUnuBL9sMD3VcXXlc9fapDv7To5ORlHFxYrbh2DqNOgUkP9V7Kv32IMRITB0RXQZgI4uBS8jJISQ7FSvi5fvkxAQABqtZpmzZrxySefUKlSJbN1w8LC6NSpk0lZ586dWb58ORqNBnt7e7PbpaSkkJKSYvwdHx+fvWAyaFYikeQTV6Ifcva2Fc+dIsrKlSsZO3YssbGxAJw6dYqxY8dy9OhRFAoFVatW5csvv+Thw4e89tprwJNg+KlTpzJt2jTbCH5kueFv7d7gUib7+tW7gncluP8fnPgJmg0vWPkkJYpi43Zs1qwZ33//Pdu2bePrr78mKiqKli1bEhMTY7Z+VFQU5cqVMykrV64cWq2We/fuWdzPrFmz8PDwMC6BgTJ5qkQikeSWAQMGUKFCBY4cOcKxY8eYNGkS9vb2tGzZkoULF+Lu7m4MJZkwYYJthEy6D/8+DklpPMS6bZQqaD7K8P/BxaDXFYxskhJJsbF8de3a1fh/nTp1aNGiBZUrV+a7775j/PjxZrfJOLRYCGG2PD2TJ082aS8+Pl4qYBKJRPKYjRs34upqGoielrfMHBEREbz77rvUqFEDgKpVqxrXeXh4WDV4qsA5+RPoUsCvLlRobP129fvDrpnwIBwuboaaPQtMREnJothYvjLi4uJCnTp1uHz5stn1fn5+REVFmZRFR0djZ2dHmTKWTcpqtRp3d3eTJTuk01EikZQW2rVrx8mTJ02Wb775xmL98ePHM3ToUJ555hlmz57N1atXC1FaK9Drn7gcmwzJWRiJg4thG4ADX+S/bJISS7FVvlJSUjh//rzFebpatGjBjh07TMq2b99O48aNLcZ7SSQSiSRrXFxcqFKlislSvnx5i/WnTZvG2bNn6d69O7t27eKpp55i/fr1hSixKZlGeP63Gx5cA7U71Hkh5w02HQ4qB7hx0JAZPy+ySEoNxcbtOGHCBHr27EnFihWJjo5m5syZxMfHM2jQIMDgLrx16xbff/89ACNHjuSLL75g/PjxDBs2jLCwMJYvX87q1avzXTZ5+0gkEollqlWrRrVq1Rg3bhwvv/wy3377Lc8//zwODg5ZuiwLgowjSj9ImEsL4Hfa8tWy47lqc6yqDR11f/H399OY4/qeVdsU1GhTSfGg2ChfN2/e5OWXX+bevXuULVuW5s2bc/DgQYKCggCIjIwkIiLCWD8kJITNmzczbtw4Fi9eTEBAAP/3f/8n00xIJBJJIfHo0SPeffdd+vbtS0hICDdv3uTIkSPG53BwcDAPHz5k586d1KtXD2dn50KZaDxtRKk/MTRVHwIF/F98G67G5W6U6WeK9nRU/0WzlINcj4/iIXKydEnWFBvla82aNVmuX7lyZaaytm3bcvx47r5kcoKM+ZJIJPlFFV8zWdWL6X5UKhUxMTEMHDiQO3fu4OPjQ+/evZk+fToALVu2ZOTIkfTr14+YmJhCTzXxkt0uVArBAd1TXBWWXafZcU4EcVXvT2VlJO2VJ/hD3yofpZSURIqN8iWRSCQlHZ1eFKorSqcXqJTWfz6a+8gFCA0NNY4mHzx4MIMHDwbAwcEh21CPpUuXsnTpUqtlyD8EvZQHAFija5/HthRs0jfjLeUGuqkOS+VLki3FNuBeIpFIcsKSJUsICQnB0dGRRo0asW/fPqu2++eff7Czs6N+/foFKyDkSBEqjvsrStRSXCdYeYdkYc9f+oZ5bm+LrhkAocqTOJOc5/YkJRupfOUDMsG9RFK0Wbt2LWPHjuX999/nxIkTtG7dmq5du5rEiZojLi6OgQMH0qFDh0KSVFJYdFMdBGCXvgFJOOa5vfOiItf05XBUaGivPJHn9iQlG6l8SSSSEs+CBQsYMmQIQ4cOpWbNmixcuJDAwMBs3V0jRoygf//+tGjRopAklRQKQtBdeQiAzY8tVnlHwWa9oa2uqkP51KakpCKVL4lEUqJJTU3l2LFjmeZ67dSpEwcOHLC43bfffsvVq1eZOnWqVftJSUkhPj7eZJEUTSrp/jO6HHfpM8bYCVBoTResS4eRpsi1V57ESboeJVkgA+4lklKIVqdn3M+naBzkxaCWwbYWp0C5d+8eOp3O7FyvGWfBSOPy5ctMmjSJffv2YWdn3WNy1qxZxlF8kqLN06n7Aditr2/iclSqb+FYfi0qdbRJfSGUaGIbk3KnBwgHi+2eFcFc1/sSpIwmVHmKLfr8sqpJShrS8pUPyJCvksuZm3F8s++/EpeJetvZO/x56jZT/zhra1EKDXNzvZqb51Wn09G/f3+mT59OtWrVrG5/8uTJxMXFGZcbN27kWWZJASCEUfl64nIU2Hsewjl4aSbFC0Ch0OPgdRjn4CUoHO5m0bjCqHB1k65HSRZIy5dEkgU9vzA8pN0d7XmxScmZYD0xRWtrEQoNHx8fVCqV2bleM1rDABISEjh69CgnTpxgzJgxAOj1eoQQ2NnZsX37dtq3z5yaQK1Wo1arC+YgJPnH3UuU10eSLOzZqW8IihQc/ddj73ESAG1CTZKjnkfon1i4VE43cAxYi8oxCpfgRSRH9kGbUM9s85t1TRlp9yftlSdQk0oKli1lktKLtHxJJFZwISrB1iLkK8pSlGLAwcGBRo0aZZrrdceOHbRs2TJTfXd3d86cOWMycfTIkSOpXr06J0+epFkz6Uoq1lwxXAe79fV55JCAc8gX2HucRAglyXe68ujmQITWHfSOxkWXWJWka2+hTQxBoUrFqcJq1OV+B/SZmj8tKnFT+OCiSCFUeaqQD05SXJCWL4nECkQJm8GzFOleAIwfP55XX32Vxo0b06JFC7766isiIiIYOXIkYDo3rFKppHbt2ibb+/r64ujomKlcUgy5uhOAP/WNcQr6AZX6LnqNO8m3+qN7FGxxM6F151HEUBzK/oXaZzcO3mEIrQepMaEZairYrGvGcLtNdFUdYpu+SYEdiqT4IpUviaQUUtqSa6ZNXzNjxgwiIyOpXbs2mzdvtjg3rKSEokuFuBuk4MDeMvdRqaPRa11JuvYmQudmRQMqUu92Rmg8cfRfj4PPDrQPa6BP8TOptUXXlOF2m+ggXY8SC0i3o0RSClGWwszAo0aNIjw8nJSUFI4dO0abNm2M61auXMmePXssbjtt2jROnjxZ8EIWcQYPHsxzzz1nUvbrr7/i6OjI3LlzmTZtGgqFAoVCgZ2dHT4+PrRp04aFCxeSkpJisl1oaKixbvolzRpZIGiSAFjtUhuFtyHJanJkHysVr3TNxDZFm1AThVKHY8BawDSG8oSowi1RBjfFI1orz+SL6JKShVS+8gFzI6YkJQtRsryOpc7yJSkYvvnmGwYMGMAXX3zBxIkTAahVq5bRkrh7925eeOEFZs2aRcuWLUlIMI2dHDZsGJGRkSbL3LlzC0ZYISD1EUkoWFbmEQqFIDW2MbqHNXPRmILkyN7otc6oHCNxKLsz0/rtusYAtJVxXxIzSOVLIimFlEbLlyR/mTt3LmPGjGHVqlUMHTrUWG5nZ4efnx8BAQHUqVOHN998k7179/Lvv/8yZ84ckzacnZ3x8/MzWdzd3QtGYE0y6DWs8PIiUZWIPtXLkLcrlwidGylRzwPgUGYPSkdTt/U/ekN8YEtl6UnnIrEeqXxJJEUAjU7Piv3XuFhIoyrTG75ESTPrFUeEgNRE2yy5OP+TJk3io48+YuPGjfTp0yfb+jVq1KBr166sW7cuN72TP6QmkKxQsN3ZEYSC5MgXDKMZ84A2oQ6auPooFAKngJ9BkWpcd0hfE51QUFkZiT8xeZVeUsKQAfcSSRHguwPhzNx0HoDw2d0LfH/p3Y46vcBOJS1hNkWTBJ8E2GbfU26Dg4vV1bds2cLvv//Ozp07zeY7s0SNGjXYvn27SdmSJUv45ptvTMoWL17MoEGDrG7XWrQpCcSpVAC4pbYnIalSvrSbHPUsKuf/UKrvofbdRsqdngAk4MxpUZkGiiu0Uv3Lr7q2+bI/SclAWr7yAfnakuSVM7fiCnV/6fN8aUtY9n5JwVK3bl2Cg4P58MMPM8VwZYW5GQUGDBhgkk/t5MmTPP/88/ktMmiSiRNadEB5F388k5/Nv7b1ziRHGqx/9l5hKOxijav+0dcCpOtRkhlp+ZJIigD5ocALIdh2Noqa/u4ElcnakpE+5kt6HYsA9s4GC5St9p0Dypcvz2+//Ua7du3o0qULW7duxc0t+9GC58+fJyQkxKTMw8ODKlWq5Gj/uUGX/IDYx9bdAbVe5bNwe+BR/rWfWB1tYmXsXK7iUGYPKXeeAwxxX2P4nVbKfwGB/FSXpCEtX5Ick6rVM3/bRY6E37e1KCWG/AiA/+t8NCN/PE7beXtytF1JSyBbLFEoDK4/Wyy5uPYqVqzI3r17iY6OplOnTsTHx2dZ/8KFC2zdutWq+LCC4H5yLHoU2CmUtAzIPKtBfpB6z+CCtfc8isLO0B/H9VVJFvaUU8RSWWEj5VpSJJHKl41YeySCd34+hVaXeXqKos73YeF8sfsKLywLs7UoJYd8+CA+ej13yrC0fElyQ4UKFdizZw8xMTF06tSJuDiD61yr1RIVFcXt27c5c+YMixYtom3bttSvX593333XpI2kpCSioqJMlgcPHuSrnDpNMjEKHQCuDm4oFQXz2tMlVUKbFIRCqcXB+28AUnDgqN4wObvB+iWRGCg2ytesWbNo0qQJbm5u+Pr68txzz3Hx4sUst9mzZ4/ZJH4XLlwoJKkt895vZ/jt+E02nYm0tSg55urdRFuLUCzQ6QXztl1g76W72dZNb/l6f/0ZHiSmZlHbPIpcanBS95LklvLly7N3715iY2Pp2LEjsbGxnD17Fn9/fypWrEhoaCg///wzkydPZt++fbi6upps//XXX+Pv72+yvPzyy/kq44OkO+hQYI8CJ7ucuVhzhoLUex0AsPc6hEL1EIADj+O+Wsm4L0k6ik3M1969exk9ejRNmjRBq9Xy/vvv06lTJ86dO4eLS9bxLRcvXjTJHVO2bNmCFtdq4h5pbC2CxApyk45hw4lbLN59lcW7r2Y7gjG92vTToQgSkrX838sNcrzP3KCXpi+JlaxcuTJTmb+/v8kH7cKFC61qK6sZBfILvdATozEoQV52ztxXpGSzRd7QJVZF96gCKqeb2HvvI/VuVw7oawM/01x5DiV69MXH5iEpQIqN8rV161aT399++y2+vr6Zpgkxh6+vL56engUonaQ0o9MLHqZo8XCyNym/FZt9QK9Gp2fW5szWsUt3zI8iE0Jw9W4iIT4uqJQKEpI1XIhKoFFFrxzJnF7Zk7qXpKTy4FEMWsBeCNycfLjPrQLeo4KUe+1xDvweB68wUmPackYfQrxwwkORRG3FNU6LygUsg6Q4UGxV8LT4Am9v72zrNmjQAH9/fzp06MDu3buzrJuSkkJ8fLzJkh3FOVm4EIL7uXBxSZ4wcMUh6k3fzn93H5qUW3NZrDkcwYp/rhGdYN0X+Q8Hr/PMgr2M//kkAH2WHuCFZWH8fPRGjq5Dk7pS+ZKUQPRCz71H9wDwQYXSrnAmt9Y9rIku2R+FKhUH73/QoeKQ/ilAuh4lTyiWypcQgvHjx/P0009Tu3Zti/X8/f356quv+O2331i3bh3Vq1enQ4cO/P333xa3mTVrFh4eHsYlMDCwIA6hyDBv20UafrSD347dzJf2tDo9vRb/w1urT+RLe8WBf64Yslf/fDTnfXg7LtlsuSVr1KJdVwD4/aRh5NSlOwaFb8NJ0y/6nIxElaMdJSWR2JRYtEKPnRB4OubMMpw3FKTeaweAg/c/oExOl+9LBt1LDBRL5WvMmDGcPn2a1atXZ1mvevXqDBs2jIYNG9KiRQuWLFlC9+7dmT9/vsVtJk+eTFxcnHG5ceOGcV34vUR+CAsnRavLt2OxtctnyZ6rAEz/M+svsrgkDZ/tuJTJupORkzdiOXUjlj9Olaxh1dacpmSN6XVhjSXK0vzWluKwLF0vGVNV5GQk6t+X71ldVyIpDgghiEmzeul0KB09C3X/2oTa6FJ8UaiSsfc8ZJznsYnyImqkp0FSDJWvN998kz/++IPdu3dToUKFHG/fvHlzLl++bHG9Wq3G3d3dZEkjdP4e/vf7Wb7Zd81km9yOMitOfPD7v3y+8zJdPt+XZb3SnCw9RWuaNiRjNm9zWMrvldNuzIvre9Wh67nfWCIpgiRqEknVaVAi8FQ6gH3e5nDMOUo0958GwMHrMJdFANHCE0eFhoZKy+8fSemh2ChfQgjGjBnDunXr2LVrV6ZMydZy4sQJ/P398yRLSUwumt3L/tjjY07VFs28ZI9S888amVtSNDmXwZLOlJvRlbnVvyzt6n5iKl/uvUp0QjIanb5I9LFEYg0PUgy5wjx0elSFbPVKQxNXD6FzQOkQg8r5Ggcex33JqYYkUIyUr9GjR/Pjjz+yatUq3NzcjAn5Hj16MqJs8uTJDBw40Ph74cKFbNiwgcuXL3P27FkmT57Mb7/9xpgxY/IkS4pGj740m3iyIDdKQ175ZPN5an64lUP/xWRb93xkPN/s+8+Y3DZVq+fjTefYn43rzZrDytUciTm2fJlfo1Qocm39srSv0T8dZ9aWC7y+8ghPz9lFzQ+3FpoCFhGTxJ6L0YWyL0nJQqvXkpBqGC3spdeDo4dtBBFqNPGGdDH2noeNrkeZbFUCxUj5Wrp0KXFxcYSGhpok5Fu7dq2xTmRkJBEREcbfqampTJgwgbp169K6dWv279/Ppk2b6N27d55kCfsvhrfXnsxTG/nFjwev8+wX+4l5WLD5a4oyX/39HwCzt2afPLfr5/uYuek8Pxw0uNp+PHidr/dd45Xlh/IsR0YlxpwylJiiZfzak+w4dwewHPNV0DqsSfsW9hX2WJn991Y8d+IN15elFBj5SVyShjbzdjP42yMctEKhlkjSE5sSixACJ6HHSWkP9k42k0UT2xQAO7d/2Y/BW1NX8R8u+TivpKR4UmyULyGE2WXw4MHGOitXrjRJ3Ddx4kSuXLnCo0ePuH//Pvv27aNbt275Is+fOQwotzSNUF7TVHyw4V9O34zj8515jCPI5mWfPn7JWpltYQXLCk26c3DmVhx6vWDGxnNWbXslOuuBBtby5d6rrDtxi2HfHwWyiPlK13f/3X2Yrbs3NilnyXrTn5nD4fcZt/YkkXHZvxAKOq3Ksev3qTdju/H30RLo4pcUHEIIHiQbXI5eOj04eto0F5A+uTy6R+VRKHXc87jOTeGDnUJPPeVVm8kkKRoUG+WrOPP13/9R7YMtZmPF8ks/SSrEeJysZDYxqJipZyuFLDLuEbU+3JZOENh5wXq3VpgVFpiMx5Z+IMbkdWcAjBakNCxZvsJjkvj3Vhwnb8TS/tO9vPRV1qMXz9yKy9HAj4yyrj9xiwHf5N36l1eW7jF9Kc3ffslGkkjyyquvvsonn3xS4Pvp27cvCxYsACBJk0SqLhUl4G5Ll2M6NLHNAHDwPMwxfRUAGinkdV3akcpXIfDx5vPoBUz67bRV9YUQ3LOhG/H/dl6my8K/TaY+ys3HY0Y1a+h3R+m1+B90BRQvl5WIK/8JJzWd5UurF7maPzFH8qQTaPXhiExlht+Wpe6xaL8x7ul4RCyQf8q6uWb+s2LOzoIe2WvJEigpGgwePBiFQsHs2bNNyjds2GByLZ8+fZpNmzbx5ptvGsuEEEybNo2AgACcnJwIDQ3l7Nmsg8/Pnj1Lnz59CA4ORqFQmJ266MMPP+Tjjz8mPj4+XaC9DpXSDhyynnquMNDEPw68V99ju9owtZ0c8SiRypeVJCRn4dbJ4n0x9LsjT6pZ+WJ555dTNJ75F7su3Mm07vO/LvPToescu36fuBy6mqxlwY5LXIhKYOU/4XlqJ2Ouqr/O3+H0zTjOR2Y/a0BuyEovybjuj1O3TZSxnHD5TgJL91zNlNcrU8yXFW1lp2xkTF+R1TEWht5S0PtQWTIFSooMjo6OzJkzhwcPHlis88UXX/DCCy/g5uZmLJs7dy4LFizgiy++4MiRI/j5+dGxY0cSEizHESYlJVGpUiVmz56Nn5+f2Tp169YlODiY73/4nvhUw7PFGGhfFJR5vRpNfH0AjrkbwhcaKi+jEEVz5LikcJDKl5XEZzMB9qNUHTfuJ5mUaXR6/jqfvWsrKVXLiB+OsuGEIUv5uuOGv2nZzNO4fCeBz/66xPvr/6XP0jA6frbXuC7jSzo/0OqftJl+CqL0z7PZWy6g0emZ+vu/xiDyNNIrX+lHhxaGdePrv/9jzKrjRiubOXenNTFO5uj42d/M2XqBRbty/vWaUQHPriuyWv1KBjfh5jOR2e7fMDfkQ25bMe9kdiQka/jq76vcuJ+EEILdF6KJspCx31qUUvkq8jzzzDP4+fkxa9Yss+v1ej2//PILzz77rLFMCMHChQt5//336d27N7Vr1+a7774jKSmJVatWWdxXkyZNmDdvHi+99BJqtdpivWeffZafVv+EEAJHIXASwhDvVURIC7x/6BZOpEKNhyKJCvr8mVVEUjyRypeVLN6ddYBkh0/30Hrubi5EPbHqZHzfW3qtfP33NbadvcPYtScJuxpjsX7GrPHp5wPM6QCAjGRlUdHo9CYxZemPa9neq3yw/l++C7vOsO+PmqxL/78u3Y+Csm6ciIg1Klsfbz7PxtORVJ6ymat3H5p11+UqNUQ6joQ/4OztuCcFGc+3mcPMWJaXrth/xTQ9xlUr3IarDkfQ4dO9vL/e/HD3mVYMQIiKS+bgfzG0mLWLTzZfoPXc3Ww6E8lrK4/QfNZO64S3gKooWCpsgBCCJE2STZacxmGqVCo++eQTFi1axM2bmRWI06dPExsbS+PGjY1l165dIyoqik6dOhnL1Go1bdu25cCBA7nvuMc0adKE40ePk5qSipdOBwolqF3z3G5+oU+uYAy8/9rVMGVdTW32o7MlJRc7WwtQXPg3/Us2AwqezNG3/ewdavgZsuJbM2fe35fu4qx+chreeTxhMmS2kmS0hFlDfLKG3ksO0KWWHxM6V7dY72GKltuxjwjwfDIsO23v2Vn9LkWbdxukaPQ42qsATOK8VAWo8h+6FkPLyj4mZaN/Ok6rKj6Z6up0mc/Pz0duEPdIw7A2lbLd1+Fr9+n+f/uNv6053xlVi+ysgBlXZ3cusmPRzqyvoW/2X+P1p0NMroOMmFOw9l3K2RRFiSlaElO1+LqZZh4vSLfjkiVLmDdvHpGRkdSqVYuFCxfSunVrs3X379/Pe++9x4ULF0hKSiIoKIgRI0Ywbty4ApHtkfYRzVY1K5C2s+NQ/0M42zvnaJvnn3+e+vXrM3XqVJYvX26yLjw8HJVKha+vr7EsKioKgHLlypnULVeuHNev532GhTLlypCakkpMdAx1y5UBRy+DAlaE0MQ2ReW0nh3uCv6XADU1520tksSGFK2rswhjTTAymCoZGT8ozb2ad16INrFapZ9oOe09dDEqgVetzEO152K0SS6mnw5GcCX6IV/szvzS/fnoDZPfLWfvMttmdiqFpddlvRnbjXFrukJyO5pLyfAgKdUqy1eyRsfE307z8ebzRMQkZd4gGzafiTKZ+zJjcPp/dx/y06EIk7Ls4gDTt3Hs+v08W+usITcDIswpnrdiH6HXG1LCZIxPbPjRDpp+vJO7CRlHfxbMtbF27VrGjh3L+++/z4kTJ2jdujVdu3Y1yQuYHhcXF8aMGcPff//N+fPn+eCDD/jggw/46quvCkS+4sicOXP47rvvOHfO1Fr66NEj1Gq12Ws7Y5kQwupY2KxIVRrCIuyTklABONl+lGNGNPH1EXoHYh1SOK12oKZWKl+lGWn5ygdM0ytYVr6uRD9k98VoqpS1zhye9uIdtOIwUfHZx9KcvR3H4G8NAf7hs7sDpnFX647f5GGKlhcbB+Jor2Lir9aNvsxIVA5ipV5feZTw2d1NlIaD/92nkpV9kFPMp7cwrxxkHBDQ/+uDxv8TUsxbmKb9kfXorDdXn2DTWwZryi/HTJVbcznFsnvtpH8v9Vlq/WTZlrDGOmensiyVpfdk+q58bvE/NK9UhmV7r/Jc/QDsVEp+PXaTNcOb07xSGeBJjOLxiAd0rvUkkLqgrKILFixgyJAhDB06FDDMfrFt2zaWLl1qNnapQYMGNGjQwPg7ODiYdevWsW/fPoYPH57v8jnZOXGov21SfTjZ5S4JaZs2bejcuTNTpkwxybfo4+NDUlISqampODg4ABiD5aOiokymd4uOjs5kDcspeqHn1l1DnGywhxugALV71hvZAr0abcJT2HucZJOLC1Pu34Sk++DsbWvJJDZAKl/5THqjQcaXO8Br3x7JVGaRxy86axQvgAuRmd1/6S0J438+BcCHv5/lxyHWuzgyHsbui3dNficka7Pc/m5CCnbp3ElT1p+hZeUyBPtkHga+//I9Tt54wOh2VXL1RWxeyTKvlGW08KSlcwDLKRVWHgjPcv9nb8fzzs+n2HspmnsPTVNZmDMoFcX48mt3E42zBlhL+kM7eSOWkzdiAdhw8olVd/HuKzQL8TY5r3q9YM3hCGoFeLD/yj1+Ppr/QcipqakcO3aMSZMmmZR36tTJ6nijEydOcODAAWbOnGmxTkpKCikpTyx58fHWj+pVKBQ5dv0VBWbPnk39+vWpVq2asax+/foAnDt3zvh/SEgIfn5+7Nixw6jUpqamsnfvXubMmZMnGRJSE7h07hJ+AX5U9PYEtRsoVXlqs6DQxDUwKF+urrx7/wH2N49CtU7ZbygpcUjlKx9IP5IvLbBcpxds/TcqT+3m9L1szqZh6eU+8ddTVrd7PSZrl+vlbLK/J6ZocXU0vdSu308i2MeFuCQNey5F0+kpP5wcVMZpfiqXdaVrnZxPgG4psau5oOKC8uD9dtx6BSI8G/dmfutm1sRW989FslVr2t13+R4tZu1i/eiWxrJtZ6NMFDRzRFv58WGJe/fuodPpzMYbpcUiWaJChQrcvXsXrVbLtGnTjJYzc8yaNYvp06fnSdbiRp06dRgwYACLFi0ylpUtW5aGDRuyf/9+o/KlUCgYO3Ysn3zyCVWrVqVq1ap88sknODs7079/f4vtp6amGt2aqamp3Lp1i5MnT+Lq6kqVKoaEpXEpcRw/eJx2oS0N90sRGuWYEV1iFfRaV+LtHhLm5EibG4ek8lVKkTFf+UD6kXxpithPh67zzi/WKzjmyKnhx5yCYSmA+bYVKQH+b9cVPttxiaGPp8KxSgYzKuBX+/7LZGWyfyzX698d4e01J5n+p6k778aDJBJTtNSZuo3QebutjkMyq3yRfdyaNTz7xf7sK2VBxvPz7T/XsrWk5SVP0b+3Mg8Syek0RBmxZBG0xp0JBivugnRZ689ZkfOt/ad7s61jDbmJN9q3bx9Hjx5l2bJlLFy4kNWrV1usO3nyZOLi4ozLjRs3LNYtSXz00UeZru3hw4fz008/mZRNnDiRsWPHMmrUKBo3bsytW7fYvn27SS6wwYMHExoaavx9+/Ztows4MjKS+fPn06BBA6MSrNVriYmPYefmnYx4uZdhI8ci6HI0okIbXxeAja4ucMP2s0pIbINUvvKB9HpB2H8xfLPvPz78PevYIGvIj2ziOXXd9V1q6ob5fOflHL2wL0Zldn2uOhTBxtOmOajSlMJj1w2JGjecvGWyXgiDiy8hRUt4TBJb/s0+hxWYV7IMli+rNs+S0zctj3jNDdP/zD6tQ16ugB6LniiLyRod34eF5zqxrFEeCwKdeuxmtIb0inR0QsHP5ODj44NKpcpk5bIm3igkJIQ6deowbNgwxo0bx7Rp0yzWVavVuLu7mywljZUrV7JhwwaTsqCgIJKTk00UsEGDBnH79m3Cwp7EKSoUCqZNm0ZkZCTJycns3buX2rVrm7QVHh5uonwFBwebndM3bQ7f+JR4fvvpN+o1qkvbhnXAwRVU9vl+3PmJJs7gdt3t7ETi7eOgyzpsQ1IykcpXPpD+xXP6ZhwzN+XPKBaFImdzIZrm2DL8yGlM0dHrlrNWW4MlheKjDMHmSqXCZARcskbP/stP0hVExSebjDC9GJVgtCpO++MsH2w4Y7VMegsB91nZw747EM6U9dbvwxr2Xc5ZOgbIvwTdi3ZdzpcPAktYk2MsjfRpW/JqibMGBwcHGjVqxI4dO0zKd+zYQcuWLS1slRkhhElMl8Qyjo6OfP/999y7Z/01n5CQwNWrV5kwYYLV28SmxmJnb8f8WR883nHRG+WYEX1yBfQpPiQrlex0AKIL7r6UFF1kzFcRRqGAC2YsSZaYmG7uSJ1eYKdSFNnpWpbvu8bsPnVMygaueGKC/zbD1EaLdl3hfGQ8C19qYHTVvd2hGmXdTLNem1NWhRA8NDMo4IwZt1waa48WDZdRXB7zeqW51pbsyTpJcGFy6U7WMYIFwfjx43n11Vdp3LgxLVq04KuvviIiIoKRI0cCBpfhrVu3+P777wFYvHgxFStWpEaNGoAh79f8+fNN5iqUZE3btm1zVN/NzS1HrtpUXSqPNI94YeALVEvVAKJYKF+gQBPfAHXZHWxycebZG4fBv56thZIUMlL5KsL8cyWGrp/vy9W2D5I0nL4ZW6DWjryw9WwUc/rWNSnLLqzrr/PR7E030lKj02eKBTPXRHyy1mxQ97+3CmaOyfwkoxKaU5p8/Bdda/vn24TcBTUpekHTr18/YmJimDFjBpGRkdSuXZvNmzcTFBQEQGRkpEnOL71ez+TJk7l27Rp2dnZUrlyZ2bNnM2LECFsdgiQDcSmGjycXlQP2pIKdI9hZnoKoKKGJq4+67A4OOjly9/o+yjYdZmuRJIWMVL5KKDM3neP3bEaR2ZoV+6/leJvRq44b/zeXFPb3k7f49p+ct1tSufcwlR8O5j2DeBp5HcFrS0aNGsWoUaPMrlu5cqXJ7zfffFNauYowQghiU2IB8EwLYywWVi8DQlMGL40vD+yj2XLvBANtLZCk0JExXyWUoq54gSGYP7/ZfCaKg//dz/d2JQbMzZQgyT05nVdRYiBZl0yqLhWFQoFb6uN0LdkoX0Wtr+01rQDYpEqBhOL7USPJHVL5kkgkkkJGpTIkAU1NTc2mpsQcaVYvd5UTKqEHpT1kk6Q2KcmgpNnbF43RkPbaFtgJOKdW89+ljbYWR1LISLejRCKRFDJ2dnY4Oztz9+5d7O3tUSrld7C1CCGITYhFL/Q46XQkawU4OoOFkahCCJKSkoiOjsbT09Oo+NoalXCllYMPezX32HhtM281spzAV1LykMqXRCKRFDIKhQJ/f3+uXbvG9ev5F5NXGkjRpRDzKAalQolKp0eh14ILEJN1GhBPT0/jHJNFhe7+rdgb8TtbH/7Hm/k0ybikeFDslK8lS5Ywb948IiMjqVWrFgsXLqR169YW6+/du5fx48dz9uxZAgICmDhxonF4uUQikdgKBwcHqlatKl2POeSLE1+wPXw7nf2aMfrYerBzgiE7wN7R4jb29vZFxuKVnra1X8EpfD03lHAu6ji1/BvZWiRJIVGslK+1a9cyduxYlixZQqtWrfjyyy/p2rUr586do2LFipnqX7t2jW7dujFs2DB+/PFH/vnnH0aNGkXZsmXp06ePDY5AIpFInqBUKnF0tKw0SEzR6DSsD19PfGo8bZITcHx4A2r0ADdPW4uWK5x9qhOqgS1q2HLuB6l8lSKKVaDBggULGDJkCEOHDqVmzZosXLiQwMBAli5darb+smXLqFixIgsXLqRmzZoMHTqU119/nfnz5xey5BKJRCLJK2GRYcSnxuPj5EPD64/nnK3ezbZC5QWFgs5uVQHYGhmGXuRt+i9J8aHYKF+pqakcO3aMTp1MZ4Dv1KkTBw4cMLtNWFhYpvqdO3fm6NGjaDTmM4enpKQQHx9vskgkEonE9my5tgWAzv6tUEWdAYUSqnW2sVR54+mQzrjq9dzRJXEy+qStxZEUEsVG+bp37x46nS7TRLjlypXLNGFuGlFRUWbra7Vai3OOzZo1Cw8PD+MSGBiYPwcgkUgkklyTrE1mV4QhsXIXnYOhMLAZuPjYUKq8ow5+mvaJhjQYW/7bbGNpJIVFsVG+0sg4GkRkM0LEXH1z5WlMnjyZuLg445KTucYkEolEUjDsu7WPJG0SAS4B1It4PNNF9a62FSo/8H2KrqmG99H28C1o9ZnnoZWUPIqN8uXj44NKpcpk5YqOjs5k3UrDz8/PbH07OzvKlCljdhu1Wo27u7vJIpFIJBLbYnQ5BrZDEb7fUFi9uw0lyieUKpr5NsRTp+N+ajxHoo7YWiJJIVBslC8HBwcaNWrEjh07TMp37NhBy5YtzW7TokWLTPW3b99O48aNi0yWY4lEIpFkTaImkb9v/g1AV5UX6DXgXQl8qthYsvzBPqgFHR+7HreGb7WxNJLCoNgoXwDjx4/nm2++YcWKFZw/f55x48YRERFhzNs1efJkBg58MkXpyJEjuX79OuPHj+f8+fOsWLGC5cuXM2HCBFsdgiQLVEqZYFAikWRm943dpOhSCHYPpsbN04bCqsU70N6Eii3p+lj52nF9Bxqd+QFhkpJDsVK++vXrx8KFC5kxYwb169fn77//ZvPmzQQFBQEQGRlJRESEsX5ISAibN29mz5491K9fn48++oj/+7//kzm+iij2qrwpX73qB+STJBKJpCix7do2ALoEd0Zx5S9DYdWONpQonynfkIYaKKvVkpCaQFhkmK0lkhQwxSrJKsCoUaMYNWqU2XUrV67MVNa2bVuOHz9ewFJJ8gO9yNv2/RoH8vvJ2/kjTDGkfqAnJ2/EWvwtkRRH4lLi2H/bEOPVxbUSPIwyTKId/LSNJctH7NSoyjek88Pz/OjhzpZrW2hToY2tpZIUIMXK8iUp2fSsm73lav0o8/F9AHnU3Yo9GY+/OPTHZ/3q2VoESRFnV8QutHotVb2qUjnynKGwUijYqW0qV75TsQWdH7sed0XsIlmbbGOBJAWJVL4khUK9Ch7Z1vmge81s6zSo6MUX/RuYXacX+adueDrLARmFwfMNKthaBEkRZ/M1Q+6rrsFd4fJ2Q2FJcjmmEdSSeimpBOghSZtkHGAgKZlI5UtSKCx5Jfs5yxztrZv4tocFC1le3ZbpUWaRO67Iko/KZ2Hi4+pgaxEkRZR7j+5xOOowAF38WsDNx2kYqpRA5atCExQo6BIfBzxJrSEpmUjly4a4O+Y95C7ExyVT2bVZ3ahkptyW2FkxklGZg6vRxzWzy0Hkk/JRqawLRW3gZaC3k61FyDVVfV2zXL9tbObYls61zOfuk5QutoVvQy/01PWpS+CdCyD04PsUeJbAmUecPKFcbbo9dj3+ffNvElITbCuTpMCQypcN2TC6VZ7bKO+Z+aWsUChwsDN/ap+uUrBTcfwwpKnZcmvSSOTE2rT/vXaZyvKqe41uV5nP+tXj5xEt6FDD8PI317+2oKK3c7Z1Mh6+rfTHqT2fMv7/bufqbB3bJstYPXMobCa9pCiRZv3pGpLe5dgpiy2KORWbUy1VQyWVK6n6VON0SpKSh1S+bEh+5LUa+0xVetT1z1RuZyFtQ/9mFfO8z6xoXbWs2XJrLF/2KiWda5Wjko8LJ/6X2a2QPpWEORdlXmO+nB3seL5BBXxc1XzY8yk+6lWL395oyf+9bD7GzMXBOjdpfmCXE7OgjRnUIpilAxqy/712jG5XBZVSgYeTjKGT5IxbD29x6u4plAolnSs+A5cfJ8wuycpXUAsUQNdkwxRD0vVYcik+T/QSiFKhYOVrTejfrCLnZ3TJVRuezvZ80b9hpnJLL+tUrT5X+8kr1iqaX77amF0TQvFyyRwHtODF+llu26qKDxW88sdS5aK249UWwfh5OPJsvQB+GdkiU53CjLCyJgdaQdmKXmluvcJeyccFpVJB1zr+VPDK3loHmLXSFiNdU1JApCkeTco1oeyDG/DoPqg9INC8db1EUNHwnOl25xoAByMPcj/5vi0lkhQQ8hFXyKRXQpRKBaHVffnk+To45dKKYq8yfwozvqxbVCrD/73cgBStLlf7sYZWVczPlwl5t9xU8XXNVoFztFex993M7khrySpmrGFFr1y3m1taVn7SnxmPfdwz1TLVzyj9iDaVrN5XVn0787k6mcosVX+rQ1Wz5eWzUIrdHO2Z+VxtPnqutrHM183RYn1J6cCsy7FyO1CVYCuqewB4BVNRo6GWSwV0Qsf28O22lkpSAEjlq5AxUb4yvMCssW44p1PSutXxyxQLlPY7o7Kzenhznq0XkK0S0btheX7PZSzavL6Wczbl1cVqbusVgxvn636y8lqaa7agBxf2afgkDUPG81krwPyE7682D8Ld0Y6/321Huxq+Vu/r+QblcyTbe11q5Ki+2k5Fi0qWlfNXmgfxavMgk7LBLYMB6PSU9ceRFUuWLCEkJARHR0caNWrEvn37LNZdt24dHTt2pGzZsri7u9OiRQu2bduWL3JIsudq7FUuPbiEndKOZ4KeKR3xXmlUMnxAdsUwaEq6HksmUvkqZFSK9MpXzhWFn4Y2o4afG6uGNmPJgEYoMrSRpsBZivmqWs4ty/Z93RxzrcBkFXNlTcxXVphTNtpVz5+XchpZ6VIZ+xlAqy9YF66L+sloWGW6/hsVWpm6gZnzpgkBHz1Xm+P/60jFMs442qsIrf4kBu+rV7NP95GRve+Gmi33dnHIpCxlh2sOR/dO6VaTn4Y245PedXO0nTnWrl3L2LFjef/99zlx4gStW7ema9euJtORpefvv/+mY8eObN68mWPHjtGuXTt69uzJiRMn8iyLJHvScns9HfA0HqmPIPKkYUVJzO+VkccKZpfbl1Cg4Hj0cSIfRtpYKEl+I5WvQsbU8pVzhaRBRS+2jm1DSwujFt0cDSb5rJSdw1M6GP+f0atWjmUAS6keLNdX5lH5mvZsZjnNKUTWYi5YPqeWLI0uZxvkJZ9V+vPZvoZvlrLapXNFP+X/RGmtH+iZ4/0GlbGcskSYUVfNlaWR00vAwU5Jqyo+Vud/y4oFCxYwZMgQhg4dSs2aNVm4cCGBgYEsXbrUbP2FCxcyceJEmjRpQtWqVfnkk0+oWrUqf/75Z55lKY3ocpCETwhh6nJMm8sxoAG45u8HV5EkpA2oHCh3/zqNvA0jh7eGb7WxUJL8ptjN7VjcSf8Cys9cUp/1q8einVeY/4LBSpBVDJmn8xMloFUGJU6hMCzZcWhKBz7feZm65T0Y+v1RIOejDb1dHGhX3Zffjt/Msl7rqj4mMueVOuU9+H10K6r/b4uJAvVcg4KZmNvXTc2ETtVxVqsYs8p6y4nC5Fp58kNg6n7OijHtq5CYoqVLbf8sI/LTK6PujnbEPx5tZYnceFxtlT4iNTWVY8eOMWnSJJPyTp06ceDAAava0Ov1JCQk4O3tXRAilnhUSgVvrznBleiH2dZNUYVzx/UGCuHAoo0OuCes4mlg9f3q/Ph/ll3F1hBavSzvds6Zy7zQUbsaAu+v7aWrXRmOYnA9vlb7NVtLJslHpPJVyCjy6Ha0xPMNKphM1TK5a002n4kyWzd9bFmAhxOze9dh0rozgMH6Y81LUqVUML5jNZMA/pxmmK/p72YxHxlA80reHPzvPgPyOT2GQGSyxJ2e1gl3x4IJ5P1+SFNq+Lnz17k7uW4jvbh6vTBaONNjzurk7GDH9F6GQPa7CSkW23/7mWqcuhnHC40rMGfLhVzLmRW2GsF47949dDod5cqZJm4tV64cUVHm75GMfPrppyQmJvLiiy9arJOSkkJKypM+jo+Pz53AJZQr0Q85ezv7PlH7HsDBFVLja3L5diJ11cdBAWvjnuJsbN76tHLZopV82iJVO8G1vXS6e4NZCjvO3z/PtbhrhHiE2FoyST4h3Y6FTKV0N39eXXFZEejtzGIzKSjAoACentaJE//riJODipea5l65SR/DZmnAwNsWRsApUOCqtmzB+f71Zux8p63BamOB9CMCrSXNQJdeySwoxSs9eclDlj6GL60Vc4lmsyIrXd/bxYENo1sxoFnO4rhytH8bJ07N6KYWQljlul69ejXTpk1j7dq1+PpadnvNmjULDw8P4xIYWAKzsBc4euzcTwOgia9HI8Vl3BWPiBFunBbWj94t9jyObfO8fpAW/obUGjLwvmQhla98wFVtvQEx/SixjLpXfo+esxR0DwZlw1wurYzvolXDmjG4ZTDDLaQtsFMpeadjNUa0qWQ2r9PItpUZ1zFzWoS0fY1uV4XGQV58/HztTOsd7JRULpv11DTfDGpM9zr+FifbntQ1s4vBVlMg5mXuyfRW0jQlLmN/Z3dcOblOC4L8SCqcG3x8fFCpVJmsXNHR0ZmsYRlZu3YtQ4YM4eeff+aZZ57Jsu7kyZOJi4szLjdu3Miz7KUNlfM1lPbxCJ0jusRqhKpOAvC3vi760vS68qkGnhVBl0JXJ8PH8eZrm/NtCjWJ7SlFV3PBoFIqODW1ExO7VLeqfvpM31m5HXe909ZsLqecUMaMcmUN6cWqV8GTac/WYkq3mhZzOL3ZoSqTu9U0u250u8oW96NUKPB0duDXN1rm2uLi7GDH4gENTSbbTpvv8qUmgTxXP3MKhbxmwk+jQw5SOUDu5p4s62YY2NC5ll+6dnLcDGDIg7ZtbBu2jm2duwYyYE6OrGR7t3N1swM1ChoHBwcaNWrEjh07TMp37NhBy5aWpz1avXo1gwcPZtWqVXTv3j3b/ajVatzd3U0WSc6w9zgOgCa+Lgg7QpUnAditq287oWyBQmGcPLxDbDROdk5cj7/O6XunbSyYJL+Qylce0QuBSqlgVGiVHG+blSWgUllXGgZ55kEyaBTkxYg2lfjk+cxJMi2RcZRkbsLSfnujJX0bVeDI+8+YjU3KS9vW8OPQZnzY4yk+7PlU1vvI4/4nd7MucNff3ZBgVJcLrWnnO235c8zTtKn2JGVEXnTH6n5u1PDLB6UgFzIEejtz5P0O2Vck/yZJT2P8+PF88803rFixgvPnzzNu3DgiIiIYOXIkYLBaDRw40Fh/9erVDBw4kE8//ZTmzZsTFRVFVFQUcXFx+SqXJB2KVOzcDLGn2riG+BNDTeUN9ELB3/q8pxspdjx2PTpf2cUzFQ33zZ9X5WjbkoIMuM8jAR5FY+JlcygUCosWqYyMe6Yaf56+zdCnK3E77tGTNnKhoTQK8qJRUPYZ4QvKCVXe04nXnzYEpj5MyTxqL7fv9VVDm3Er9hHv/mr4+lTbWY5Xm9CpGr3qlydZo8PD2aCA5tTt2CzEG3dHe+pUMM3pZclyVxw8EnlJD5IX+vXrR0xMDDNmzCAyMpLatWuzefNmgoIMFtfIyEiTnF9ffvklWq2W0aNHM3r0aGP5oEGDWLlyZWGLXyqwczuLQpWKPtUb3aMg2qp2A3BCVCGWrPMTlkgep5wgNoKePg3587+NbLm2hYlNJuKgyr/R3xLbIC1feeTb15qYLZ/Xty7eVsRUpWdIa4PC0OWxi6kwX6ZvP1OVv8a3xcPZ3kTGgnxX5udoT2v2UdXXED826rErtIJnzhTnllV86FnPunQUY9pXJdDb2SSpbU6sOf9O72wxvUalfB6x5euWf67AoqwAjho1ivDwcFJSUjh27Bht2rQxrlu5ciV79uwx/t6zZw9CiEyLVLwKDqPLMa4hoKDdY5fjHp3lmTNKNA4uEGSYbaTpgyh8nX2JT41n7829NhZMkh9I5SsPfPVqI6pZyBj/QuNAypqJbwn0cqZd9bL0qOufKXnku52qs3Z4cxa+VB8o3ImbrSG/VaXCsIKk38PCl+qz/7129HocB/b1oMa0qVaW397IPGm2JdK7ZT2dzbtUOz5lPog7J4qJueD43RNCWTeqpcUJq3NzvbSrXpYNuZxOqiBOX5pyO+jx1EKS0oHCLg6VyxUANHENcEBDK+W/AOzW17ehZDbmsetRdeUvelbqCcAfV/+wpUSSfKJYKF/h4eEMGTKEkJAQnJycqFy5MlOnTiU1NTXL7QYPHoxCoTBZmjdvnm9y1a3gmeV6czE+CgV8+1pTvjCTBsJOpaRZpTL5ktE7v0j/gs1vZTCvUw5ZQ3rLlwKFieJSuawr37/elEZB1ifOtFMp2Ta2DRvffNpsPNu0nk8x/wXzX+p5DfQP8XHJ9wm+hzxdiYAcWgDBkFMst4eTVYLY/3upPudmdKZSNqNcJSULe48TKBQCbVIwQlOGxsqLuCqSuSs8OCuCbS2e7Uiby/L6AXoGGuK+9t/cz/3k+zYUSpIfFAvl68KFC+j1er788kvOnj3LZ599xrJly5gyZUq223bp0oXIyEjjsnnz5jzLc/LDjuyb2A4/D0eT8rHPGEYDvtjYkOxUbybIx0GVuy6f2vMp1gzPP8UxKwojH5OfuyNTrIxHywuqdOk2skromhOq+7lRu3zmuRUBBrcKMRnRmp6cTLFSWGQ1HVB6/hrfhs8fW2TBYMXr/zj5bU5zra0Z3pwmwV6sG5V5pKFCocDZQYaili4Edo9djto4w0dpqPIUYHA5iuLxmioYylQBzyDQpVL5wU1qlamFVmhlzq8SQLF4ynXp0oUuXboYf1eqVImLFy+ydOlS5s+fn+W2arUaPz+/LOvkFE9nB7PxOG93qErnWn5GV6Q23ct2Utca9KofYDLvXnakjxEa3DLYJsHK6RWx/Nr7sNYhTOlWs1COx93RnsEtgxFC2Dy7dXpLUeMgL07eiDW5RvLefsEpd1V83aji68bba04ay2oFeHD8fx3xcLKn8hTDR401EtSt4MkvIy2neJCULpSOt1CpoxF6O0OKCXgS71WaXY5gcD1U7QRHvobL23m28rOcjTnL71d+Z0DNAbaWTpIHiu0nRVxcnFXzrO3ZswdfX1+qVavGsGHDiI6OzrJ+SkoK8fHxJou1KBQKavq7G1NIpLd0jGxbGf88jIwsTMWroAPu01zAhcW0Z2sxvVdtm420SyO92/HXN1riVATcy/4ZrLc5xdvFwWbJUyUlg7RAe21CLdA7UkERTVXlLbRCyT595uTLpY7HcV9c3ErXoM7YPZ5u6PKDy7aVS5IniqXydfXqVRYtWmTM0WOJrl278tNPP7Fr1y4+/fRTjhw5Qvv27U3mX8tIfk4Rkl/JPAsbhYX/C6L90kRR8jquHtacz1+qTxXf/B3C7+ZYLIzpkiKDFjt3g4tRk8HleExUIx4Z+0dIW1B7QMJtvKIv0LqCIUnyn//JnF/FGZsqX9OmTcsUEJ9xOXr0qMk2t2/fpkuXLrzwwgsMHTo0y/b79etH9+7dqV27Nj179mTLli1cunSJTZs2WdwmP6cIKYoxPjmlIKxFtrZA5SfjLUydZI5MyrgNu6FF5TLGUZ+5IeOVPfO52rzQqAIda2Y9XY9Ekh4714so7RLRa93QJRoSVYcaU0zUt51gRQl7R3jKMNKRM7/wbOVnAdh0dRM6vc6Ggknygk0/U8eMGcNLL72UZZ3g4GDj/7dv36Zdu3a0aNGCr776Ksf78/f3JygoiMuXLZtr1Wo1anX+5D3y93QiOsGylS07bKW6mbgdC7j94s4boZVZsOOSVXU71SrHBxv+pX6gJ5D/fWtLQ+srzYN4pXnBTcotKZk8CbSvD6hQk0or5VkA9uhLaX4vc9R5AU78COc20KbTTDzUHkQ/iuZg5EFalc9dqhiJbbGp8uXj44OPj49VdW/dukW7du1o1KgR3377LUplzo12MTEx3LhxA39//xxvmxv+76X6TP3jLG+0tTy/YZbY6GXq7fJE+SyshKvFFXuVkkldazB7y4Vs6/q6OXJ2emeLsV4hPi5cu5eY3yJKJEUShSoBO7fzwBOXYwvlWZwUqUQJL86LirYUr2gR3Bpcy8HDOziE76drcFfWXFzDb5d/k8pXMaVYxHzdvn2b0NBQAgMDmT9/Pnfv3jXOtZaeGjVqsH79egAePnzIhAkTCAsLIzw8nD179tCzZ098fHx4/vnnC0XuoDIurHytKc0q5Wwovq3xdnFg1dBm/PZGy4JxO+Z7i7YlJ4HzLmo7lBYC1Ps2MqQoqffYMiaRlGTsPY+iUOjRJVVEn2L4IO6mPAzAdl1jSt6TIg8oVVC7j+H/M7/Qt1pfAHZH7OZu0l0bCibJLcVC+dq+fTtXrlxh165dVKhQAX9/f+OSnosXLxonvlWpVJw5c4ZevXpRrVo1Bg0aRLVq1QgLC8PNrRTOE5ZDWlbxsWp+xtxQ0ixoLzYOpEmwF+92rp6j7d5+xjRebESbSvw4pBk/DmmaKzmszdklkdgePfaehwBIjW0GgB1aOqkMMb6b9c1sJlmRpbZB4eLiZqq7lKd+2fpohZb1V9bbVi5JrigWQ5MGDx7M4MGDs62XPs+Rk5MT27ZtK0CpCp6S+jItjDkdCxMnB1Wu8la93iqYmZvOGWO17FRKnq5qnRu+IOn4lB+/Hb9JJR/LedGK6UBeSRFB5XIJpUMsQueE9nFur1bKs3gqErkrPDisr2FjCYsg5RuCVwg8uAYXt/Bi9Rc5efckv176lSG1h6BS2j51jcR6ioXlS1KyKFmqV+5RKBSEZKHg5JT8Uoim96rFzOdqs2ZE4cyoICl9OHgZrF6a2EYgDDNCdFMayrbqmqCXr6bMKBSGwHuAM7/QMagjHmoPIhMj+ef2P7aVTZJj5BUukUhMcFXb8UrzIHzd8paAVSIxh8IuFpWrYYCKdDnmkDqPXY9Xd+KYkkivyr0AWHtxrQ2FkuQGqXxJrCa/5nwsSXm+8kpFb+fsK0kkJQh7r8OGSbQTKyNSywLQQnkOL8VD7gl36XLMirLVwa8u6LVwbgMvVDNYwvbd3Mfth7dtLJwkJ0jlqwhT1OJq8isGLdhHKhxpzOlTl+51/FmbD5OmF+blUlLjESUFjQ57zyMAaB48sXCluRy36ZqgQ8YuZYnR9fgrwR7BNPNvhkDw66VfbSuXJEdI5asIU9SUr7yyelhz3ulYjV71cp9ZvaRRzt2RxQMaFpt0JC81CaS8p1OesuNLSi92budQ2iWg17qiTXjKUIaWziqDQrZJuhyzp3YfQAERByD2Bi9WexGAdZfXodFrbCubxGqKxWjHokSrKsXjJVkQ5NXt2KJyGVpULr39V9CIQtDWZ/epixBCuo4luSItvYQmtglpr5/myvN4Kx4SI9w4pK9pQ+mKCR7lIagVXN8Pp9fQ7umx+Dj5cO/RPXZH7KZTcCdbSyixAmn5yiEDWwQX2r68XOwLbV8SibVIxUuSGzTKaOxcryCEAs2DJ7nsnrgcG0uXo7U0eMXw9+i32AsFz1cxJA7/+dLPNhRKkhOk8pVDCvO107CiF2PaVeHTF+QcZ5Ls8fdwsrUIEolFEhz2AKB7WB2hNSRwVqEzuhw362VqE6up3RucfSD+FlzYSN9qfVEqlByKPMSlB9bNNSuxLVL5KsIoFAomdK5On8fTzkgkWTG3b11biyCRmOV+8n0SHQy5qFLvP20sb6Y8TxlFAveFK2H6p2wlnk0o66pGp89lqICdGhoNNvx/+CsCXAN4puIzAHz777e5ajLXskhyhYz5yiHy8pQUVQI8peVLUjRZfWE1QqFB96gCuqTKxvLupXiUo7uTHSqlgrfXnOBK9MMcb19GX5tvUaK6/g+jF3zPJYeG4LadjVc3c/xkM+yE9fG1VXxd+fylBjmWQZJ7pPIlkUgkkgIjSZPEqvOrAEiNaUta8IYzyfRQhQGwRZ+7+UxLAleiH3L2dnwutnRgi30TeqgO8fT9dWzSDsMpsAp2rlcI124h5c6z+S6rJP+QbsccUtLSP+QEGWctkUhyym+XfyM+NR47nS/ahFrG8pdUu/FQJPGf3o/9+jo2lLD48p22MwDPqf7Bg4ePlVuw9zyCQpVoS9Ek2SCVL4lEUipYsmQJISEhODo60qhRI/bt22exbmRkJP3796d69eoolUrGjh1beIKWIDQ6Dd+d/Q4A95RnSHvl2KHldbstAHyt6y7ncswlR0R1zumDcFKk0k+1G11SFXSPyqNQarD3OmBr8SRZIK94idX0fRz4376Gr40lkUhyxtq1axk7dizvv/8+J06coHXr1nTt2pWIiAiz9VNSUihbtizvv/8+9erJ0ca5ZdO1TdxJukNZp7K4aJ4kUO2uPEgFxT3uCnfW6VrbUMLijoKVOkNer1dVf6FEGK1fDl5hoEi1pXCSLJDKl8RqAjydOD+jC8sHNba1KBJJjliwYAFDhgxh6NCh1KxZk4ULFxIYGMjSpUvN1g8ODubzzz9n4MCBeHh4FLK0JQO90BtH3r3y1CsoSMtbKBhptxGAldoupOBgIwlLBr/rWvFAuBKovEsH5XG0CbXRp5ZBYZeEvedhW4snsYBUviQ5wslBJZNsSooVqampHDt2jE6dTDN/d+rUiQMH8s81k5KSQnx8vMlSmtlzYw//xf2Hm72bcQocgDbK09RURpAo1Pyoe8Z2ApYQUnBgra4dAINU2wAlqTFtAHAosw/Q2U44iUWk8pVjSnHEvURSDLl37x46nY5y5cqZlJcrV46oqKh828+sWbPw8PAwLoGBgfnWdnFDCMGKf1cA8GL1F3F1cDWuG6EyWL3W6NoTh6vZ7SU54wftM+iEgqdVZ2mguIwmriF6rRtK+zjsPE7aWjyJGaTyJZFISgUZLbb5PUfl5MmTiYuLMy43btzIt7aLG3/f/JtTd0/hoHTgladeMZbXVvxHK9VZtELJcm1XG0pYsrhFWX7TGaxd79mvAWGHJsaQzFbtsxMUWluKJzGDVL5ySGlONSGRFEd8fHxQqVSZrFzR0dGZrGF5Qa1W4+7ubrKURrR6LZ8e+xQwxHr5OPkY1414HOv1h74lt/Exu70kd3ym7UuKsKe58jyhylOkPmiBXuOO0uE+9l5hthZPkgGpfOUQe5XsMomkOOHg4ECjRo3YsWOHSfmOHTto2bKljaQquay7vI5rcdfwVHsytM5QY7mfLso4ifZX2h62Eq/EEkkZvns88vE9uzUohB0pdw2/1T47QZlkS/EkGSg2mkRwcDAKhcJkmTRpUpbbCCGYNm0aAQEBODk5ERoaytmzZ3O1/+GtK9G2WllCq5fN1fYSicR2jB8/nm+++YYVK1Zw/vx5xo0bR0REBCNHjgQMLsOBAweabHPy5ElOnjzJw4cPuXv3LidPnuTcuXO2EL/Y8DD1IYtPLgbgjXpv4ObgZlih1zMm8QtUCsFeXV0uiIo2lLLkskT7LPHCmZrKCHopD6CNa4gu2Q+FKhm1zy5biydJR7GaXmjGjBkMGzbM+NvVNetgzblz57JgwQJWrlxJtWrVmDlzJh07duTixYu4ubnlaN9vPVO11LoRJJLiTr9+/YiJiWHGjBlERkZSu3ZtNm/eTFBQEGBIqpox51eDBk/mujt27BirVq0iKCiI8PDwwhS9WLHi3xXcT75PkHsQL1R/4cmKfxbSQHuSR8KBj7SvWG5AkidicWOZticT7dfyjt0vbE5tRkp0d5wrLsfeO4zUB80RGunuLQoUG8sXgJubG35+fsYlK+VLCMHChQt5//336d27N7Vr1+a7774jKSmJVatWFaLUEomkKDBq1CjCw8NJSUnh2LFjtGnTxrhu5cqV7Nmzx6S+ECLTIhUvy0QlRvH9ue8BGNdoHPbKx3m9bhyGXTMB+FA7mCuigq1ELBWs0HXhjvAkUHmX/qqd6BKron1YDYVCh9p3m63FkzymWClfc+bMoUyZMtSvX5+PP/6Y1FTL2XuvXbtGVFSUSW4ftVpN27Zts8ztI3P1SCQSSc5ZdGIRKboUGvo2pH1ge0Pho1j4dQgIHXsc2vKLrq1NZSwNJKNmobYPAG/arceVJFKiuyGEAnv3MyidrttYQgkUI+Xr7bffZs2aNezevZsxY8awcOFCRo0aZbF+2simnOb2kbl6JBKJJGecjznPn1f/BODdJu8aUngIAX+8CXER4BXMFy6jAZmguTD4WRfKVb0/ZRQJjLL7A32KH5pYw8wkjr6bkPkqbY9Nla9p06ZlCqLPuBw9ehSAcePG0bZtW+rWrcvQoUNZtmwZy5cvJyYmJst95DS3j8zVI5FIJNaj1WuZeWgmAkG3kG7U9qltWHHsWzj/Byjtoe+3PFI421bQUoQOFXO0LwEwQvUnjRQXSb3XEaG3R+Ucgb3HURtLKLFpwP2YMWN46aWXsqwTHBxstrx58+YAXLlyhTJlymRa7+fnBxgsYP7+/sby7HL7qNVq1Gp1dqJLJBKJBFh5diWn757G1d6VcY3GGQr/XQebJxr+f2YalG8I7LOViKWS7fom/KZ7mj6q/Sy0X0K31Fkk3+2IY7nNqMv9iTapMkLjbWsxSy02Vb58fHzw8cndyIsTJ04AmChW6QkJCcHPz48dO3YYRy2lpqayd+9e5syZkzuBJRKJRGLk4v2LxtQSk5pOws/FDw5/DZvfBQTU7gvNLYeHSAqWqZrBNFFcpKLyLtPsV/LO/ZHYuZ3Fzvk6jv6/8ihiKMUo+qhEUSx6PSwsjM8++4yTJ09y7do1fv75Z0aMGMGzzz5LxYpP8sXUqFGD9evXAwZ349ixY/nkk09Yv349//77L4MHD8bZ2Zn+/fvb6lAkEomkRKDRaXh///to9VpCA0N5tlJP2D0LNk8ABDQZCr2/AmWxeM2USB7izDjNKHRCQR/Vfp5VHiT59gsIvT12Lv9h75V/E8tLckaxuCvUajVr164lNDSUp556ig8//JBhw4axevVqk3oXL14kLi7O+HvixImMHTuWUaNG0bhxY27dusX27dtznONLIpFIJKYsPbWUiw8u4qX2Ymqz/6HY8i7snW1YGToZus0Hpcq2Qko4Jqrzhe55AGbaryBAI0i50x0Ate9WlA7RthSv1FIskqw2bNiQgwcPZltPZJh4UaFQMG3aNKZNm1ZAkkkkEknp4/Td0yz/dzkA/2s0Hp/f34JLWwAFdJsHTYdl3YCkUPk/7fO0Vp6mofIKCxyW0j92Clq3s9i5XsYx4BdE6kRbi1jqKBaWL4lEIpEUDZI0Sby//330Qk93/6fpuGW6QfFSqaHvCql4FUF0qBirGc1D4Ugz5QU+svuW5Mg+CJ0jKqcbxKtl8tXCRipfEolEIrEKnV7He3+/R3h8OL72bkw+sgHu/wceFWHINqjd29YiSiwQIcrxjuYNdEJBf7vdjGM7yVHPAhCn3sTOiJ02lrB0IZUviUQikWSLEII5R+aw5+YeHFDy6fXLeGiSoHIHGLEXAhpk34jEpmzTN+ED7esAvGW3gf6J0aQ+aAYKwaS/J3Hm7hkbS1h6kMqXRCKRSLLlx/M/svqCYZDTrDt3qJ+SCm0mwoBfwFnmiyourNZ14FNNXwCm2f3AM9FlcdTUIlmXzJhdY7iZcNPGEpYOpPIlkUgkkizZeX0n847MA+CdmAd00qvh5bXQ/n05orEYskj3PN9pO6JUCD6z/5L28Y2o4V2D+8n3GbVzFHEpcdk3IskTUvmSSCQSiUXORB1j0p7xCAT94hMY5F4dRu6H6l1sLZok1yiYrh3ERl1zHBQ6ZsbP5osKPSjnXI5rcdcYu3ssqbpUWwtZopHKl0QikUjMcvjcz4zYOphk9LROesSkagNQvLYVPANtLZokj+hRMl7zBlt1TbBHS7nf32Zx2ba42Ltw9M5RRu8cTUJqgq3FLLFI5UsikUhKGDq9yL5Slg1o2bRlNCMOzyBBAQ1Ttcxv+yl2nT8GlX3+CCmxOanYM0rzNn+qewCC6nvm87lrXZzsnDgYeZDBWwdzJ/GOrcUskRSLJKsSiUQisR6VUsHba05wJfphjrcN0N2gknIeqzy1oFDQOMmRlJRJvPCXN/yV88mxQ6uX5d3ONXK8naRw0KNkmfMIerZuAn9Npdnxtays2ZnRdtFcenCJAZsHsOSZJVTzqmZrUUsUUvmSSCSSEsiV6IecvR1vdX13Ehlq9yf3ff9hlYcLAEH3Q9h9ZyigAqxvKz2Vy7rkajtJIaJQwNNjwT0ANoziqfPb+NG7IqPK+fJf0h0GbRnEZ+0+o7l/c1tLWmKQbkeJRCIpxTiSwgjVn6xwe4d/Kh7iNw8XFAIcotrz750RGBQvSamg7ovw6jpwr0D5+xF8f/EYjXDmoeYhI3aMYP6R+TzSPrK1lCUCqXxJJBJJKcSDhwxWbWWHehyuZTczrLwH59RqVDp7km69QsyDTrYWUWILQtrAmMPw9Hg8sOPL8Av0evgIvdDz3bnv6PNHH45EHbG1lMUeqXxJJMWYBhU9AWhd1ce2gkiKBXZoaa88zmL7hRxWj+I51zW8WcGRr7w80CoUaONrEXd1ItqE2rYWVWJLHFzgmakwKgx1SCgz795lcVQ05bRabiTc4PVtrzN9z7syH1gekDFfEkkx5puBjfnz1G2ea1De1qJIiigOaGihPEdH5VE6q47go4gnzNGR0Z7eHHJyBEBoXUmO6oU2oY6NpZUUKXyqwqsb4OJm2hz/ng1Xd7LQ05W17m78en0rm8O38oJLZV6tOYByVbuC2tXWEhcbpPIlkRRjyriqGdwqxNZiSIoaD6Npl7KLUfb7aas8jasiGS2w09mJLz0DuKw2PPqFUKKJa0jKnW6gd7atzJKiiUIBNbpDje64Jt3ng3O/0/nfn5ideoNLage+S7rKT0en03Pvewx2CqFSyDMQ0hoqNAE7ta2lL7JI5UsikUiKO6mJcPMIXN1lWKLOMAHQqOCgkyN/OPux18WRRyo9AEJvjya2CakxrRFaL9vKLrE5ZV3V6PQClVKRdUVnb2j8Gk0av8avD++y/9Rylodv5Jg2jvWuLqwnmhqXV9Lx5BKeSdFTKaAxBD0NgU2hQmODO9NKrJKnGCOVL4lEUipYsmQJ8+bNIzIyklq1arFw4UJat25tsf7evXsZP348Z8+eJSAggIkTJzJy5MiCEU4I0CZDSgKkPgS9HkTaogNdKqQmgeYRaBIhOR5iLkP0Bbh7HmIjANAClx3sOeXmyt9OZTjkqCRVpXu8Ez16rQuaB83RPGiJ0MkUEBID7k52ucwN1wpoRTnVf6Q4/Emc/SUuqB24oHZgEVAl5QKtTp2k3qEUaqVoSCSYc3Y1uWxXlauqytxUVUCvyDyatoqvK5+/1CC/Dq9IIpUviURS4lm7di1jx45lyZIltGrVii+//JKuXbty7tw5KlasmKn+tWvX6NatG8OGDePHH3/kn3/+YdSoUZQtW5Y+ffrkbOc3joAyCRLvwsO7kBgNDx8vidHwKNagdOk1VjepBSLt7Lhub1givL245OzCWXs7HqF/XEsAOvRaN7TxtdAm1EGXFIxMHSGxRE5zwz3BB3gNhSoRO9dz2Lmfwc7lClccHLji4AAehlp+2iTqpIQRkvo3XbVa/JIFyan+3NBW5IqowBVRniv68lwRwfl4VEUTqXxJJJISz4IFCxgyZAhDhw4FYOHChWzbto2lS5cya9asTPWXLVtGxYoVWbhwIQA1a9bk6NGjzJ8/P8fKl+7H59GoFegUCnSAVqFAk/ZXAakKBcl2ClIUapIVCpIdnEhUqUhQKklUKElQKohVqbinsuOeSkGMQhCj0KMzuzc9bvZu1Clbh3//8yQqqiK6RxWRA9slhYHQuaCJa4ImrgkoH2HnegGVczgqpwhU6iii7OyIsrMDE6OrBmf9ZXx0F/DR6Wih0+OhU7DoKzfc1G64qD1xc/TG2ckLR6UDaqUDjip71EoH7PU67LUp2GmSsdMmY6dNQaXXodRrUel1kJhiq67IFql8ZYMQhjnS4uNzl91ZIpHkjbR7L+1ezCmpqakcO3aMSZMmmZR36tSJAwcOmN0mLCyMTp1M81x17tyZ5cuXo9FosLfPPL9hSkoKKSlPHvZxcYZh+M19/VE55dHaJARoNQaT12OU2OOk9MVF4YuzwhcXpT8eqko096vOi42DmHjjFC5OieCUt13nlbJqPfHx8QS6gsbbtlY3KUthyuIKNIbUxpAKgmRSlTdJVd1Aq7yHVnkXoYwiVfWQBCABJddQGr4TlIA+BR6lwKN7uZZAn2S4YXL77ChIpPKVDTExMQAEBgbaWBKJpHSTkJCAh4dHjre7d+8eOp2OcuXKmZSXK1eOqKgos9tERUWZra/Varl37x7+/v6Ztpk1axbTp0/PVH5p/KUcy5wXlgPDCnWPWbMD+NDWQjxGymKeoiRLQZDbZ0dBIpWvbPD29gYgIiKiyJ28okZ8fDyBgYHcuHEDd3d3W4tTpJF9ZR1p/XTu3DkCAgLy1JZCYTpySgiRqSy7+ubK05g8eTLjx483/tbr9dy/f58yZcpkuZ/iSGm4fkvDMULJPk4hBAkJCXl+dhQEUvnKBqXSECvh4eFR4i7MgsLd3V32lZXIvrKO8uXLG+/FnOLj44NKpcpk5YqOjs5k3UrDz8/PbH07OzvKlCljdhu1Wo1abZrXyNPTM1cyFxdKw/VbGo4RSu5xFlWjiYzClEgkJRoHBwcaNWrEjh07TMp37NhBy5YtzW7TokWLTPW3b99O48aNzcZ7SSQSSU6QypdEIinxjB8/nm+++YYVK1Zw/vx5xo0bR0REhDFv1+TJkxk4cKCx/siRI7l+/Trjx4/n/PnzrFixguXLlzNhwgRbHYJEIilBSLdjNqjVaqZOnZrJnSDJjOwr65F9ZR351U/9+vUjJiaGGTNmEBkZSe3atdm8eTNBQUEAREZGEhERYawfEhLC5s2bGTduHIsXLyYgIID/+7//y3mOrxJKabh+S8MxQuk5zqKGQhTFMZgSiUQikUgkJRTpdpRIJBKJRCIpRKTyJZFIJBKJRFKISOVLIpFIJBKJpBCRypdEIpFIJBJJISKVryxYsmQJISEhODo60qhRI/bt22drkQqdadOmoVAoTBY/Pz/jeiEE06ZNIyAgACcnJ0JDQzl79qxJGykpKbz55pv4+Pjg4uLCs88+y82bNwv7UPKVv//+m549exIQEIBCoWDDhg0m6/OrXx48eMCrr76Kh4cHHh4evPrqq8TGxhbw0eUv2fXV4MGDM11jzZs3N6lTWvqquBEeHs6QIUMICQnBycmJypUrM3XqVFJTU20tWp4pyc//WbNm0aRJE9zc3PD19eW5557j4sWLtharVCGVLwusXbuWsWPH8v7773PixAlat25N165dTYajlxZq1apFZGSkcTlz5oxx3dy5c1mwYAFffPEFR44cwc/Pj44dO5KQkGCsM3bsWNavX8+aNWvYv38/Dx8+pEePHuh0OlscTr6QmJhIvXr1+OKLL8yuz69+6d+/PydPnmTr1q1s3bqVkydP8uqrrxb48eUn2fUVQJcuXUyusc2bN5usLy19Vdy4cOECer2eL7/8krNnz/LZZ5+xbNkypkyZYmvR8kRJf/7v3buX0aNHc/DgQXbs2IFWq6VTp04kJibaWrTSg5CYpWnTpmLkyJEmZTVq1BCTJk2ykUS2YerUqaJevXpm1+n1euHn5ydmz55tLEtOThYeHh5i2bJlQgghYmNjhb29vVizZo2xzq1bt4RSqRRbt24tUNkLC0CsX7/e+Du/+uXcuXMCEAcPHjTWCQsLE4C4cOFCAR9VwZCxr4QQYtCgQaJXr14WtymtfVVcmTt3rggJCbG1GHmitD3/o6OjBSD27t1ra1FKDdLyZYbU1FSOHTtGp06dTMo7derEgQMHbCSV7Th//rzRHdSzZ0/+++8/AK5du0ZUVBS//PILtWvXBgwJ+9q2bWvsp2PHjqHRaEz6MiAggNq1axeZvhw8eDDBwcFW1RVCsGrVKtq3b4+XlxeOjo4AfP3119y6dQt40i/pjzmrfjl48CAvvPACjRo1QghB3759efHFF1m1ahUeHh40a9bM2E7z5s3x8PAoMn2XX+zZswdfX1+qVavGsGHDiI6ONq6z5hoKCwsrNX1V1ImLi8Pb2xuA06dP89prrxndd66urjRs2JC5c+dy//59G0v6hD179qBQKNizZ0+pfP7HxcUBGM+bpOCRypcZ7t27h06nyzTpbrly5TJNtlvSadasGcOGDTP+Pnz4MC1btiQmJsbYFw4ODibbpO+nqKgoHBwc8PLyslinuKDX63n55ZcZMGAAfn5+rFy5kq1btwJw6NAh6tWrx+HDh43HldX1k9YvP/74I61ateLmzZvMnTuXRo0a0aRJE27cuMHHH39sNuu0r69vseu7rOjatSs//fQTu3bt4tNPP+XIkSO0b9+elJQUwLprKCoqCl9f30xtl7S+KupcvXqVRYsWMXLkSL7++msaNWrEkSNHePfdd9m6dSvr16/nhRdeYNmyZQwZMsTW4pqltD3/hRCMHz+ep59+2vgRLSl4pPKVBQqFwuS3ECJTWUmna9euNG7cGDDE5dy7dw+NRsN3331ncRtr+imrOo8ePcq9wAXInDlzWLt2LbNnz2bVqlX06tWL0NBQAObPn4+rqyu9e/c2xk1kd/3o9XrGjh1Lt27d2LdvH6+++iqenp5Uq1aNffv2Ua1aNaKjozly5EiW7RR3+vXrR/fu3alduzY9e/Zky5YtXLp0iU2bNmW5XcZ+MNcnJa2vCgtzA20yLkePHjXZ5vbt23Tp0oUXXniBWrVq8cYbb/DMM89w7NgxRo0aRWhoKB07dmTy5MlcuHCB1157Lc9yJiUlmS3X6XRG5T23FMbzXwhh8+fdmDFjOH36NKtXr7apHKUNqXyZwcfHB5VKlekrJzo6OtPXUGli4sSJlClTBoVCweXLl42jHjOObIqOjsbHx4fJkyfzzjvvkJqaSkBAAKNHjzaOPkvry+DgYHr06MG6deto0KABjo6OTJ8+3egGWLVqFe+99x7+/v64urrSs2dP7ty5Q0JCAsOHD8fHxwcfHx9ee+01Hj58aCLH4sWLadOmDb6+vri4uFCnTh3mzp2LRqPJ8bGnpqYyb948atasycSJEzOt9/T0ZNasWdy6dcs4Kiqr68fPzw+tVotCoWDp0qXY2dmZ1LGzs2Po0KGAYWRSeu7evVuir0N/f3+CgoK4fPkyYOir1NRUHjx4YFIvY3/euXMnU1slva8KijFjxnD+/Pksl/RWktu3b9OuXTtatGjBV199xSeffIJCoeCrr74ya711cHDg2WefBQwfIXPnzqVGjRqo1Wp8fX0ZOHBgptGsoaGh1K5dm7///puWLVvi7OzM66+/Tnh4OAqFgrlz5zJz5kxCQkJQq9Xs3r0bgKNHj/Lss8/i7e2No6MjDRo04Oeff7Z47Omf/3/88QctWrTA2dmZ6dOnc+fOHcLCwjJt8/vvv1O3bl3UajWVKlXi888/Nyqw6VEoFIwZM4Zly5ZRs2ZN1Gq18UN2+vTpNGvWDG9vb9zd3WnYsCHLly9HZJgBMO2ZuXHjRho0aICTkxM1a9Zk48aNAKxcuZKaNWvi4uJC06ZNMynJ6XnzzTf5448/2L17NxUqVLBYT1IA2CTSrBjQtGlT8cYbb5iU1axZs8QGXGbFt99+KwBx5MgR8emnnwpADBo0yBhYXqlSJVGrVi0hhBApKSnC3d1dPPXUU8LOzk68++67QqVSiVdeeUW4uLiIBg0aiGvXrhmDpYOCgoS/v7+oVKmSWLFihdi9e7c4fPiw2L17twBEUFCQGDx4sNi6datYtmyZcHV1Fe3atRMdO3YUEyZMENu3bxdz5swRKpVKvPnmmyZyjxs3TixdulRs3bpV7Nq1S3z22WfCx8dHvPbaayb1Bg0aJIKCgrLsgwMHDghAvPfee5nW8TiIPCEhQSiVStGtWzfh5+cn5syZY6yTkpJiEnAfExMjAFGlShVjndu3b5sNInd2dhY6nU4IIcTBgweLdRA5ZgLuM3Lv3j2hVqvFd999J4R4EnC/du1aYx1LfXXo0CFjneLeV8WFmzdviqpVq4qXXnpJaLVaodVqhbOzs2jWrJlV2w8fPlwAYsyYMcb7vGzZsiIwMFDcvXvXWK9t27bC29tbBAYGikWLFondu3eLvXv3imvXrglAlC9fXrRr1078+uuvYvv27eLatWti165dwsHBQbRu3VqsXbtWbN26VQwePFgA4ttvvzW2nfa82b17txDC8Pzv0KGDAESnTp3Ehg0bRPny5YWfn59wcHAQ+/btM267ZcsWoVQqRWhoqFi/fr345ZdfRLNmzURwcLDI+IpNk7Nu3bpi1apVYteuXeLff/8VQggxePBgsXz5crFjxw6xY8cO8dFHHwknJycxffp0kzaCgoJEhQoVRO3atcXq1avF5s2bRbNmzYS9vb348MMPRatWrcS6devE+vXrRbVq1US5cuVEUlKSSRt6vV6MHj1aBAQEiEuXLll1niT5i1S+LLBmzRphb28vli9fLs6dOyfGjh0rXFxcRHh4uK1FK1Teeecd8d577xkfVt26dRMKhULUrVtX6PV6MXv2bKFSqURgYKA4c+aMePnll4W3t7cAxNy5c4UQQowcOVJUqFBBfPDBBwIQ1atXF/Xq1RNarVYEBQUJlUolLl68aLLftIdhz549TcrHjh0rAPHWW2+ZlD/33HPC29vb4nHodDqh0WjE999/L1Qqlbh//75xnTXK15o1awRgVJ4SEhLEiRMnxIkTJwQgFixYIE6cOCHKli0ratWqJWbPni08PDzEunXrjP3i7+8v4uPjhRBCREVFCUA4OTmJv/76Sxw/fly0b9/e2C9p+Pn5CUBs2bJFhIWFiTp16ogePXpkKWtRw1JfXb9+XSQkJIh33nlHHDhwQFy7dk3s3r1btGjRQpQvX97YV0I8uYay6qsuXbqIunXrirCwsGLbV8WNW7duiSpVqoj27duLmzdvisjISHH69GkBiJdeeinb7c+fPy8AMWrUKJPyQ4cOCUBMmTLFWNa2bVsBiJ07d5rUTVO+KleuLFJTU03W1ahRQzRo0EBoNBqT8h49egh/f3/jR01G5WvVqlUCEBUqVBD//vuv8fl/9uxZ4evrK1q2bGlsq0mTJiIwMFCkpKQYyxISEkSZMmXMKl8eHh4mzx9zpD2vZsyYIcqUKSP0er1xXVBQkHBychI3b940lp08eVIAwt/fXyQmJhrLN2zYIADxxx9/mLT/xhtvCA8PD7Fnzx4RGRlpXDIqaZKCQypfWbB48WIRFBQkHBwcRMOGDUvlMNx+/foJDw8PAQgfHx/Ru3dvMXfuXAGINWvWCL1eL4KCgoSdnZ1Qq9WiTZs24rXXXhOAiI6OFkII8ejRIzFmzBjh5eUlABEQECAiIiKEEIYHSYMGDTLtN+1h+OWXX5qUf/nllwIQ27ZtMymfPHmyAERCQoKx7Pjx46Jnz55GZTD9kj4lQW6UrzT5Mi6Ojo6idu3aQq/Xi6lTp4py5coZv7xPnDhhfNinKV9Vq1YV3t7ewsnJSfTo0cPYL2k899xzAhCurq7Czc1NDBgwQDx48CBLWYsalvpq0KBBIikpSXTq1EmULVtW2Nvbi4oVK4pBgwZl6oe0ayirvoqJiREDBgwQbm5uxbavihtpVnFzizXK15IlSwQgDh8+nGldzZo1Taxnbdu2FV5eXpnqpSlf48aNMym/fPmyAMT8+fOFRqMxWdL2e+7cOSFEZuUrzZLq6emZ6fn/xhtvCKVSKRITE8XDhw+FQqHIZHUXQhgtbOkBxPPPP2+2L3bu3Ck6dOgg3N3dM/VlVFSUsV5QUJBo0aKFybYpKSkCEC+//LJJ+cWLFwUgFi1alEkOc0t6a6CkYLGz2j9ZChk1ahSjRo2ytRg2Zc2aNaxcuZLXXnuNLVu20LhxY4QQrFmzhvfff5/evXsTHByMq6sr//77LwBDhw7Fzs6OsmXLAuDo6MiiRYtYtGgRVapUISQkhMDAQOM+/P39Le4/49DntJGVlsqTk5NxdXUlIiKC1q1bU716dT7//HOCg4NxdHTk8OHDjB49OsdBrhUrVgQMaSTAEH8iMsRiJCYm4u7uTmBgIAqFgmnTprFy5UpSU1PZt28fDRo0YOrUqUybNg0fHx+cnZ3x9vbm0qVLFvd7+/ZtnJycTJKzFjfM9VV6tm3blm0b6a8hS3h7e/Pjjz/mSkZJ7hg8eDCDBw82KdPpdLi7uxvvlayIiYkBzD8DAgICuH79uklZVs+KjOvSYgAnTJjAhAkTzG5z7969LOVatGgRr7zySia59Ho9Dx48QBgMGGbjCi3FGpo7hsOHD9OpUydCQ0P5+uuvqVChAg4ODmzYsIGPP/440/MqN8/F9GR1P0oKB6l8SXKMQqFgzpw5dOzYka+++irT+jJlyqDVarl7965RAQPDDR8VFUWTJk0ytZffbNiwgcTERNatW0dQUJCx/OTJk7lqr1GjRnh7e/PHH38wa9YsszL/8ccf6PV62rdvbyz7888/TUZdBQQEAKBSqWjfvj1btmzh5s2bZoNdb968ybFjx+jSpUuuZJZIbIFKpaJDhw5ZXttplClTBoDIyMhM9W7fvo2Pj49JWVbPiozr0radPHkyvXv3NrtN9erVs5UrI7dv30apVOLl5WUcAWlusIeltBTmjmHNmjXY29uzceNGY+5AINNUXJKSgxztKMkVzzzzDB07dmTGjBmZRhl26NABIJMV4rfffiMxMdG4viBJe8ClH2klhODrr7/OVXsODg68++67nD9/nnnz5mVaHx0dzeTJk/H09DSxBNSpU4fGjRsblzTlC2DSpEkIIRg1alSmqZZ0Oh1vvPEGOp2Ot99+O1cySyS2YvLkyQghGDZsmNl5HjUaDX/++afxQyXjs+LIkSOcP38+T8+K6tWrU7VqVU6dOmVyD6Zf3NzcLG5bvnx5Vq1aZWIlSkxM5LfffjOOgHRxcaFx48Zs2LDB5DgfPnxoHH1oDQqFAjs7O1QqlbHs0aNH/PDDD7k4cklxQFq+JLlmzpw5NGrUiOjoaGrVqmUs79ixI507d+a9994jPj6eVq1acfr0aaZOnUqDBg0KZb69jh074uDgwMsvv8zEiRNJTk5m6dKlmdIV5ISJEydy8uRJ3nvvPU6dOkW/fv3w8PDg9OnTzJs3jzt37rBx48ZMX+uWaNWqFQsXLuTtt9/m6aefZsyYMVSsWJGIiAgWL15MWFgY06ZNo2PHjrmWWSKxBS1atGDp0qWMGjWKRo0a8cYbb1CrVi00Gg0nTpzgq6++onbt2qxfv57hw4ezaNEilEolXbt2JTw8nP/9738EBgYybty4PMnx5Zdf0rVrVzp37szgwYMpX7489+/f5/z58xw/fpxffvnF7HZKpZK5c+cyYMAAevTowYgRI0hJSWHevHnExsYye/ZsY90ZM2bQvXt3OnfuzNtvv41Op2PevHm4urpancW/e/fuLFiwgP79+zN8+HBiYmKYP3++2TQdkhKCbULNJMWJ9KkmMtL//9u777AorjUM4O+CVAUslAWl2VAUK1GxIRZEEmOLNbZYEqPEQhIVTSImN6LGdhNjS4wlphiDGo3GkijYUEFBRRAxohCFIBawguye+weX1ZVd2MVdlvL+nmcfmZkzsx+zxY8z53wzYoQAoCg1Uejx48di1qxZwtXVVZiYmAhHR0fx7rvvFhkA7erqKl599dUixy0cALtt2zaNYpk3b54AoDQ1fffu3aJly5bC3Nxc1K1bV3z44Yfijz/+UBpYK4RmA+4LyeVy8f333wtfX1/FRAT8fwZnYmKiRsd40YkTJ8SgQYOEg4ODMDIyUgzc37NnT6mOR1RexMXFiTFjxggXFxdhamqqKDfzySefKCbkyGQysWjRItG4cWNhYmIibG1txciRI0VaWprSsXx9fYt8zwjxbMD9F198oTKGc+fOiSFDhgh7e3thYmIipFKp6N69u2LyjBBFB9wX2rlzp2jfvr0wNzcX1atXFz169BDHjx8v8hw7duwQXl5ewtTUVLi4uIiFCxeKqVOnFpkgAEBMmTJFZZzfffed8PDwEGZmZqJ+/foiLCxMrF+/XgAQKSkpinbqvjNVHbukc0OGIxGCI++IXsaECROwadMmhIeHKwpHvozNmzdjzJgxmDlzJhYtWqSDCImoLD19+hStWrVC3bp1ceDAAUOHQ+UQLzsSvaS1a9fi33//xZAhQ7B79+6Xvkw4evRopKenY/bs2ahevTo++eQTHUVKRPowfvx49OrVC46OjsjIyMCaNWuQmJiI//73v4YOjcop9nwRERG9hCFDhuDEiRO4desWTExM0KZNG8yZM4czlUktznYkokrtyJEj6Nu3L5ycnCCRSDSavh8ZGYm2bdvC3Nwc9evXx5o1a/QfKFVYv/zyC/755x/k5ubiwYMHOHLkCBMvKhaTLyKq1B4+fIiWLVti5cqVGrVPSUlBYGAgunTpgtjYWMyZMwdTp05FeHi4niMloqqClx2JqMqQSCTYsWMH+vfvr7bNrFmzsGvXLiQmJirWTZo0CefOnUNUVFQZRElElR17voiInhMVFQV/f3+ldb1790ZMTAyePn1qoKiIqDLhbMcSyOVy3Lx5E1ZWVnq5DQ4RFU8Igfv378PJyQlGRvr/ezEjI6PIffkcHByQn5+PrKwstfcXzM3NVbqVlFwux507d1CnTh1+dxAZQFl/d2iDyVcJbt68qXQTaCIyjLS0tGLvE6hLLyZLhaMzikuiwsLCMH/+fL3GRUTaK8vvDk0x+SpB4b2/0tLSYG1tbeBoiKqenJwcODs7q70Pn65JpdIiN0XOzMxEtWrVFDdcViUkJATBwcGK5ezsbLi4uKj87lh+8DI2nrgGmbzokFtjIwnGdnTDjF6NX/I3Iarayvq7QxtMvkpQ+JeutbU1ky8iPZPJBU6n3EHm/SewtzJHO/faim1ldenOx8cHu3fvVlp34MABeHt7w8TERO1+ZmZmKu/Fp+q7Y7RvU2yK+RdGKqY7SSTAGN+msLauXrpfgIiUlMfL/ky+iKhc2Befjvm7E5Ce/USxztHGHB/4vdxl/wcPHuDKlSuK5ZSUFMTFxaF27dpwcXFBSEgIbty4gc2bNwMomNm4cuVKBAcHY+LEiYiKisL69evx008/vVQcz3O3rY5Fg1pgVvh5FHZ+GUskEBBYNKgF3GyZeBFVZky+iMjg9sWn490tZ/FiR1BG9hMEbz33UseOiYmBn5+fYrnw0uCYMWOwceNGpKenIzU1VbHd3d0de/fuxYwZM/D111/DyckJX375JQYNGvRScbxosLczmte1Rp//HgMAvNXZDSPbuzLxIqoCmHwRkUHJ5ALzdycUSbwAqFynrW7duqG4coYbN24sss7X1xdnz57VwbMXz7XOs0QruFdjWJryK5moKihfcy+JqMo5nXJH6VLji1gFmogqGyZfRGRQmffVJ15ERJURky8iMih7K3NDh0BEVKaYfBGRQbVzrw1HG3Oomwxe/iaJExG9HCZfRGRQxkYSzOvrCaBoosXEi4gqIyZfRGRwAc0dsXpkG0htlC9BSm3MsWxoSwNFRUSkHxUm+QoNDYVEIlF6SKXSYveJjIxE27ZtYW5ujvr162PNmjVlFC0RaSuguSOOzeqOnyZ2wH+HtcJPEzvg2Kzu6OVZ/OeciKiiqVBFZZo1a4Y///xTsWxsbKy2bUpKCgIDAzFx4kRs2bIFx48fx+TJk2FnZ6fzYolEpBvGRhL4NFB//0QiosqgQiVf1apVK7G3q9CaNWvg4uKCFStWAACaNm2KmJgYLFmyhMkXERERGUyFuewIAMnJyXBycoK7uzuGDRuGq1evqm0bFRUFf39/pXW9e/dGTEwMnj59qu9QiYiIiFSqMMlX+/btsXnzZuzfvx/ffPMNMjIy0LFjR9y+fVtl+4yMDDg4OCitc3BwQH5+PrKystQ+T25uLnJycpQeRERERLpSYZKvPn36YNCgQfDy8kLPnj2xZ88eAMCmTZvU7iORKE9UL7y/24vrnxcWFgYbGxvFw9nZWQfRExERERWoMMnXi6pXrw4vLy8kJyer3C6VSpGRkaG0LjMzE9WqVUOdOuoH9IaEhCA7O1vxSEtL02ncREREVLVVqAH3z8vNzUViYiK6dOmicruPjw92796ttO7AgQPw9vaGiYmJ2uOamZnBzMxMp7ESERERFaowPV8ffPABIiMjkZKSglOnTuGNN95ATk4OxowZA6Cgx2r06NGK9pMmTcL169cRHByMxMREfPfdd1i/fj0++OADQ/0KRERERBWn5+uff/7B8OHDkZWVBTs7O3To0AEnT56Eq6srACA9PR2pqamK9u7u7ti7dy9mzJiBr7/+Gk5OTvjyyy9ZZoKIiIgMqsIkXz///HOx2zdu3Fhkna+vL86ePauniIiIiIi0V2EuOxIRERFVBlonX2fPnsWFCxcUy7/99hv69++POXPmIC8vT6fBEREREVU2Widf77zzDi5fvgwAuHr1KoYNGwZLS0ts27YNM2fO1HmARFS5yOQCUX/fxm9xNxD1923I5MLQIRERlSmtx3xdvnwZrVq1AgBs27YNXbt2xY8//ojjx49j2LBhinspEhEBBcnW6ZQ7yLz/BNeyHuGn06nIyHmi2O5oY455fT0R0NzRgFESEZUdrZMvIQTkcjkA4M8//8Rrr70GAHB2di72tj1EVPXsi0/H/N0JSM9+orZNRvYTvLvlLFaPbMMEjIiqBK0vO3p7e+M///kPvv/+e0RGRuLVV18FAKSkpBS5lyIRVV374tPx7pazxSZeAFB40XH+7gRegiSiKkHr5GvFihU4e/YsgoKCMHfuXDRs2BAA8Ouvv6Jjx446D5CIKh6ZXGD+7gRomkoJAOnZT3A65Y4+wyIiKhe0vuzYokULpdmOhb744gsYGxvrJCgiqthOp9wpscdLlcz72u9DRFTRlKrO17179/Dtt98iJCQEd+4U/KWakJCAzMxMnQZHRBVTaZMoeytzHUdCRFT+aN3zdf78efTo0QM1a9bEtWvXMHHiRNSuXRs7duzA9evXsXnzZn3ESUQViLZJlASA1MYc7dxr6ycgIqJyROuer+DgYLz11ltITk6GufmzL9g+ffrgyJEjOg2OiCqmdu614WhjDokGbQvbzOvrCWMjTfYgIqrYtE6+oqOj8c477xRZX7duXWRkZOgkKCKq+Ia94qLRgHupjTnLTBBRlaL1ZUdzc3Pk5OQUWZ+UlAQ7OzudBEVEFVdJtb2k1mYY3s4FbrbVYW9VcKmRPV5EVJVonXz169cPn376KX755RcAgEQiQWpqKmbPno1BgwbpPEAiqhhkcoGVh65g+Z+X1baZ0bMRgro3YrJFRFWa1pcdlyxZglu3bsHe3h6PHz+Gr68vGjZsCCsrK3z++ef6iJGIyjGZXOC/fyajzacHik28JAB+jk4r+YB37wLh4boL8P9WrVoFd3d3mJubo23btjh69KjathEREZBIJEUely5d0nlcRFT1aN3zZW1tjWPHjuHQoUM4e/Ys5HI52rRpg549e+ojPiIqx/aeT8fM8PN4kJtfYtvnC6n6NKijvPHpU2DfPmDzZmDXLiAvD7hyBWjQQCdxbt26FdOnT8eqVavQqVMnrF27Fn369EFCQgJcXFzU7peUlARra2vFModWEJEuaJ18FerevTu6d++uy1iIqIKQyQWm/RyL38+na72vogaYEEBsbEHC9eOPwK1bzxq1aAH8+6/Okq9ly5Zh/PjxmDBhAoCCO3Xs378fq1evRlhYmNr97O3tUbNmTZ3EQERUSKPk68svv9T4gFOnTi11MERUfsnkAqdT7uDAxXT8eDoVufmluw9j3Ud3gS9+BDZtAi5efLbBwQF4801g9GigZUsdRQ3k5eXhzJkzmD17ttJ6f39/nDhxoth9W7dujSdPnsDT0xMfffQR/Pz8dBYXEVVdGiVfy5cv1+hgEomEyRdRJVTSDMaSmD99gt7JJzH8UgTafnEWkMsLNpiZAf37FyRc/v5AtVJ3xquVlZUFmUwGBwcHpfUODg5qy+M4Ojpi3bp1aNu2LXJzc/H999+jR48eiIiIQNeuXVXuk5ubi9zcXMWyqlnhRESAhslXSkqKvuMgonJEJhc4+fdtHP/7FqJT7iD6+j2tjyERcrRLu4hB8X+hT9JxWOU9fraxc+eChGvwYKCMLutJJMozLIUQRdYV8vDwgIeHh2LZx8cHaWlpWLJkidrkKywsDPPnz9ddwERUaen+z0w9CQsLw/bt23Hp0iVYWFigY8eOWLRokdIX5IsiIiJUXiZITExEkyZN9BkuUYW1Lz4ds8Mv4N7jp6Xa3+3ODQyMP4SBFw+jXs6z+70+qucKywlvASNH6mwslyZsbW1hbGxcpJcrMzOzSG9YcTp06IAtW7ao3R4SEoLg4GDFck5ODpydnbUPmIgqPY2Sr+DgYHz22WeoXr260peLKsuWLdNJYC+KjIzElClT8MorryA/Px9z586Fv78/EhISUL169WL35YwlopLJ5AJf/ZWMFX8la72v9ZMH6Jt4BAPjD6HtzWflGHJMLXG952vwnBUEyy6dATU9TfpkamqKtm3b4uDBgxgwYIBi/cGDB9GvXz+NjxMbGwtHR/VV+M3MzGBmZvZSsRJR1aBR8hUbG4unT58qfjaEffv2KS1v2LAB9vb2OHPmjNrLAIU4Y4moeHvPp+PDX8/hYZ5M432qyfLhm3IGA+MPoeeVUzCTFZSbyJcY4Yh7G+xv2ws9Zk6Av3d9fYWtseDgYIwaNQre3t7w8fHBunXrkJqaikmTJgEo6LW6ceMGNm/eDKBgNqSbmxuaNWuGvLw8bNmyBeHh4QjXQ/0xIqp6NEq+Dh8+rPJnQ8rOzgYA1K5du8S2nLFEpF7Y3gSsPaLhuE4h0OzfvzEo/hBeT4yE7aNsxaZEOzf82rwHdnl2Q4eOTbFiWJtyU8l+6NChuH37Nj799FOkp6ejefPm2Lt3L1xdXQEA6enpSE1NVbTPy8vDBx98gBs3bsDCwgLNmjXDnj17EBgYaKhfgYgqEYkQQqv54uPGjcN///tfWFlZKa1/+PAh3nvvPXz33Xc6DVAVIQT69euHu3fvFlulOikpCUeOHFGasbRmzRqtZyw5OzsjOztb6dIlUWXwe9xNBP1ccm+2/f3b6J8QgYHxh9Ak67pi/a3qNbHTsxu2N++ORPv6qGFmjMWDWiCwhZPOYszJyYGNjU2F+wxqEvejvHx4frIfAJDwaW9YmlaYYbhE5V55/u7QOvkyNjZGeno67O3tldZnZWVBKpUiP7/kStcva8qUKdizZw+OHTuGevXqabVv3759IZFIsGvXLpXbQ0NDVc5YKo8vHlFp5eXLMevXOOyIU18k1fzpE/gnn8Sg+EPofC0OxqKgPESusQkONOqA8ObdcdS9DWRGxgCAvi2keuntKs9foMVh8kVkWOX5u0PjT3pOTg6EEBBC4P79+zA3N1dsk8lk2Lt3b5GETB/ee+897Nq1C0eOHNE68QI4Y4mqLplc4ERyFkJ/j8fftx6pbFNceYjT9TyxvVl37G3SGTnmNRTra1c3wX/6NddpbxcRUWWmcfJVs2ZNxc1lGzduXGS7RCLRa40bIQTee+897NixAxEREXB3dy/VcThjiaqax3kyTNwcjeNXbkNdN7e68hDXa0qxvVl37Gjmh9RaRT83M3o2QlD3RuVmbBcRUUWgcfJ1+PBhCCHQvXt3hIeHKw10NzU1haurK5yc9PeX75QpU/Djjz/it99+g5WVlaJmj42NDSwsLABwxhJRIZlc4FjSLUz7JRb3HqseClBceYjfm3bB9ubdEVPXU2V5iFqWJggb6IWA5ur/kCEiItU0Tr58fX0BFFS7d3Z2hpGRkd6CUmX16tUAgG7duimt37BhA8aOHQuAM5aIAGD3uZuYvjUWMnnRberKQ8gkRjji3hrhzXvgYMP2yDUp2vvbwM4SAc0d0bGBLTrUr8PeLiKiUtJ6dKerqyvu3buH06dPIzMzE3K58jf86NGjdRbc8zSZF7Bx40al5ZkzZ2LmzJl6iYeovJHJBd5YfRyxadnKGzQsD3GrRi2VxzU3McKywS05pouISEe0Tr52796NN998Ew8fPoSVlZXSvdEkEoneki8iKurBk3wEbTmNI1fu4sWOLk3LQxQnyK8BZvTyYC8XEZEOaZ18vf/++xg3bhwWLFgAS0tLfcRERMV4nCfDx7+dw69nipaJ0LY8RHHGd3bDB715D1QiIl3TOvm6ceMGpk6dysSLqIzl5cvR57+RRcpElKY8REl6edrj49ea6Sx2IiJ6Ruvkq3fv3oiJiUH9+oa/XxtRVZD96Cl6LDmErEfKsxZLWx6iOCZGwPIhrfBaq7o6iZ2IiIrSOvl69dVX8eGHHyIhIQFeXl4wMTFR2v7666/rLDiiqurBk3xM3nwSR64qD54vrjzEniadEe7VQ215iOI0sK2O0NeboWNDW47vIiLSM62Tr4kTJwIAPv300yLbJBIJZDLZy0dFVAU9eJKPdzdF4WhKjtL6lykPUZL2brXw/YQOMK1WtqVjiIiqMq2TrxdLSxBR6T3Ok2HO9rPYEZepvOEly0MUx9rcGEF+jTC2kzuTLiIiA+BdXIkMIOPeE3Rc+JdeykOoU8vCGCdCesHCtOSZjkREpD+lSr4ePnyIyMhIpKamIi8vT2nb1KlTdRIYUWXz4Ek+3tlwHMevP1Bar8vyEOqM7+yKj19r/lLxExGRbmidfMXGxiIwMBCPHj3Cw4cPUbt2bWRlZcHS0hL29vZMvoiec+POY3RdfAgvjoTUR3kIVRraWWLvNF9eXiQiKke0Tr5mzJiBvn37YvXq1ahZsyZOnjwJExMTjBw5EtOmTdNHjEQVSvajpxiy8hCS7hS9obW68hCpNg7Y3rw7tjfrrnV5iBfVtDBBQHMp5vVtxkuMRETlkNbJV1xcHNauXQtjY2MYGxsjNzcX9evXx+LFizFmzBgMHDhQH3ESlWtJN++j95dHVG7TV3mI59nWMMFfwX6wsTQpuTERERmU1smXiYmJ4n6ODg4OSE1NRdOmTWFjY4PU1FSdB0hUHqVkPoTfsgi12/VZHuJ59jWq4djsXrysSERUgWidfLVu3RoxMTFo3Lgx/Pz88MknnyArKwvff/89vLy89BEjkcE9zpPh/Z+isDcxW30jPZaHeJGntAZ+mdQJNcw5YZmIqKLR+pt7wYIFuH//PgDgs88+w5gxY/Duu++iYcOG2LBhg84DJDKkuGv30H/N8WLb6LM8xPNMjIGvh7dFD08HVqEnIqrAtE6+vL29FT/b2dlh7969Og2IyNAupGaj76pjxbYpi/IQhd5oUxef9ffi4HkiokqC1yyoynucJ8OMH45jX9L9YtuVVXkIAOja0BarRrblZUUiokpI6292d3d3xYB7Va5evfpSARGVhYR/chC48qhGbcuiPAQA2Ncwwb7p3VC7hulLH4uIiMovrZOv6dOnKy0/ffoUsbGx2LdvHz788ENdxUWkc2eu3sWgdSc0amv95AFeu3QUgy78pbfyEIX+O6QVXmvlxHFcRERVhNbJl7pCql9//TViYmJeOiAiXcnLl2PenrP4KepfjdqXVXkIAHCrY4nt73ZiLxcRURWkswElffr0QUhIiN5nPK5atQpffPEF0tPT0axZM6xYsQJdunRR2z4yMhLBwcG4ePEinJycMHPmTEyaNEmvMZLhaDJYXkkZloeY1LUBgv0bsyYXEVEVp7Pk69dff0Xt2rV1dTiVtm7diunTp2PVqlXo1KkT1q5diz59+iAhIQEuLi5F2qekpCAwMBATJ07Eli1bcPz4cUyePBl2dnYYNGiQXmOlspGXL8f8vbH44USGVvuVVXkIhxqm+H1qV9hZv3xvGRERVQ6lKrL6/IB7IQQyMjJw69YtrFq1SqfBvWjZsmUYP348JkyYAABYsWIF9u/fj9WrVyMsLKxI+zVr1sDFxQUrVqwAADRt2hQxMTFYsmQJk68KrLQJV1mUhzAC8MfUrvBwsir1MYiIqHLTOvnq37+/0rKRkRHs7OzQrVs3NGnSRFdxFZGXl4czZ85g9uzZSuv9/f1x4oTqQdRRUVHw9/dXWte7d2+sX78eT58+hYkJ74NXkWgzQ7FQYXmIgfGHEJh0TC/lIQKbO2DpkNasw0VEVEopWQ/xS0wa/rn7GPVqWWCItzPcbasbOiy90Tr5mjdvnj7iKFFWVhZkMhkcHByU1js4OCAjQ3UPSEZGhsr2+fn5yMrKgqNj0fIAubm5yM3NVSzn5OToIHoqLa3HcP2f250bGHDxMAZePAzn7GcD7nVRHoK9W0REuvNLTBpmh5+HRCKBEAISiQRrI//GokEtMNjb2dDh6YXWydeNGzcQHh6Oy5cvw9TUFB4eHhgyZAhq1Xr5AcmaeLHGWOELpU17VesLhYWFYf78+S8ZJb2MG3ceo9PiQ1rvp+/yEDsndUIrt5ql2pcMrzJM1on6+7babenZjxGRdAu3HuTCroYZunnYwdHGogyjI12rCq9pevZjzAo/DyEA/P//58J/Z4afRzUjI0htzIvs59OgThlGqXtaJV+rVq1CcHAw8vLyYGNjAyEEcnJyEBwcjG+//RbDhw+HEAJxcXFo3bq1TgO1tbWFsbFxkV6uzMzMIr1bhaRSqcr21apVQ506ql+4kJAQBAcHK5ZzcnLg7Fw5M+/yJOPeE3Rd+BfytNxP3+Uh5r/WDCM7urIGVwVX2SfrRCRlYt3Rq5AAEAAkAHafv4l3utaHb2P7Uh1Tl//xV4UkQtf08Zrqmi5e14ikW4rf8UUSAIeTMjG8XdHPaEWncfK1Z88eTJ06FdOnT8f777+vuGSXnp6OL774AmPGjIGzszNWrVqFJk2a6Dz5MjU1Rdu2bXHw4EEMGDBAsf7gwYPo16+fyn18fHywe/dupXUHDhyAt7e32vFeZmZmMDPjzLSyUNoeLn2Wh5AA2BPUBZ71rLWPi8qtyjxZJz37MdYdvQohnv0HVvjv2iNX4eFgrbLnoDi6/I+/IiQRuqSLhEQfr6muYiukq9f11oNclYkX/n/cWw9y1Wyt2DROvhYvXozZs2fjP//5j9J6R0dHLFu2DJaWlujVqxekUqnKLzNdCA4OxqhRo+Dt7Q0fHx+sW7cOqampiksBISEhuHHjBjZv3gwAmDRpElauXIng4GBMnDgRUVFRWL9+PX766Se9xEcle/AkHxO+PYKT/zwuufEL9FUeondTB6wYzgHzlZWhJ+s8ystHtbx8tdtU/azOk6eyIuv+TPy32J6Dg4kZGNxW8977jJwnxf7H71anOhysNfuPX5fHevG4R5Nv4faDPNSpYYoujewgLcVxdH2so8m3sOHEtSIJybiO7ujcyFbj4+j6NdVlbIBuX9dalibF/q61LE1Uvu81+bxo0sZQJKJwEFQJrK2tER0dDQ8PD5Xbk5KS0LRpU1y7dk1lN76urFq1CosXL0Z6ejqaN2+O5cuXo2vXrgCAsWPH4tq1a4iIiFC0j4yMxIwZMxTjNmbNmqXVuI2cnBzY2NggOzsb1tbsDSmt1KxH6LrksNb76as8xLxAT4zu7MbLiRXAy34Gb968ibp16+L48ePo2LGjYv2CBQuwadMmJCUlFdmncePGGDt2LObMmaNYd+LECXTq1Ak3b97UeLKOs7MznKf/AiMzS63jJqKXI899hLQVQ8rl/98a93zJ5fJi/9ozMTGBhYWFXhMvAJg8eTImT56sctvGjRuLrPP19cXZs2f1GhOpVtqES1/lIXZP7gwvFxut46HKgZN1iKi80Dj5atasGX777TfMmDFD5fadO3eiWbNmOguMKqaMe0/gt/AvaH9RUfflIXg5kQDDT9Y5PbeHzv7qPnX1TpF1GTlPMGfHBai6hiGRAGEDvLS6tLftTBr2xWdAruJ4RhIgoLlU40teujxWeY9tTeTfOH3tjtrXoZ1bbUzybaDRsXT9muoyNkD35w4A/s15giPPXf7t2siu2N+xff2S76iTk5MDxxVahVFmNE6+Jk+ejHfffRdmZmZ4++23Ua1awa75+flYu3YtPvroI71XuKfy6VZOLgKW/onbpRgXqevyECwHQS8y9GQdS9NqsDTVzZ3czE2K/iHhVqc63ulaH2uPKA9+FgDe6VofrnW0K1TZs6kD/ohXXTtRAOjVVKoyDn0fCwDuPnpa7ODsu4+eanw8XR4LAByszYsdu+Rgba7x8XT9muoyNkD3rysAuNapjlFa/F6afKbydfS50weNIxszZgwuXLiAoKAghISEoEGDgiz577//xoMHDzB16lSMHTtWX3FSOXMrJxd9lv2JrCfa76vr8hC8nEglqeyTdXwb28PDwRqHkzIVM9n8POxLNSPO0cai2P/4tTmmLo8FAHY1zIpNIuxqaD5TXZfHAoBuHnbYff6mym0CgJ+HdjM7dfma6jo2Xb+uVZFWaeGSJUvwxhtv4KeffkJycjIAoEuXLhg+fDg6dOiglwCpfMl+9BStPz0AubY76rg8xNgObpjzWlOYVjPSNhKqgoYOHYrbt2/j008/VUzW2bt3L1xdXQEUlMxJTU1VtHd3d8fevXsxY8YMfP3113BycsKXX35p8DITJRWWHNCmrs6eZ9grLtj63O1ehno7w60Ut3vR5bGkNub4XU0SAQDBvRprfFxdHquQTC4w64VK7UIILBrUotSvja5eU13HpsvXtSrSeLZjVcXZjsCdB3kY8NVhXM/WftquLstDfNa3OUb4uHCGYhVTUT+DFTXu8m5bTJraJELbW9Ho8liFrmU9LLcJSXmOTR/K82eQyVcJyvOLVxbafnoQtx9pV3del+Uh7GuYYM9UX9hZs/BtVVVRP4MVNe6KQJdJRFVLSKqS8vwZLL+j0chgZHKBQxcyMPEnzUt06LI8BBMuIiqOm211zApoUu6ORaQpJl+kZFtMGj789bzG7XVVHsJTaoWf3vaBjaXmlcOJiIgqIiZfBEC7gfS6Kg9hbAQc+aA76tbmDXaJiKjqKFXylZ+fj4iICPz9998YMWIErKyscPPmTVhbW6NGDe2qjpNhyeQCHRb8iVsPih/XpcvyEJO6NkCwf2POVCQioipJ6+Tr+vXrCAgIQGpqKnJzc9GrVy9YWVlh8eLFePLkCdasWaOPOEkPws/8g/e3nVPfQIflIYK6NcDUnky4iIiItE6+pk2bBm9vb5w7d07pNhsDBgzAhAkTdBoc6Z5MLnAkMRMTtsRApmaeq67KQzDhIiIiKkrr5OvYsWM4fvw4TE1Nlda7urrixo0bOguMdO+3uBuY/nOcyorOuigPIQEwoJUTPh/YgvdTJCIiUkPr5Esul0MmkxVZ/88//8DKykonQZFuPc6TodPCv3Dn0VOl9boqD+HlaImd73Vj8VMiIiINaJ189erVCytWrMC6desAABKJBA8ePMC8efMQGBio8wCp9B7nydBzaQRuZCvfgFEX5SGMAAxoXRf/GeDFXi4iIiItaJ18LV++HH5+fvD09MSTJ08wYsQIJCcnw9bWttzedLaqkckF3lh9HLFpzwbI66o8RPVqwPlPA9nLRUREVEpaJ19OTk6Ii4vDTz/9hLNnz0Iul2P8+PF48803YWHBek2GtvvcTbz3UywA3ZaHMAIQ81Ev1K5hWmJbIiIiUq9Udb4sLCwwbtw4jBs3TtfxkJZkcoETyVnYdiYVf17KxKNcGZplXsWgC3+9dHkIAKgmAc587M/K80RERDqiUfK1a9cujQ/4+uuvlzoY0s6++HQE/3IOj/JksL9/GyN1UB7ieec+YdJFRESkaxolX/3799foYBKJROVMSNK9ffHpmL7hxEuXh1ClW6Na2Di+oz7CJiIiqvI0Sr7kck3u+EdlQi6HLPII7k9fgOhLpS8PoUpNcyNEzfHn7EUiIiI9qhA31r527Ro+++wzHDp0CBkZGXBycsLIkSMxd+7cIsVenzd27Fhs2rRJaV379u1x8uRJfYese8nJwPffQ3z/PYyvXcPg/6/WpjyEOnUsqyFyZg/UMK8QbwciIqIKrVT/2/71119Yvnw5EhMTIZFI0KRJE0yfPh09e/bUdXwAgEuXLkEul2Pt2rVo2LAh4uPjMXHiRDx8+BBLliwpdt+AgABs2LBBsVxcslbu3L0L/PILsGkTEBUFoKCKvLblIdSRAPhqWCu81qqu7mImIiKiYmmdfK1cuRIzZszAG2+8gWnTpgEATp48icDAQCxbtgxBQUE6DzIgIAABAQGK5fr16yMpKQmrV68uMfkyMzODVCrVeUx68/QpsG8fsHkzsGsXkJcH4Fl5iO3NuuNAow4alYdQp6ZFNfx3WGt0bmTHel1ERERlTOvkKywsDMuXL1dKsqZOnYpOnTrh888/10vypUp2djZq165dYruIiAjY29ujZs2a8PX1xeeffw57e3u17XNzc5Gbm6tYzsnJ0Um8xRICiIsr6OH68Ufg1i3FphvODbGhYVf85tkNt2qU/PsWx9JEgjMf9+aYLiIiIgPSOvnKyclR6oUq5O/vj1mzZukkqJL8/fff+Oqrr7B06dJi2/Xp0weDBw+Gq6srUlJS8PHHH6N79+44c+YMzMxU9xyFhYVh/vz5+gi7qJs3gR9+KOjlio9/tt7BAVf9+2O6aXOct3XXyVO91ckF8/p66eRYREREVHoSIYTQZoc333wTrVq1wocffqi0fsmSJThz5oxWtxgKDQ0tMdGJjo6Gt7e3YvnmzZvw9fWFr68vvv32W21CR3p6OlxdXfHzzz9j4MCBKtuo6vlydnZGdnY2rK2ttXo+lR49AnbuLEi4Dh4ECmeSmpkB/fsDo0djQX49rDuR9vLPBaC9Wy18P6EDTKsZ6eR4RGUtJycHNjY2uvsMlpGKGjdRZVGeP4Na93w1bdoUn3/+OSIiIuDj4wOgYMzX8ePH8f777+PLL79UtJ06dWqxxwoKCsKwYcOKbePm5qb4+ebNm/Dz84OPj4/ixt7acHR0hKurK5KTk9W2MTMzU9srVmpyOXD0aEHCtW0bcP/+s22dOwOjRwODBwM1a+LzPRfxzYlrL/V01ubGCPJrhLGd3Jl0ERERlTNaJ1/r169HrVq1kJCQgISEBMX6mjVrYv369YpliURSYvJla2sLW1tbjZ73xo0b8PPzQ9u2bbFhwwYYGWmfVNy+fRtpaWlwdCxdSQat/b88BL7/Hrh27dl6d/eChGvUKKBBA8Xqvedv4puj14ocRhvdPezw3VvtXuoYREREpD9aJ18pKSn6iKNYN2/eRLdu3eDi4oIlS5bg1nMD0p+fydikSROEhYVhwIABePDgAUJDQzFo0CA4Ojri2rVrmDNnDmxtbTFgwAD9BauiPAQAwNoaGDKkIOnq3LlIeQiZXOCj3+LxMno0scX6sUy8iIiIyrMKUVXzwIEDuHLlCq5cuYJ69eopbXt+yFpSUhKyswtuJG1sbIwLFy5g8+bNuHfvHhwdHeHn54etW7fCyspKtwE+fQrs31+QcD1XHgJGRkDv3gUJV79+gIWF2kOcTrmDOw+fljqEiV3cMPfVZqXen4iIiMqG1gPuhRD49ddfcfjwYWRmZha59dD27dt1GqChqR2wV0x5CHh5AWPGACNGABpc4pTJBd5YfQKxafe0jq+Dey1sHs8B9VR5ledBs8WpqHETVRbl+TOodc/XtGnTsG7dOvj5+cHBwQGSUlZXr7CKKQ+BN98s6OVq2VLjw+09n44Pfz2Hh3na3ZCcSRcREVHFpHXytWXLFmzfvh2BgYH6iKf8CwwEzp0r+Pm58hDw9weqaX46ZXKBaT/H4vfz6Vo9vbmJEZYNbonAFk5a7UdERETlg9bJl42NDerXr6+PWCqGN98ErKyUykNoQyYXWHnoCtZEXsHjp/KSd3hOK2drhL/bmbcEIiIiqsC0Tr4KC6N+9913sChmAHml9cEHwAsFZjW1Lz4ds7dfwL1HpRtYPyvAk4kXERFRBaf1gKHBgwfj7t27sLe3h5eXF9q0aaP0qPRKOcZtX3w6Jm05W+rEq051U7Rzf7l7OxJVRXfv3sWoUaNgY2MDGxsbjBo1Cvfu3St2n7Fjx0IikSg9OnToUDYBE1Glp3XP19ixY3HmzBmMHDmyag64LwWZXCB0V0LJDYvxWb/m7PUiKoURI0bgn3/+wb59+wAAb7/9NkaNGoXdu3cXu19AQAA2bNigWDY1NdVrnERUdWidfO3Zswf79+9H586d9RFPpbTyUDIycp6Uev93urojsEUZVeUnqkQSExOxb98+nDx5Eu3btwcAfPPNN/Dx8UFSUhI8PDzU7mtmZqZUxJmISFe0vuzo7Oxc7upllGf74tOx/E/195IsTg0zY6wa0RohgZ46joqoaoiKioKNjY0i8QKADh06wMbGBidOnCh234iICNjb26Nx48aYOHEiMjMz9R0uEVURWidfS5cuxcyZM3Ht+XsVkkp5+XLM2VG6Wwb1bSHFuXm9WVKC6CVkZGTA3t6+yHp7e3tkZGSo3a9Pnz744YcfcOjQISxduhTR0dHo3r07cnNz1e6Tm5uLnJwcpQcRkSpaX3YcOXIkHj16hAYNGsDS0hImJiZK2+/cuaOz4CqyffHpmLPjgta3DKphZozFg1ow6SIqRuGs6+JER0cDgMpxqUKIYserDh06VPFz8+bN4e3tDVdXV+zZswcDBw5UuU9YWFiJMRERAaVIvlasWKGHMCqXffHpeHfLWWhz36bqpsZ4u2t9BHVvxIH1RCUICgrCsGHDim3j5uaG8+fP499//y2y7datW3BwcND4+RwdHeHq6orkZPVDCEJCQhAcHKxYzsnJgbOzs8bPQURVh9bJ15gxY/QRR6UhkwvM352gVeL1Rpt6WPRGCyZdRBqytbWFra1tie18fHyQnZ2N06dPo127dgCAU6dOITs7Gx07dtT4+W7fvo20tDQ4FnOvVjMzM5iZmWl8TCKqul7qxoCPHz/mGIcXnE65g/RszWc2Sq3NmHgR6UnTpk0REBCAiRMn4uTJkzh58iQmTpyI1157TWmmY5MmTbBjxw4AwIMHD/DBBx8gKioK165dQ0REBPr27QtbW1sMGDDAUL8KEVUiWidfDx8+RFBQEOzt7VGjRg3UqlVL6VHVZd7XPPGSAAh9vRkTLyI9+uGHH+Dl5QV/f3/4+/ujRYsW+P7775XaJCUlITs7GwBgbGyMCxcuoF+/fmjcuDHGjBmDxo0bIyoqClZWVob4FYioktH6suPMmTNx+PBhrFq1CqNHj8bXX3+NGzduYO3atVi4cKE+YqwQZHKB0yl3kPzvfY3a16luis8HNEdAc9bvItKn2rVrY8uWLcW2EeLZQAELCwvs379f32ERURWmdfK1e/dubN68Gd26dcO4cePQpUsXNGzYEK6urvjhhx/w5ptv6iPOcm1ffDrm707Q+HJj7eomiArpAdNqL3XVl4iIiCogrf/3v3PnDtzd3QEA1tbWitISnTt3xpEjR3QbXQVQOLNRk8RL8v/HggFeTLyIiIiqKK0zgPr16ysKrHp6euKXX34BUNAjVrNmTV3GVu5pO7NRamOO1SPb8FIjERFRFab1Zce33noL586dg6+vL0JCQvDqq6/iq6++Qn5+PpYtW6aPGMstTWc2Bvk1RKeGtmjnXpuD64mIiKo4rZOvGTNmKH728/NDYmIizpw5gwYNGqBly5Y6Da6803RmYyOHGvBpUEfP0RAREVFF8NIDj1xdXTFw4EC9J15ubm6QSCRKj9mzZxe7jxACoaGhcHJygoWFBbp164aLFy/qLCZ7K3OdtiMiIqLKT+Pk69SpU/jjjz+U1m3evBnu7u6wt7fH22+/XexNZ3Xh008/RXp6uuLx0UcfFdt+8eLFWLZsGVauXIno6GhIpVL06tUL9+9rVg6iJO3ca8PRxhzqLiRKADjamKOde22dPB8RERFVfBonX6GhoTh//rxi+cKFCxg/fjx69uyJ2bNnY/fu3QgLC9NLkIWsrKwglUoVjxo1aqhtK4TAihUrMHfuXAwcOBDNmzfHpk2b8OjRI/z44486icfYSIJ5fT0BoEgCVrg8r68nx3kRERGRgsbJV1xcHHr06KFY/vnnn9G+fXt88803CA4OxpdffqmY+agvixYtQp06ddCqVSt8/vnnyMvLU9s2JSUFGRkZ8Pf3V6wzMzODr68vTpw4oXa/3NxcrW6ZFNDcEatHtoHURvnSImc2EhERkSoaD7i/e/cuHBwcFMuRkZEICAhQLL/yyitIS0vTbXTPmTZtGtq0aYNatWrh9OnTCAkJQUpKCr799luV7TMyMgBAKebC5evXr6t9nrCwMMyfP1+r2AKaO6KXpxSnU+4g8/4T2FuZc2YjERERqaRxz5eDgwNSUlIAAHl5eTh79ix8fHwU2+/fvw8TExOtnjw0NLTIIPoXHzExMQAKZln6+vqiRYsWmDBhAtasWYP169fj9u3bxT6HRKKcAAkhiqx7XkhICLKzsxUPTRNKYyMJfBrUQb9WdeHToA4TLyIiIlJJ456vgIAAzJ49G4sWLcLOnTthaWmJLl26KLafP38eDRo00OrJg4KCMGzYsGLbuLm5qVzfoUMHAMCVK1dQp07RMg5SqRRAQQ+Yo+OzS3+ZmZlFesOeZ2ZmBjMzs5JCJyIiIioVjZOv//znPxg4cCB8fX1Ro0YNbNq0Caamport3333ndL4Kk3Y2trC1tZWq30KxcbGAoBSYvU8d3d3SKVSHDx4EK1btwZQ0GMXGRmJRYsWleo5iYiIiF6WxsmXnZ0djh49iuzsbNSoUQPGxsZK27dt21bs7MOXERUVhZMnT8LPzw82NjaIjo7GjBkz8Prrr8PFxUXRrkmTJggLC8OAAQMgkUgwffp0LFiwAI0aNUKjRo2wYMECWFpaYsSIEXqJk4iIiKgkWle4t7GxUbm+dm391bIyMzPD1q1bMX/+fOTm5sLV1RUTJ07EzJkzldolJSUhOztbsTxz5kw8fvwYkydPxt27d9G+fXscOHAAVlZWeouViIiIqDgSIYSm94WuknJycmBjY4Ps7GxYW1sbOhyiKqeifgYratxElUV5/gy+9O2FiIiIiEhzTL6IiIiIyhCTLyIiIqIyxOSLiIiIqAwx+SIiIiIqQ0y+iIiIiMoQky8iIiKiMqR1kdWqTCYXOJ1yB5n3n8Deyhzt3GvzBtpERESkFSZfGjqYkIElh6ORnv1Esc7Rxhzz+noioLnq+0sSERERvYiXHTUUvPWcUuIFABnZT/DulrPYF59uoKiIiIioomHypSFV92AqXDd/dwJkct6liYiIiErG5OslCQDp2U9wOuWOoUMhIiKiCoDJl45k3n9SciMiIiKq8ph86Yi9lbmhQyAiIqIKgLMdNaSuoIQEgNSmoOwEERERUUnY86WFFxOwwuV5fT1Z74uonPr888/RsWNHWFpaombNmhrtI4RAaGgonJycYGFhgW7duuHixYv6DZSIqgwmXxpaNrQlpDbKlxalNuZYPbIN63wRlWN5eXkYPHgw3n33XY33Wbx4MZYtW4aVK1ciOjoaUqkUvXr1wv379/UYKRFVFbzsqKFenlL0b9eIFe6JKpj58+cDADZu3KhReyEEVqxYgblz52LgwIEAgE2bNsHBwQE//vgj3nnnHX2FSkRVBHu+tGBsJIFPgzro16oufBrUYeJFVAmlpKQgIyMD/v7+inVmZmbw9fXFiRMnDBgZEVUW7PkqgRAFxVNzcnIMHAlR1VT42Sv8LOpbRkYGAMDBwUFpvYODA65fv652v9zcXOTm5iqWs7OzAfC7g8hQyvq7QxtMvkpQOMbD2dnZwJEQVW3379+HjY0NACA0NFRxOVGd6OhoeHt7l/r5JBLlnm0hRJF1zwsLC1MZE787iAzr+e+O8oLJVwmcnJyQlpYGKyurYr94y5OcnBw4OzsjLS0N1tbWhg7H4Hg+nqmI50IIgfv378PJyUmxLigoCMOGDSt2Pzc3t1I9n1QqBVDQA+bo+GwyTWZmZpHesOeFhIQgODhYsSyXy3Hnzh3UqVOn2O+OiviavKii/w4VPX6Av4Mqqr47ygsmXyUwMjJCvXr1DB1GqVhbW1fYD6E+8Hw8U9HOxYt/tdra2sLW1lYvz+Xu7g6pVIqDBw+idevWAApmTEZGRmLRokVq9zMzM4OZmZnSOk1LWwAV7zVRpaL/DhU9foC/w4vKW49XIQ64J6JKLTU1FXFxcUhNTYVMJkNcXBzi4uLw4MEDRZsmTZpgx44dAAouN06fPh0LFizAjh07EB8fj7Fjx8LS0hIjRoww1K9BRJUIe76IqFL75JNPsGnTJsVyYW/W4cOH0a1bNwBAUlKSYoA8AMycOROPHz/G5MmTcffuXbRv3x4HDhyAlZVVmcZORJUTk69KyMzMDPPmzStyCaSq4vl4piqei40bN5ZY4+vF2VASiQShoaEIDQ3VX2D/Vxlek4r+O1T0+AH+DhWNRJTHOZhERERElRTHfBERERGVISZfRERERGWIyRcRERFRGWLyRURERFSGmHxVYteuXcP48ePh7u4OCwsLNGjQAPPmzUNeXp6hQyszq1atgru7O8zNzdG2bVscPXrU0CEZRFhYGF555RVYWVnB3t4e/fv3R1JSkqHDqjK0fR9GRkaibdu2MDc3R/369bFmzZoyirSo0rx3IiIiIJFIijwuXbpURlE/ExoaWiSOwrsYqFOezj9QcLcGVedzypQpKtuXh/N/5MgR9O3bF05OTpBIJNi5c6fSdiEEQkND4eTkBAsLC3Tr1g0XL14s8bjh4eHw9PSEmZkZPD09FfX5KhomX5XYpUuXIJfLsXbtWly8eBHLly/HmjVrMGfOHEOHVia2bt2K6dOnY+7cuYiNjUWXLl3Qp08fpKamGjq0MhcZGYkpU6bg5MmTOHjwIPLz8+Hv74+HDx8aOrRKT9v3YUpKCgIDA9GlSxfExsZizpw5mDp1KsLDw8s48gIv895JSkpCenq64tGoUaMyiLioZs2aKcVx4cIFtW3L2/kHCu5T+nz8Bw8eBAAMHjy42P0Mef4fPnyIli1bYuXKlSq3L168GMuWLcPKlSsRHR0NqVSKXr16Ke6nrEpUVBSGDh2KUaNG4dy5cxg1ahSGDBmCU6dO6evX0B9BVcrixYuFu7u7ocMoE+3atROTJk1SWtekSRMxe/ZsA0VUfmRmZgoAIjIy0tChVHravg9nzpwpmjRporTunXfeER06dNBbjNrQ5L1z+PBhAUDcvXu37AJTY968eaJly5Yaty/v518IIaZNmyYaNGgg5HK5yu3l6fwLIQQAsWPHDsWyXC4XUqlULFy4ULHuyZMnwsbGRqxZs0btcYYMGSICAgKU1vXu3VsMGzZM5zHrG3u+qpjs7GzUrl3b0GHoXV5eHs6cOQN/f3+l9f7+/jhx4oSBoio/Cqu5V4X3giGV5n0YFRVVpH3v3r0RExODp0+f6i1WTWnz3mndujUcHR3Ro0cPHD58WN+hqZWcnAwnJye4u7tj2LBhuHr1qtq25f385+XlYcuWLRg3blyxN2wHys/5f1FKSgoyMjKUzrOZmRl8fX2L/X5W99pUxO90Jl9VyN9//42vvvoKkyZNMnQoepeVlQWZTAYHBwel9Q4ODsjIyDBQVOWDEALBwcHo3LkzmjdvbuhwKrXSvA8zMjJUts/Pz0dWVpbeYtWEpu8dR0dHrFu3DuHh4di+fTs8PDzQo0cPHDlypAyjLdC+fXts3rwZ+/fvxzfffIOMjAx07NgRt2/fVtm+PJ9/ANi5cyfu3buHsWPHqm1Tns6/KoXvfW2/n9W9NhXxO523F6qAQkNDMX/+/GLbREdHw9vbW7F88+ZNBAQEYPDgwZgwYYK+Qyw3XvzLUAhR4l+LlV1QUBDOnz+PY8eOGTqUKkPb96Gq9qrWlzVN3zseHh7w8PBQLPv4+CAtLQ1LlixB165d9R2mkj59+ih+9vLygo+PDxo0aIBNmzYhODhY5T7l9fwDwPr169GnTx84OTmpbVOezn9xSvP9XFm+05l8VUBBQUEYNmxYsW3c3NwUP9+8eRN+fn7w8fHBunXr9Bxd+WBrawtjY+MifxFlZmYW+cupKnnvvfewa9cuHDlyBPXq1TN0OJVead6HUqlUZftq1aqhTp06eou1JC/73unQoQO2bNmih8i0U716dXh5eSE5OVnl9vJ6/gHg+vXr+PPPP7F9+3at9y0v5x+AYrZpRkYGHB0dFetL+n5W99pUxO90XnasgGxtbdGkSZNiH+bm5gCAGzduoFu3bmjTpg02bNgAI6Oq8ZKbmpqibdu2illBhQ4ePIiOHTsaKCrDEUIgKCgI27dvx6FDh+Du7m7okKqE0rwPfXx8irQ/cOAAvL29YWJiordY1dHVeyc2NlbpP1pDyc3NRWJiotpYytv5f96GDRtgb2+PV199Vet9y8v5BwB3d3dIpVKl85yXl4fIyMhiv5/VvTYV8jvdUCP9Sf9u3LghGjZsKLp37y7++ecfkZ6ernhUBT///LMwMTER69evFwkJCWL69OmievXq4tq1a4YOrcy9++67wsbGRkRERCi9Dx49emTo0Cq9kt6Hs2fPFqNGjVK0v3r1qrC0tBQzZswQCQkJYv369cLExET8+uuvBolfk/fOi7/D8uXLxY4dO8Tly5dFfHy8mD17tgAgwsPDyzz+999/X0RERIirV6+KkydPitdee01YWVlVmPNfSCaTCRcXFzFr1qwi28rj+b9//76IjY0VsbGxAoBYtmyZiI2NFdevXxdCCLFw4UJhY2Mjtm/fLi5cuCCGDx8uHB0dRU5OjuIYo0aNUpoVfPz4cWFsbCwWLlwoEhMTxcKFC0W1atXEyZMny+z30hUmX5XYhg0bBACVj6ri66+/Fq6ursLU1FS0adOmypZWUPc+2LBhg6FDqxKKex+OGTNG+Pr6KrWPiIgQrVu3FqampsLNzU2sXr26jCN+RpP3zou/w6JFi0SDBg2Eubm5qFWrlujcubPYs2dP2QcvhBg6dKhwdHQUJiYmwsnJSQwcOFBcvHhRsb28n/9C+/fvFwBEUlJSkW3l8fwXlrt48TFmzBghREG5iXnz5gmpVCrMzMxE165dxYULF5SO4evrq2hfaNu2bcLDw0OYmJiIJk2aGCSh1wWJEP8fSUhEREREelc1BgARERERlRNMvoiIiIjKEJMvIiIiojLE5IuIiIioDDH5IiIiIipDTL6IiIiIyhCTLyIiIqIyxOSLiIiIqAwx+aoCrl27BolEgri4OEOHohU3NzesWLFCZ8fr1q0bpk+frrPjGZJEIsHOnTsBVNzXl4ioqmLyVcFJJJJiH2PHjjV0iCXauHEjatasWWR9dHQ03n777TKN5fHjx5g3bx48PDxgZmYGW1tbvPHGG7h48WKZxlEoNDQUrVq1KrI+PT0dffr0KfuAiIjopVUzdAD0ctLT0xU/b926FZ988gmSkpIU6ywsLHD37l1DhAaZTAaJRAIjo9Ll+HZ2djqOqHi5ubno2bMnUlNTsXTpUrRv3x7//vsvwsLC0L59e/z555/o0KFDmcakjlQqNXQIRERUSuz5quCkUqniYWNjA4lEUmRdoatXr8LPzw+WlpZo2bIloqKilI514sQJdO3aFRYWFnB2dsbUqVPx8OFDxfa7d+9i9OjRqFWrFiwtLdGnTx8kJycrthf2YP3+++/w9PSEmZkZrl+/jry8PMycORN169ZF9erV0b59e0RERAAAIiIi8NZbbyE7O1vRWxcaGgqg6GXHe/fu4e2334aDgwPMzc3RvHlz/P777wCA27dvY/jw4ahXrx4sLS3h5eWFn376SatzuWLFCkRFReH333/HkCFD4Orqinbt2iE8PBxNmzbF+PHjUXgrVFWXMPv376/U07hlyxZ4e3vDysoKUqkUI0aMQGZmpmJ7REQEJBIJ/vrrL3h7e8PS0hIdO3ZUJM8bN27E/Pnzce7cOcW52bhxIwDly46qJCQkIDAwEDVq1ICDgwNGjRqFrKwsxfZff/0VXl5esLCwQJ06ddCzZ0+l15qIiPSHyVcVMnfuXHzwwQeIi4tD48aNMXz4cOTn5wMALly4gN69e2PgwIE4f/48tm7dimPHjiEoKEix/9ixYxETE4Ndu3YhKioKQggEBgbi6dOnijaPHj1CWFgYvv32W1y8eBH29vZ46623cPz4cfz88884f/48Bg8ejICAACQnJ6Njx45YsWIFrK2tkZ6ejvT0dHzwwQdFYpfL5ejTpw9OnDiBLVu2ICEhAQsXLoSxsTEA4MmTJ2jbti1+//13xMfH4+2338aoUaNw6tQpjc/Pjz/+iF69eqFly5ZK642MjDBjxgwkJCTg3LlzGh8vLy8Pn332Gc6dO4edO3ciJSVF5WXguXPnYunSpYiJiUG1atUwbtw4AMDQoUPx/vvvo1mzZopzM3To0BKfNz09Hb6+vmjVqhViYmKwb98+/PvvvxgyZIhi+/DhwzFu3DgkJiYiIiICAwcOVCSWRESkZ4IqjQ0bNggbG5si61NSUgQA8e233yrWXbx4UQAQiYmJQgghRo0aJd5++22l/Y4ePSqMjIzE48ePxeXLlwUAcfz4ccX2rKwsYWFhIX755RfF8wMQcXFxijZXrlwREolE3LhxQ+nYPXr0ECEhIcXG7erqKpYvXy6EEGL//v3CyMhIJCUlaXw+AgMDxfvvv69Y9vX1FdOmTVPb3tzcXO32s2fPCgBi69atao/Vr18/MWbMGLXHP336tAAg7t+/L4QQ4vDhwwKA+PPPPxVt9uzZIwCIx48fCyGEmDdvnmjZsmWRYwEQO3bsEEI8e31jY2OFEEJ8/PHHwt/fX6l9WlqaACCSkpLEmTNnBABx7do1tbESEZH+cMxXFdKiRQvFz46OjgCAzMxMNGnSBGfOnMGVK1fwww8/KNoIISCXy5GSkoLk5GRUq1YN7du3V2yvU6cOPDw8kJiYqFhnamqq9Dxnz56FEAKNGzdWiiU3Nxd16tTROPa4uDjUq1evyHEKyWQyLFy4EFu3bsWNGzeQm5uL3NxcVK9eXePnKI74f6+QqampxvvExsYiNDQUcXFxuHPnDuRyOQAgNTUVnp6einbqXhcXF5dSxXrmzBkcPnwYNWrUKLLt77//hr+/P3r06AEvLy/07t0b/v7+eOONN1CrVq1SPR8REWmHyVcVYmJiovhZIpEAgCIhkMvleOeddzB16tQi+7m4uODy5csqjymEUBwLKBjg//yyXC6HsbExzpw5o7hEWEhVcqCOhYVFsduXLl2K5cuXY8WKFfDy8kL16tUxffp05OXlafwcjRo1QkJCgsptly5dAgBF8mdkZFTkMt3zl18fPnwIf39/+Pv7Y8uWLbCzs0Nqaip69+5dJKbiXpfSkMvl6Nu3LxYtWlRkm6OjI4yNjXHw4EGcOHECBw4cwFdffYW5c+fi1KlTcHd3L/XzEhGRZph8EQCgTZs2uHjxIho2bKhyu6enJ/Lz83Hq1Cl07NgRQMEg98uXL6Np06Zqj9u6dWvIZDJkZmaiS5cuKtuYmppCJpMVG1+LFi3wzz//4PLlyyp7v44ePYp+/fph5MiRAAoSkOTk5GJje9Hw4cMxd+5cnDt3Tmncl1wux/Lly+Ht7a3osbKzs1OaaSqTyRAfHw8/Pz8ABclaVlYWFi5cCGdnZwBATEyMxrEU0uTcvKhNmzYIDw+Hm5sbqlVT/RGXSCTo1KkTOnXqhE8++QSurq7YsWMHgoODtY6RiIi0wwH3BACYNWsWoqKiMGXKFMTFxSE5ORm7du3Ce++9B6CgV6hfv36YOHEijh07hnPnzmHkyJGoW7cu+vXrp/a4jRs3xptvvonRo0dj+/btSElJQXR0NBYtWoS9e/cCKJjV+ODBA/z111/IysrCo0ePihzH19cXXbt2xaBBg3Dw4EGkpKTgjz/+wL59+wAADRs2VPTmJCYm4p133kFGRoZW52DGjBlo164d+vbti23btiE1NRXR0dEYNGgQkpOTFTMNAaB79+7Ys2cP9uzZg0uXLmHy5Mm4d++eYruLiwtMTU3x1Vdf4erVq9i1axc+++wzreIpPDcpKSmIi4tDVlYWcnNzS9xnypQpuHPnDoYPH47Tp0/j6tWrOHDgAMaNGweZTIZTp05hwYIFiImJQWpqKrZv345bt25plagSEVHpMfkiAAU9S5GRkUhOTkaXLl3QunVrfPzxx4oxSACwYcMGtG3bFq+99hp8fHwghMDevXuVLpupsmHDBowePRrvv/8+PDw88Prrr+PUqVOKHqGOHTti0qRJGDp0KOzs7LB48WKVxwkPD8crr7yC4cOHw9PTEzNnzlT0Cn388cdo06YNevfujW7dukEqlaJ///5anQNzc3P89ddfGD16NEJCQtCgQQO0a9cO8fHxiI+PR7NmzRRtx40bhzFjxmD06NHw9fWFu7u7otcLKOgZ27hxI7Zt2wZPT08sXLgQS5Ys0SoeABg0aBACAgLg5+cHOzs7jcpnODk54fjx45DJZOjduzeaN2+OadOmwcbGBkZGRrC2tsaRI0cQGBiIxo0b46OPPsLSpUtZtJWIqIxIxIsDV4hI4Y8//sCAAQOwZMkSpbIbREREpcWeL6Ji9OnTB3/88Qfu3LmjVKSUiIiotNjzRURERFSG2PNFREREVIaYfBERERGVISZfRERERGWIyRcRERFRGWLyRURERFSGmHwRERERlSEmX0RERERliMkXERERURli8kVERERUhv4Hw5dFTaNcXYkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72daa797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2012-01-03    0.029356\n",
       "2012-01-04    0.022122\n",
       "2012-01-05    0.027620\n",
       "2012-01-06    0.001134\n",
       "2012-01-09    0.013514\n",
       "Name: log_rtn, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d059407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2012-01-03    0.028580\n",
       "2012-01-04    0.020277\n",
       "2012-01-05    0.026728\n",
       "2012-01-06   -0.000605\n",
       "2012-01-09    0.013357\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.resid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8a06272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be04afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample one-step-ahead\n",
    "forecast = results.get_prediction(start=-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f75a205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-11-24    0.000602\n",
       "2017-11-27    0.000860\n",
       "2017-11-28    0.000750\n",
       "2017-11-29    0.002142\n",
       "2017-11-30    0.000967\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.predicted_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "561f7a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-11-24', '2017-11-27', '2017-11-28', '2017-11-29',\n",
       "               '2017-11-30', '2017-12-01', '2017-12-04', '2017-12-05',\n",
       "               '2017-12-06', '2017-12-07', '2017-12-08', '2017-12-11',\n",
       "               '2017-12-12', '2017-12-13', '2017-12-14', '2017-12-15',\n",
       "               '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-21',\n",
       "               '2017-12-22', '2017-12-26', '2017-12-27', '2017-12-28',\n",
       "               '2017-12-29'],\n",
       "              dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.predicted_mean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb9624c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-11-24    0.000602\n",
       "2017-11-27    0.000884\n",
       "2017-11-28    0.000710\n",
       "2017-11-29    0.000817\n",
       "2017-11-30    0.000751\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-sample dymanic\n",
    "forecast_dynamic = results.get_prediction(start=-25, dynamic=True)\n",
    "forecast_dynamic.predicted_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4840c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df that have original ts, resid, in-sample one-step, and in-sample dynamic.\n",
    "check_arima = pd.concat([ts, results.resid, forecast.predicted_mean, forecast_dynamic.predicted_mean], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d5ad4494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508, 4)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_arima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31031651",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_arima.to_csv(\"../data/check_arima.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d93777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6185341])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.arparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "04abaccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65754322])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.maparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ac9f96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const     0.000776\n",
       "ar.L1    -0.618534\n",
       "ma.L1     0.657543\n",
       "sigma2    0.000283\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49a9175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.tsa.statespace.mlemodel.PredictionResultsWrapper at 0x1d5fc298940>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out-of-sample forecast\n",
    "out_sample_forecast = results.get_forecast(steps=20)\n",
    "out_sample_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "707a1bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508    0.000028\n",
       "1509    0.001239\n",
       "1510    0.000490\n",
       "1511    0.000953\n",
       "1512    0.000667\n",
       "1513    0.000844\n",
       "1514    0.000734\n",
       "1515    0.000802\n",
       "1516    0.000760\n",
       "1517    0.000786\n",
       "1518    0.000770\n",
       "1519    0.000780\n",
       "1520    0.000774\n",
       "1521    0.000778\n",
       "1522    0.000775\n",
       "1523    0.000777\n",
       "1524    0.000776\n",
       "1525    0.000776\n",
       "1526    0.000776\n",
       "1527    0.000776\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sample_forecast.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44107b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "885d9e18",
   "metadata": {},
   "source": [
    "# Step5 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbc9d2",
   "metadata": {},
   "source": [
    "## 5.1) Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd52a3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ----\n",
      "Main indices: [ 123  124  125 ... 1380 1381 1382]\n",
      "Valid indices: [1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396\n",
      " 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407]\n",
      "Fold 1 ----\n",
      "Main indices: [ 148  149  150 ... 1405 1406 1407]\n",
      "Valid indices: [1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421\n",
      " 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432]\n",
      "Fold 2 ----\n",
      "Main indices: [ 173  174  175 ... 1430 1431 1432]\n",
      "Valid indices: [1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446\n",
      " 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457]\n",
      "Fold 3 ----\n",
      "Main indices: [ 198  199  200 ... 1455 1456 1457]\n",
      "Valid indices: [1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471\n",
      " 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482]\n",
      "Fold 4 ----\n",
      "Main indices: [ 223  224  225 ... 1480 1481 1482]\n",
      "Valid indices: [1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496\n",
      " 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507]\n"
     ]
    }
   ],
   "source": [
    "# Code modified from book \"Python for Finance\"\n",
    "# Define the sliding window validation and print the indices of the folds\n",
    "sliding_cv = TimeSeriesSplit(n_splits=5, test_size=25, max_train_size=1260)\n",
    "\n",
    "for fold, (main_ind, valid_ind) in enumerate(sliding_cv.split(X_train)):\n",
    "    print(f\"Fold {fold} ----\")\n",
    "    print(f\"Main indices: {main_ind}\")\n",
    "    print(f\"Valid indices: {valid_ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc46a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a247d189",
   "metadata": {},
   "source": [
    "#### Explore RandomForestRegressor\n",
    "Fit model with default parameters on all train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ea53aad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492737015961273\n"
     ]
    }
   ],
   "source": [
    "# Fit model with default parameters on all train set \n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d1dc184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0853771334567146\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "95ac0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.8492737015961273\n",
      "Train mean_squared_error          : 4.277935454516461e-05\n",
      "Train roof of mean_squared_error  : 0.006540592828265998\n",
      "Train mean_absolute_error         : 0.004761531759683281\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train r-square                    :', r2_score(y_train, y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train, y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4cf32a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.0853771334567146\n",
      "Test mean_squared_error          : 0.00022349090295534248\n",
      "Test roof of mean_squared_error  : 0.014949612133943224\n",
      "Test mean_absolute_error         : 0.011219535932303673\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de090ce",
   "metadata": {},
   "source": [
    "One can see that the above model might overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef0368",
   "metadata": {},
   "source": [
    "#### Explore cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1202b001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.003285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093760</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.082207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.046412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>0.002541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.034050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error   test_r2\n",
       "0  0.082811    0.000000                    -0.000082  0.003285\n",
       "1  0.093760    0.015622                    -0.000245 -0.082207\n",
       "2  0.078106    0.000000                    -0.000104 -0.046412\n",
       "3  0.093728    0.000000                    -0.000198  0.002541\n",
       "4  0.093728    0.000000                    -0.000239 -0.034050"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_validate() for cross-validation:\n",
    "rf = RandomForestRegressor(n_estimators=50, max_features='auto', max_depth=1, random_state=12)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    rf, \n",
    "    X_train, y_train, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_squared_error\", \n",
    "             \"r2\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed2285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad900796",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21bb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d71032ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 100, 250, 500]\n",
      "['auto', 0.1, 0.3, 0.5]\n",
      "[1, 2, 5, 10, 20, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 100, 250, 500],\n",
       " 'max_features': ['auto', 0.1, 0.3, 0.5],\n",
       " 'max_depth': [1, 2, 5, 10, 20, None]}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 250, 500]\n",
    "max_features = ['auto', 0.1, 0.3, 0.5]\n",
    "max_depth = [1, 2, 5, 10, 20, None] \n",
    "\n",
    "print(n_estimators)\n",
    "print(max_features)\n",
    "print(max_depth)\n",
    "\n",
    "grid = {'n_estimators': n_estimators, \n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth\n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d70d2e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.718581</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>9.172146e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>-0.029654</td>\n",
       "      <td>-0.050036</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.032271</td>\n",
       "      <td>-0.022351</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.337420</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>5.722046e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>-0.030001</td>\n",
       "      <td>-0.053452</td>\n",
       "      <td>-0.002568</td>\n",
       "      <td>-0.034177</td>\n",
       "      <td>-0.022783</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.428024</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>7.653312e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>-0.036923</td>\n",
       "      <td>-0.049168</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>-0.022788</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.867392</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>1.239324e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>-0.045857</td>\n",
       "      <td>-0.000970</td>\n",
       "      <td>-0.032267</td>\n",
       "      <td>-0.022900</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.174959</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>6.248569e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>-0.041802</td>\n",
       "      <td>-0.050173</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.033135</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>7.652670e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>-0.061452</td>\n",
       "      <td>-0.044348</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.024205</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.782870</td>\n",
       "      <td>0.094315</td>\n",
       "      <td>0.046943</td>\n",
       "      <td>1.585491e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>-0.042540</td>\n",
       "      <td>-0.053354</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>-0.029328</td>\n",
       "      <td>-0.024511</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143715</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>1.169018e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>-0.027899</td>\n",
       "      <td>-0.062681</td>\n",
       "      <td>-0.003484</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.024929</td>\n",
       "      <td>0.024694</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069051</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>7.654228e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>-0.030789</td>\n",
       "      <td>-0.061860</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>-0.036449</td>\n",
       "      <td>-0.025075</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.376984</td>\n",
       "      <td>0.023455</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>1.001588e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>-0.040582</td>\n",
       "      <td>-0.057123</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.034686</td>\n",
       "      <td>-0.025832</td>\n",
       "      <td>0.023956</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.295080</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>1.845527e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.055253</td>\n",
       "      <td>-0.052125</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.034894</td>\n",
       "      <td>-0.028534</td>\n",
       "      <td>0.024154</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.143716</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>6.248426e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>-0.053270</td>\n",
       "      <td>-0.066645</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>-0.038935</td>\n",
       "      <td>-0.030605</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.070251</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>5.716898e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>-0.066690</td>\n",
       "      <td>-0.069479</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.030530</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156213</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>7.653079e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>-0.082207</td>\n",
       "      <td>-0.046412</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>-0.034050</td>\n",
       "      <td>-0.031369</td>\n",
       "      <td>0.032152</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.037046</td>\n",
       "      <td>0.086397</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>1.111295e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>-0.076797</td>\n",
       "      <td>-0.051368</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>-0.034783</td>\n",
       "      <td>-0.032419</td>\n",
       "      <td>0.029978</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.502199</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>3.001866e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>-0.085255</td>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.035262</td>\n",
       "      <td>-0.033862</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.042381</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.654052e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.090657</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-0.035888</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.387970</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.049988</td>\n",
       "      <td>6.248570e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.101749</td>\n",
       "      <td>-0.049511</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>-0.037402</td>\n",
       "      <td>-0.037905</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.515504</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>6.248879e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>-0.110562</td>\n",
       "      <td>-0.063046</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.029540</td>\n",
       "      <td>-0.039660</td>\n",
       "      <td>0.042944</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.652650e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>-0.104777</td>\n",
       "      <td>-0.080506</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.026759</td>\n",
       "      <td>-0.041649</td>\n",
       "      <td>0.043933</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.113042</td>\n",
       "      <td>0.098241</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>1.269183e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>-0.134717</td>\n",
       "      <td>-0.062182</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.033319</td>\n",
       "      <td>-0.045640</td>\n",
       "      <td>0.050427</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.877919</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>1.177701e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>-0.126662</td>\n",
       "      <td>-0.082159</td>\n",
       "      <td>-0.008940</td>\n",
       "      <td>-0.023652</td>\n",
       "      <td>-0.047058</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.159338</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>6.248569e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.009512</td>\n",
       "      <td>-0.134761</td>\n",
       "      <td>-0.078987</td>\n",
       "      <td>-0.015276</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>-0.047588</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>2.911561e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>-0.152468</td>\n",
       "      <td>-0.058098</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>-0.031059</td>\n",
       "      <td>-0.048466</td>\n",
       "      <td>0.056301</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.090603</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>7.653020e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>-0.161420</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>-0.028694</td>\n",
       "      <td>-0.028626</td>\n",
       "      <td>-0.053200</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.295406</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.248403e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.211422</td>\n",
       "      <td>-0.062445</td>\n",
       "      <td>-0.002077</td>\n",
       "      <td>-0.033398</td>\n",
       "      <td>-0.061866</td>\n",
       "      <td>0.078207</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.221981</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>6.248522e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>-0.215801</td>\n",
       "      <td>-0.075944</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.027284</td>\n",
       "      <td>-0.063136</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.690759</td>\n",
       "      <td>0.057098</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.653020e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.264307</td>\n",
       "      <td>-0.053432</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.071279</td>\n",
       "      <td>0.098624</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.099210</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>6.339674e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>-0.149134</td>\n",
       "      <td>-0.240451</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>-0.071858</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.704439</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.023271</td>\n",
       "      <td>3.895647e-03</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.094597</td>\n",
       "      <td>-0.221562</td>\n",
       "      <td>-0.193437</td>\n",
       "      <td>-0.045918</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>-0.074205</td>\n",
       "      <td>0.118368</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.518942</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>6.248331e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>-0.161190</td>\n",
       "      <td>-0.190064</td>\n",
       "      <td>-0.014002</td>\n",
       "      <td>-0.015294</td>\n",
       "      <td>-0.074710</td>\n",
       "      <td>0.083280</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.024760</td>\n",
       "      <td>0.018745</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>3.234067e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.192222</td>\n",
       "      <td>-0.164119</td>\n",
       "      <td>-0.012694</td>\n",
       "      <td>-0.034772</td>\n",
       "      <td>-0.079139</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.121846</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>6.248760e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>-0.316050</td>\n",
       "      <td>-0.084104</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>-0.016449</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0.121543</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.281183</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.652942e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>-0.002751</td>\n",
       "      <td>-0.327556</td>\n",
       "      <td>-0.061455</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.031560</td>\n",
       "      <td>-0.086054</td>\n",
       "      <td>0.122552</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.207455</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>7.066386e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>-0.010684</td>\n",
       "      <td>-0.169428</td>\n",
       "      <td>-0.232308</td>\n",
       "      <td>-0.016473</td>\n",
       "      <td>-0.005157</td>\n",
       "      <td>-0.086810</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.743385</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>7.021358e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.1, 'n_es...</td>\n",
       "      <td>0.131232</td>\n",
       "      <td>-0.256800</td>\n",
       "      <td>-0.226768</td>\n",
       "      <td>-0.043762</td>\n",
       "      <td>-0.050807</td>\n",
       "      <td>-0.089381</td>\n",
       "      <td>0.140815</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.489236</td>\n",
       "      <td>0.026868</td>\n",
       "      <td>0.049980</td>\n",
       "      <td>7.403066e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.1, 'n_es...</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>-0.272450</td>\n",
       "      <td>-0.224307</td>\n",
       "      <td>-0.036024</td>\n",
       "      <td>-0.041344</td>\n",
       "      <td>-0.094010</td>\n",
       "      <td>0.137253</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.099977</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.652709e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>-0.393741</td>\n",
       "      <td>-0.058871</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>-0.024665</td>\n",
       "      <td>-0.094117</td>\n",
       "      <td>0.151556</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.428085</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>1.323261e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>-0.393492</td>\n",
       "      <td>-0.061078</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>-0.032724</td>\n",
       "      <td>-0.096376</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.438662</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>0.051055</td>\n",
       "      <td>8.381891e-03</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.088747</td>\n",
       "      <td>-0.260504</td>\n",
       "      <td>-0.204001</td>\n",
       "      <td>-0.059457</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>-0.096518</td>\n",
       "      <td>0.123738</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.129221</td>\n",
       "      <td>0.093274</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>6.248498e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>-0.382328</td>\n",
       "      <td>-0.059870</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.040672</td>\n",
       "      <td>-0.096699</td>\n",
       "      <td>0.144680</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.075996</td>\n",
       "      <td>0.046338</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.652942e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-0.408430</td>\n",
       "      <td>-0.059174</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.037996</td>\n",
       "      <td>-0.100961</td>\n",
       "      <td>0.155432</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.849800</td>\n",
       "      <td>0.076910</td>\n",
       "      <td>0.028119</td>\n",
       "      <td>6.248498e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>-0.417512</td>\n",
       "      <td>-0.092597</td>\n",
       "      <td>-0.011800</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>-0.113284</td>\n",
       "      <td>0.155331</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.284518</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>2.725763e-03</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.049376</td>\n",
       "      <td>-0.265994</td>\n",
       "      <td>-0.310110</td>\n",
       "      <td>-0.080795</td>\n",
       "      <td>-0.036398</td>\n",
       "      <td>-0.128784</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.624619</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.049988</td>\n",
       "      <td>1.169000e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>-0.486078</td>\n",
       "      <td>-0.100948</td>\n",
       "      <td>-0.012109</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.128908</td>\n",
       "      <td>0.181865</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.308893</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>8.073880e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.1, 'n_es...</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>-0.294375</td>\n",
       "      <td>-0.269450</td>\n",
       "      <td>-0.044112</td>\n",
       "      <td>-0.110750</td>\n",
       "      <td>-0.129940</td>\n",
       "      <td>0.136973</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>6.248665e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.1, 'n_es...</td>\n",
       "      <td>0.081726</td>\n",
       "      <td>-0.187939</td>\n",
       "      <td>-0.455587</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>-0.084798</td>\n",
       "      <td>-0.130577</td>\n",
       "      <td>0.185223</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.141494</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>4.985898e-03</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.1, 'n_esti...</td>\n",
       "      <td>0.108712</td>\n",
       "      <td>-0.274580</td>\n",
       "      <td>-0.311086</td>\n",
       "      <td>-0.168191</td>\n",
       "      <td>-0.038829</td>\n",
       "      <td>-0.136795</td>\n",
       "      <td>0.155060</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.221697</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>5.046329e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>-0.594241</td>\n",
       "      <td>-0.065759</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>-0.037899</td>\n",
       "      <td>-0.137590</td>\n",
       "      <td>0.229914</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.146840</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.652709e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>-0.004152</td>\n",
       "      <td>-0.707199</td>\n",
       "      <td>-0.065285</td>\n",
       "      <td>-0.005604</td>\n",
       "      <td>-0.033884</td>\n",
       "      <td>-0.163225</td>\n",
       "      <td>0.272902</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        0.718581      0.017112         0.046864    9.172146e-07   \n",
       "6        0.337420      0.012496         0.031242    5.722046e-07   \n",
       "10       0.428024      0.007653         0.021870    7.653312e-03   \n",
       "11       0.867392      0.012963         0.050438    1.239324e-02   \n",
       "9        0.174959      0.006248         0.003124    6.248569e-03   \n",
       "8        0.090604      0.006248         0.006248    7.652670e-03   \n",
       "23       0.782870      0.094315         0.046943    1.585491e-04   \n",
       "5        0.143715      0.006249         0.012497    1.169018e-02   \n",
       "4        0.069051      0.007729         0.009374    7.654228e-03   \n",
       "22       0.376984      0.023455         0.030421    1.001588e-02   \n",
       "1        0.295080      0.013166         0.014699    1.845527e-03   \n",
       "21       0.143716      0.015306         0.012497    6.248426e-03   \n",
       "20       0.070251      0.006372         0.005518    5.716898e-03   \n",
       "0        0.156213      0.009880         0.006249    7.653079e-03   \n",
       "15       1.037046      0.086397         0.049667    1.111295e-02   \n",
       "14       0.502199      0.012759         0.026144    3.001866e-03   \n",
       "2        0.737327      0.042381         0.024994    7.654052e-03   \n",
       "3        1.387970      0.022959         0.049988    6.248570e-03   \n",
       "26       0.515504      0.009880         0.018746    6.248879e-03   \n",
       "38       0.412403      0.007653         0.024994    7.652650e-03   \n",
       "27       1.113042      0.098241         0.055989    1.269183e-02   \n",
       "39       0.877919      0.038771         0.046864    1.177701e-06   \n",
       "37       0.159338      0.006249         0.012497    6.248569e-03   \n",
       "13       0.213100      0.013060         0.012278    2.911561e-03   \n",
       "36       0.090603      0.011690         0.006249    7.653020e-03   \n",
       "31       1.295406      0.014350         0.043740    6.248403e-03   \n",
       "25       0.221981      0.022884         0.012497    6.248522e-03   \n",
       "30       0.690759      0.057098         0.024994    7.653020e-03   \n",
       "52       0.099210      0.008923         0.010769    6.339674e-03   \n",
       "70       0.704439      0.008355         0.023271    3.895647e-03   \n",
       "54       0.518942      0.011610         0.028118    6.248331e-03   \n",
       "55       1.024760      0.018745         0.046864    3.234067e-07   \n",
       "24       0.121846      0.015305         0.003124    6.248760e-03   \n",
       "29       0.281183      0.024201         0.009373    7.652942e-03   \n",
       "53       0.207455      0.006124         0.008273    7.066386e-03   \n",
       "86       0.743385      0.008684         0.023722    7.021358e-03   \n",
       "87       1.489236      0.026868         0.049980    7.403066e-03   \n",
       "12       0.099977      0.007653         0.009373    7.652709e-03   \n",
       "17       0.428085      0.019615         0.011768    1.323261e-03   \n",
       "71       1.438662      0.034544         0.051055    8.381891e-03   \n",
       "19       2.129221      0.093274         0.049989    6.248498e-03   \n",
       "18       1.075996      0.046338         0.024994    7.652942e-03   \n",
       "42       0.849800      0.076910         0.028119    6.248498e-03   \n",
       "69       0.284518      0.002460         0.013373    2.725763e-03   \n",
       "43       1.624619      0.123399         0.049988    1.169000e-02   \n",
       "85       0.308893      0.011539         0.011279    8.073880e-04   \n",
       "84       0.148368      0.006986         0.003124    6.248665e-03   \n",
       "68       0.141494      0.010536         0.007114    4.985898e-03   \n",
       "16       0.221697      0.009396         0.008976    5.046329e-03   \n",
       "28       0.146840      0.012497         0.009373    7.652709e-03   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "7                1                0.1                500   \n",
       "6                1                0.1                250   \n",
       "10               1                0.3                250   \n",
       "11               1                0.3                500   \n",
       "9                1                0.3                100   \n",
       "8                1                0.3                 50   \n",
       "23               2                0.1                500   \n",
       "5                1                0.1                100   \n",
       "4                1                0.1                 50   \n",
       "22               2                0.1                250   \n",
       "1                1               auto                100   \n",
       "21               2                0.1                100   \n",
       "20               2                0.1                 50   \n",
       "0                1               auto                 50   \n",
       "15               1                0.5                500   \n",
       "14               1                0.5                250   \n",
       "2                1               auto                250   \n",
       "3                1               auto                500   \n",
       "26               2                0.3                250   \n",
       "38               5                0.1                250   \n",
       "27               2                0.3                500   \n",
       "39               5                0.1                500   \n",
       "37               5                0.1                100   \n",
       "13               1                0.5                100   \n",
       "36               5                0.1                 50   \n",
       "31               2                0.5                500   \n",
       "25               2                0.3                100   \n",
       "30               2                0.5                250   \n",
       "52              10                0.1                 50   \n",
       "70              20                0.1                250   \n",
       "54              10                0.1                250   \n",
       "55              10                0.1                500   \n",
       "24               2                0.3                 50   \n",
       "29               2                0.5                100   \n",
       "53              10                0.1                100   \n",
       "86            None                0.1                250   \n",
       "87            None                0.1                500   \n",
       "12               1                0.5                 50   \n",
       "17               2               auto                100   \n",
       "71              20                0.1                500   \n",
       "19               2               auto                500   \n",
       "18               2               auto                250   \n",
       "42               5                0.3                250   \n",
       "69              20                0.1                100   \n",
       "43               5                0.3                500   \n",
       "85            None                0.1                100   \n",
       "84            None                0.1                 50   \n",
       "68              20                0.1                 50   \n",
       "16               2               auto                 50   \n",
       "28               2                0.5                 50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "7   {'max_depth': 1, 'max_features': 0.1, 'n_estim...           0.001573   \n",
       "6   {'max_depth': 1, 'max_features': 0.1, 'n_estim...           0.006285   \n",
       "10  {'max_depth': 1, 'max_features': 0.3, 'n_estim...           0.004321   \n",
       "11  {'max_depth': 1, 'max_features': 0.3, 'n_estim...           0.002008   \n",
       "9   {'max_depth': 1, 'max_features': 0.3, 'n_estim...           0.007041   \n",
       "8   {'max_depth': 1, 'max_features': 0.3, 'n_estim...           0.009487   \n",
       "23  {'max_depth': 2, 'max_features': 0.1, 'n_estim...           0.005542   \n",
       "5   {'max_depth': 1, 'max_features': 0.1, 'n_estim...           0.006725   \n",
       "4   {'max_depth': 1, 'max_features': 0.1, 'n_estim...           0.007265   \n",
       "22  {'max_depth': 2, 'max_features': 0.1, 'n_estim...           0.008233   \n",
       "1   {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.000222   \n",
       "21  {'max_depth': 2, 'max_features': 0.1, 'n_estim...           0.013672   \n",
       "20  {'max_depth': 2, 'max_features': 0.1, 'n_estim...           0.014957   \n",
       "0   {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.003285   \n",
       "15  {'max_depth': 1, 'max_features': 0.5, 'n_estim...           0.001326   \n",
       "14  {'max_depth': 1, 'max_features': 0.5, 'n_estim...           0.003348   \n",
       "2   {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.000629   \n",
       "3   {'max_depth': 1, 'max_features': 'auto', 'n_es...          -0.000284   \n",
       "26  {'max_depth': 2, 'max_features': 0.3, 'n_estim...           0.003457   \n",
       "38  {'max_depth': 5, 'max_features': 0.1, 'n_estim...           0.010299   \n",
       "27  {'max_depth': 2, 'max_features': 0.3, 'n_estim...           0.001946   \n",
       "39  {'max_depth': 5, 'max_features': 0.1, 'n_estim...           0.006124   \n",
       "37  {'max_depth': 5, 'max_features': 0.1, 'n_estim...           0.009512   \n",
       "13  {'max_depth': 1, 'max_features': 0.5, 'n_estim...           0.001491   \n",
       "36  {'max_depth': 5, 'max_features': 0.1, 'n_estim...           0.011365   \n",
       "31  {'max_depth': 2, 'max_features': 0.5, 'n_estim...           0.000013   \n",
       "25  {'max_depth': 2, 'max_features': 0.3, 'n_estim...           0.004180   \n",
       "30  {'max_depth': 2, 'max_features': 0.5, 'n_estim...          -0.000978   \n",
       "52  {'max_depth': 10, 'max_features': 0.1, 'n_esti...           0.011440   \n",
       "70  {'max_depth': 20, 'max_features': 0.1, 'n_esti...           0.094597   \n",
       "54  {'max_depth': 10, 'max_features': 0.1, 'n_esti...           0.006999   \n",
       "55  {'max_depth': 10, 'max_features': 0.1, 'n_esti...           0.008113   \n",
       "24  {'max_depth': 2, 'max_features': 0.3, 'n_estim...           0.003970   \n",
       "29  {'max_depth': 2, 'max_features': 0.5, 'n_estim...          -0.002751   \n",
       "53  {'max_depth': 10, 'max_features': 0.1, 'n_esti...          -0.010684   \n",
       "86  {'max_depth': None, 'max_features': 0.1, 'n_es...           0.131232   \n",
       "87  {'max_depth': None, 'max_features': 0.1, 'n_es...           0.104075   \n",
       "12  {'max_depth': 1, 'max_features': 0.5, 'n_estim...           0.005276   \n",
       "17  {'max_depth': 2, 'max_features': 'auto', 'n_es...           0.005178   \n",
       "71  {'max_depth': 20, 'max_features': 0.1, 'n_esti...           0.088747   \n",
       "19  {'max_depth': 2, 'max_features': 'auto', 'n_es...           0.000130   \n",
       "18  {'max_depth': 2, 'max_features': 'auto', 'n_es...          -0.000457   \n",
       "42  {'max_depth': 5, 'max_features': 0.3, 'n_estim...          -0.002455   \n",
       "69  {'max_depth': 20, 'max_features': 0.1, 'n_esti...           0.049376   \n",
       "43  {'max_depth': 5, 'max_features': 0.3, 'n_estim...          -0.002429   \n",
       "85  {'max_depth': None, 'max_features': 0.1, 'n_es...           0.068987   \n",
       "84  {'max_depth': None, 'max_features': 0.1, 'n_es...           0.081726   \n",
       "68  {'max_depth': 20, 'max_features': 0.1, 'n_esti...           0.108712   \n",
       "16  {'max_depth': 2, 'max_features': 'auto', 'n_es...           0.008583   \n",
       "28  {'max_depth': 2, 'max_features': 0.5, 'n_estim...          -0.004152   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7           -0.029654          -0.050036          -0.001368   \n",
       "6           -0.030001          -0.053452          -0.002568   \n",
       "10          -0.036923          -0.049168          -0.002131   \n",
       "11          -0.037414          -0.045857          -0.000970   \n",
       "9           -0.041802          -0.050173          -0.002187   \n",
       "8           -0.061452          -0.044348           0.000348   \n",
       "23          -0.042540          -0.053354          -0.002875   \n",
       "5           -0.027899          -0.062681          -0.003484   \n",
       "4           -0.030789          -0.061860          -0.003544   \n",
       "22          -0.040582          -0.057123          -0.005003   \n",
       "1           -0.055253          -0.052125          -0.000620   \n",
       "21          -0.053270          -0.066645          -0.007846   \n",
       "20          -0.066690          -0.069479          -0.005016   \n",
       "0           -0.082207          -0.046412           0.002541   \n",
       "15          -0.076797          -0.051368          -0.000472   \n",
       "14          -0.085255          -0.051540          -0.000600   \n",
       "2           -0.090657          -0.050505          -0.000714   \n",
       "3           -0.101749          -0.049511          -0.000581   \n",
       "26          -0.110562          -0.063046           0.001392   \n",
       "38          -0.104777          -0.080506          -0.006502   \n",
       "27          -0.134717          -0.062182           0.000073   \n",
       "39          -0.126662          -0.082159          -0.008940   \n",
       "37          -0.134761          -0.078987          -0.015276   \n",
       "13          -0.152468          -0.058098          -0.002194   \n",
       "36          -0.161420          -0.058626          -0.028694   \n",
       "31          -0.211422          -0.062445          -0.002077   \n",
       "25          -0.215801          -0.075944          -0.000833   \n",
       "30          -0.264307          -0.053432          -0.001330   \n",
       "52          -0.149134          -0.240451          -0.005070   \n",
       "70          -0.221562          -0.193437          -0.045918   \n",
       "54          -0.161190          -0.190064          -0.014002   \n",
       "55          -0.192222          -0.164119          -0.012694   \n",
       "24          -0.316050          -0.084104           0.003977   \n",
       "29          -0.327556          -0.061455          -0.006947   \n",
       "53          -0.169428          -0.232308          -0.016473   \n",
       "86          -0.256800          -0.226768          -0.043762   \n",
       "87          -0.272450          -0.224307          -0.036024   \n",
       "12          -0.393741          -0.058871           0.001416   \n",
       "17          -0.393492          -0.061078           0.000238   \n",
       "71          -0.260504          -0.204001          -0.059457   \n",
       "19          -0.382328          -0.059870          -0.000753   \n",
       "18          -0.408430          -0.059174           0.001252   \n",
       "42          -0.417512          -0.092597          -0.011800   \n",
       "69          -0.265994          -0.310110          -0.080795   \n",
       "43          -0.486078          -0.100948          -0.012109   \n",
       "85          -0.294375          -0.269450          -0.044112   \n",
       "84          -0.187939          -0.455587          -0.006290   \n",
       "68          -0.274580          -0.311086          -0.168191   \n",
       "16          -0.594241          -0.065759           0.001365   \n",
       "28          -0.707199          -0.065285          -0.005604   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7           -0.032271        -0.022351        0.019651                1  \n",
       "6           -0.034177        -0.022783        0.021799                2  \n",
       "10          -0.030039        -0.022788        0.020542                3  \n",
       "11          -0.032267        -0.022900        0.019630                4  \n",
       "9           -0.033135        -0.024051        0.022471                5  \n",
       "8           -0.025060        -0.024205        0.026578                6  \n",
       "23          -0.029328        -0.024511        0.022590                7  \n",
       "5           -0.037304        -0.024929        0.024694                8  \n",
       "4           -0.036449        -0.025075        0.024595                9  \n",
       "22          -0.034686        -0.025832        0.023956               10  \n",
       "1           -0.034894        -0.028534        0.024154               11  \n",
       "21          -0.038935        -0.030605        0.029531               12  \n",
       "20          -0.030530        -0.031352        0.033290               13  \n",
       "0           -0.034050        -0.031369        0.032152               14  \n",
       "15          -0.034783        -0.032419        0.029978               15  \n",
       "14          -0.035262        -0.033862        0.033005               16  \n",
       "2           -0.038195        -0.035888        0.034028               17  \n",
       "3           -0.037402        -0.037905        0.037469               18  \n",
       "26          -0.029540        -0.039660        0.042944               19  \n",
       "38          -0.026759        -0.041649        0.043933               20  \n",
       "27          -0.033319        -0.045640        0.050427               21  \n",
       "39          -0.023652        -0.047058        0.049796               22  \n",
       "37          -0.018429        -0.047588        0.052421               23  \n",
       "13          -0.031059        -0.048466        0.056301               24  \n",
       "36          -0.028626        -0.053200        0.058505               25  \n",
       "31          -0.033398        -0.061866        0.078207               26  \n",
       "25          -0.027284        -0.063136        0.081448               27  \n",
       "30          -0.036347        -0.071279        0.098624               28  \n",
       "52           0.023926        -0.071858        0.104851               29  \n",
       "70          -0.004705        -0.074205        0.118368               30  \n",
       "54          -0.015294        -0.074710        0.083280               31  \n",
       "55          -0.034772        -0.079139        0.082469               32  \n",
       "24          -0.016449        -0.081731        0.121543               33  \n",
       "29          -0.031560        -0.086054        0.122552               34  \n",
       "53          -0.005157        -0.086810        0.095295               35  \n",
       "86          -0.050807        -0.089381        0.140815               36  \n",
       "87          -0.041344        -0.094010        0.137253               37  \n",
       "12          -0.024665        -0.094117        0.151556               38  \n",
       "17          -0.032724        -0.096376        0.150481               39  \n",
       "71          -0.047376        -0.096518        0.123738               40  \n",
       "19          -0.040672        -0.096699        0.144680               41  \n",
       "18          -0.037996        -0.100961        0.155432               42  \n",
       "42          -0.042057        -0.113284        0.155331               43  \n",
       "69          -0.036398        -0.128784        0.137321               44  \n",
       "43          -0.042975        -0.128908        0.181865               45  \n",
       "85          -0.110750        -0.129940        0.136973               46  \n",
       "84          -0.084798        -0.130577        0.185223               47  \n",
       "68          -0.038829        -0.136795        0.155060               48  \n",
       "16          -0.037899        -0.137590        0.229914               49  \n",
       "28          -0.033884        -0.163225        0.272902               50  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"R_squared\"\n",
    "rf = RandomForestRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1\n",
    "                  ) # Default scoring is R-square\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b2cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf298a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.689383</td>\n",
       "      <td>1.444717e-02</td>\n",
       "      <td>0.046865</td>\n",
       "      <td>6.289914e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.370663</td>\n",
       "      <td>1.204359e-02</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>1.199770e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.415766</td>\n",
       "      <td>7.687407e-03</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.653449e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.837462</td>\n",
       "      <td>2.352903e-02</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>5.519789e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128095</td>\n",
       "      <td>6.248379e-03</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>5.840039e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078106</td>\n",
       "      <td>7.629395e-07</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>6.248474e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.770290</td>\n",
       "      <td>2.402148e-02</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>6.248665e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.169871</td>\n",
       "      <td>9.381763e-03</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>4.485726e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.366813</td>\n",
       "      <td>9.183814e-03</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.653215e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078531</td>\n",
       "      <td>5.197831e-04</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>7.653020e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        0.689383  1.444717e-02         0.046865    6.289914e-07   \n",
       "6        0.370663  1.204359e-02         0.016221    1.199770e-03   \n",
       "10       0.415766  7.687407e-03         0.024994    7.653449e-03   \n",
       "11       0.837462  2.352903e-02         0.046864    5.519789e-07   \n",
       "5        0.128095  6.248379e-03         0.015622    5.840039e-07   \n",
       "4        0.078106  7.629395e-07         0.003124    6.248474e-03   \n",
       "23       0.770290  2.402148e-02         0.049989    6.248665e-03   \n",
       "9        0.169871  9.381763e-03         0.013379    4.485726e-03   \n",
       "22       0.366813  9.183814e-03         0.024994    7.653215e-03   \n",
       "8        0.078531  5.197831e-04         0.006249    7.653020e-03   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "7                1                0.1                500   \n",
       "6                1                0.1                250   \n",
       "10               1                0.3                250   \n",
       "11               1                0.3                500   \n",
       "5                1                0.1                100   \n",
       "4                1                0.1                 50   \n",
       "23               2                0.1                500   \n",
       "9                1                0.3                100   \n",
       "22               2                0.1                250   \n",
       "8                1                0.3                 50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "7   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "6   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000082   \n",
       "10  {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000082   \n",
       "11  {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000083   \n",
       "5   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000082   \n",
       "4   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000082   \n",
       "23  {'max_depth': 2, 'max_features': 0.1, 'n_estim...          -0.000082   \n",
       "9   {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000082   \n",
       "22  {'max_depth': 2, 'max_features': 0.1, 'n_estim...          -0.000082   \n",
       "8   {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000082   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7           -0.000233          -0.000105          -0.000198   \n",
       "6           -0.000233          -0.000105          -0.000199   \n",
       "10          -0.000235          -0.000105          -0.000199   \n",
       "11          -0.000235          -0.000104          -0.000198   \n",
       "5           -0.000233          -0.000106          -0.000199   \n",
       "4           -0.000234          -0.000106          -0.000199   \n",
       "23          -0.000236          -0.000105          -0.000199   \n",
       "9           -0.000236          -0.000105          -0.000199   \n",
       "22          -0.000236          -0.000106          -0.000199   \n",
       "8           -0.000241          -0.000104          -0.000198   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7           -0.000239        -0.000172        0.000065                1  \n",
       "6           -0.000239        -0.000172        0.000066                2  \n",
       "10          -0.000238        -0.000172        0.000066                3  \n",
       "11          -0.000239        -0.000172        0.000066                4  \n",
       "5           -0.000240        -0.000172        0.000066                5  \n",
       "4           -0.000240        -0.000172        0.000066                6  \n",
       "23          -0.000238        -0.000172        0.000066                7  \n",
       "9           -0.000239        -0.000172        0.000066                8  \n",
       "22          -0.000239        -0.000172        0.000066                9  \n",
       "8           -0.000237        -0.000172        0.000067               10  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "rf = RandomForestRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c15ace75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'max_features': 0.1, 'n_estimators': 500}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab08de3",
   "metadata": {},
   "source": [
    "The best hyperparameters are the same whether scoring is R-square or neg_mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719d47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7920b3a6",
   "metadata": {},
   "source": [
    "#### Test performance and check for sign of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model with best hyperparameters for 1260 days (5 years) before test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8445d089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1eb09bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.iloc[-1260:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1d1a17c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma50</th>\n",
       "      <th>rsi50</th>\n",
       "      <th>vol_1d_change</th>\n",
       "      <th>vol_1d_change_ma10</th>\n",
       "      <th>log_rtn_lag_0</th>\n",
       "      <th>log_rtn_lag_1</th>\n",
       "      <th>log_rtn_lag_2</th>\n",
       "      <th>log_rtn_lag_3</th>\n",
       "      <th>log_rtn_lag_4</th>\n",
       "      <th>log_rtn_lag_5</th>\n",
       "      <th>log_rtn_lag_6</th>\n",
       "      <th>log_rtn_lag_7</th>\n",
       "      <th>log_rtn_lag_8</th>\n",
       "      <th>log_rtn_lag_9</th>\n",
       "      <th>log_rtn_lag_10</th>\n",
       "      <th>log_rtn_lag_11</th>\n",
       "      <th>log_rtn_lag_12</th>\n",
       "      <th>log_rtn_lag_13</th>\n",
       "      <th>log_rtn_lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>47.8018</td>\n",
       "      <td>58.808517</td>\n",
       "      <td>-0.590183</td>\n",
       "      <td>-0.065383</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "      <td>-0.016761</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>47.8846</td>\n",
       "      <td>57.757435</td>\n",
       "      <td>-0.059625</td>\n",
       "      <td>-0.080472</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "      <td>-0.016761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>47.9668</td>\n",
       "      <td>57.423200</td>\n",
       "      <td>-0.178461</td>\n",
       "      <td>-0.128118</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>48.0578</td>\n",
       "      <td>58.453586</td>\n",
       "      <td>0.274878</td>\n",
       "      <td>-0.088947</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.010957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>48.1546</td>\n",
       "      <td>57.307954</td>\n",
       "      <td>0.349522</td>\n",
       "      <td>-0.078281</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>0.009073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ma50      rsi50  vol_1d_change  vol_1d_change_ma10  \\\n",
       "Date                                                                \n",
       "2017-12-22  47.8018  58.808517      -0.590183           -0.065383   \n",
       "2017-12-26  47.8846  57.757435      -0.059625           -0.080472   \n",
       "2017-12-27  47.9668  57.423200      -0.178461           -0.128118   \n",
       "2017-12-28  48.0578  58.453586       0.274878           -0.088947   \n",
       "2017-12-29  48.1546  57.307954       0.349522           -0.078281   \n",
       "\n",
       "            log_rtn_lag_0  log_rtn_lag_1  log_rtn_lag_2  log_rtn_lag_3  \\\n",
       "Date                                                                     \n",
       "2017-12-22      -0.002529       0.014287      -0.003149      -0.001767   \n",
       "2017-12-26      -0.009199      -0.002529       0.014287      -0.003149   \n",
       "2017-12-27      -0.002954      -0.009199      -0.002529       0.014287   \n",
       "2017-12-28       0.012347      -0.002954      -0.009199      -0.002529   \n",
       "2017-12-29      -0.009983       0.012347      -0.002954      -0.009199   \n",
       "\n",
       "            log_rtn_lag_4  log_rtn_lag_5  log_rtn_lag_6  log_rtn_lag_7  \\\n",
       "Date                                                                     \n",
       "2017-12-22       0.019210       0.015923      -0.010911      -0.013969   \n",
       "2017-12-26      -0.001767       0.019210       0.015923      -0.010911   \n",
       "2017-12-27      -0.003149      -0.001767       0.019210       0.015923   \n",
       "2017-12-28       0.014287      -0.003149      -0.001767       0.019210   \n",
       "2017-12-29      -0.002529       0.014287      -0.003149      -0.001767   \n",
       "\n",
       "            log_rtn_lag_8  log_rtn_lag_9  log_rtn_lag_10  log_rtn_lag_11  \\\n",
       "Date                                                                       \n",
       "2017-12-22       0.010359      -0.019630        0.009073        0.010957   \n",
       "2017-12-26      -0.013969       0.010359       -0.019630        0.009073   \n",
       "2017-12-27      -0.010911      -0.013969        0.010359       -0.019630   \n",
       "2017-12-28       0.015923      -0.010911       -0.013969        0.010359   \n",
       "2017-12-29       0.019210       0.015923       -0.010911       -0.013969   \n",
       "\n",
       "            log_rtn_lag_12  log_rtn_lag_13  log_rtn_lag_14  \n",
       "Date                                                        \n",
       "2017-12-22       -0.019048       -0.016761        0.032609  \n",
       "2017-12-26        0.010957       -0.019048       -0.016761  \n",
       "2017-12-27        0.009073        0.010957       -0.019048  \n",
       "2017-12-28       -0.019630        0.009073        0.010957  \n",
       "2017-12-29        0.010359       -0.019630        0.009073  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[-1260:, :].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "02becf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model with best hyperparameters for 1260 days (5 years) before test set \n",
    "rf = RandomForestRegressor(n_estimators=500, max_features=0.1, max_depth=1, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bf368417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010792841734387881\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train.iloc[-1260:, :], y_train.iloc[-1260:])\n",
    "print(rf.score(X_train.iloc[-1260:, :], y_train.iloc[-1260:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1e6375ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0146122595783591\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b7cc8091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.010792841734387881\n",
      "Train mean_squared_error          : 0.00026550199625891235\n",
      "Train roof of mean_squared_error  : 0.016294231993528027\n",
      "Train mean_absolute_error         : 0.012089350413563503\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = rf.predict(X_train.iloc[-1260:, :])\n",
    "print('Train r-square                    :', r2_score(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train.iloc[-1260:], y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train.iloc[-1260:], y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eef77851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.0146122595783591\n",
      "Test mean_squared_error          : 0.00020891964926564484\n",
      "Test roof of mean_squared_error  : 0.014454053039395034\n",
      "Test mean_absolute_error         : 0.010860576249988844\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0634a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99c7601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8501940960768659\n"
     ]
    }
   ],
   "source": [
    "# Compared with default RandomeForest\n",
    "# Estimate model with best hyperparameters for 1260 days (5 years) before test set \n",
    "rf = RandomForestRegressor(random_state=12)\n",
    "rf.fit(X_train.iloc[-1260:, :], y_train.iloc[-1260:])\n",
    "print(rf.score(X_train.iloc[-1260:, :], y_train.iloc[-1260:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a7d30537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08220684568388759\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d59b6",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 756 days training window (3 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bc54a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sliding window with 756 days \n",
    "sliding_cv = TimeSeriesSplit(n_splits=5, test_size=25, max_train_size=756)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "47b0a255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 100, 250, 500],\n",
       " 'max_features': ['auto', 0.1, 0.3, 0.5],\n",
       " 'max_depth': [1, 2, 5, 10, 20, None]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0dfd245a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.168711</td>\n",
       "      <td>1.169035e-02</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.652903e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.399906</td>\n",
       "      <td>1.874573e-02</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>7.652923e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.696712</td>\n",
       "      <td>1.874528e-02</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>5.917394e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.692771</td>\n",
       "      <td>1.165521e-02</td>\n",
       "      <td>0.040594</td>\n",
       "      <td>7.635466e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.431148</td>\n",
       "      <td>1.874531e-02</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>7.652456e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.5, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.173517</td>\n",
       "      <td>2.862438e-02</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>7.502696e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.796688</td>\n",
       "      <td>3.826454e-02</td>\n",
       "      <td>0.049988</td>\n",
       "      <td>6.248212e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078107</td>\n",
       "      <td>9.488940e-07</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>7.652281e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.3, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.348975</td>\n",
       "      <td>1.453050e-02</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>7.653098e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.143716</td>\n",
       "      <td>1.530621e-02</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.653137e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 0.1, 'n_estim...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        0.168711  1.169035e-02         0.009373    7.652903e-03   \n",
       "10       0.399906  1.874573e-02         0.024994    7.652923e-03   \n",
       "7        0.696712  1.874528e-02         0.046864    5.917394e-07   \n",
       "23       0.692771  1.165521e-02         0.040594    7.635466e-03   \n",
       "14       0.431148  1.874531e-02         0.021870    7.652456e-03   \n",
       "5        0.173517  2.862438e-02         0.013934    7.502696e-03   \n",
       "11       0.796688  3.826454e-02         0.049988    6.248212e-03   \n",
       "8        0.078107  9.488940e-07         0.009372    7.652281e-03   \n",
       "6        0.348975  1.453050e-02         0.021870    7.653098e-03   \n",
       "21       0.143716  1.530621e-02         0.009373    7.653137e-03   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "9                1                0.3                100   \n",
       "10               1                0.3                250   \n",
       "7                1                0.1                500   \n",
       "23               2                0.1                500   \n",
       "14               1                0.5                250   \n",
       "5                1                0.1                100   \n",
       "11               1                0.3                500   \n",
       "8                1                0.3                 50   \n",
       "6                1                0.1                250   \n",
       "21               2                0.1                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000083   \n",
       "10  {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000083   \n",
       "7   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "23  {'max_depth': 2, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "14  {'max_depth': 1, 'max_features': 0.5, 'n_estim...          -0.000083   \n",
       "5   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "11  {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000083   \n",
       "8   {'max_depth': 1, 'max_features': 0.3, 'n_estim...          -0.000083   \n",
       "6   {'max_depth': 1, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "21  {'max_depth': 2, 'max_features': 0.1, 'n_estim...          -0.000083   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9           -0.000233          -0.000106          -0.000198   \n",
       "10          -0.000234          -0.000106          -0.000199   \n",
       "7           -0.000234          -0.000106          -0.000198   \n",
       "23          -0.000235          -0.000106          -0.000199   \n",
       "14          -0.000236          -0.000106          -0.000199   \n",
       "5           -0.000234          -0.000106          -0.000199   \n",
       "11          -0.000236          -0.000106          -0.000199   \n",
       "8           -0.000239          -0.000106          -0.000198   \n",
       "6           -0.000235          -0.000106          -0.000198   \n",
       "21          -0.000236          -0.000106          -0.000199   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9           -0.000239        -0.000172        0.000065                1  \n",
       "10          -0.000239        -0.000172        0.000065                2  \n",
       "7           -0.000239        -0.000172        0.000065                3  \n",
       "23          -0.000239        -0.000172        0.000065                4  \n",
       "14          -0.000238        -0.000172        0.000066                5  \n",
       "5           -0.000240        -0.000173        0.000066                6  \n",
       "11          -0.000239        -0.000173        0.000066                7  \n",
       "8           -0.000237        -0.000173        0.000066                8  \n",
       "6           -0.000241        -0.000173        0.000066                9  \n",
       "21          -0.000241        -0.000173        0.000066               10  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "rf = RandomForestRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "964300d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'max_features': 0.3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d7f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d375ce3",
   "metadata": {},
   "source": [
    "## 5.2) Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028644b",
   "metadata": {},
   "source": [
    "#### Explore GradientBoostingRegressor\n",
    "Fit model with default parameters on all train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7a870261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sliding window validation with 1260 days\n",
    "sliding_cv = TimeSeriesSplit(n_splits=5, test_size=25, max_train_size=1260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ddc7c03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35968730487131906\n"
     ]
    }
   ],
   "source": [
    "# Fit model with default parameters on all train set \n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train, y_train)\n",
    "print(gb.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8bd5b94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08699273160508447\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cdbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb4b12ed",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd91b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1, 0.15],\n",
       " 'n_estimators': [50, 100, 150],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 0.1, 0.3, 0.5]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': ['auto', 0.1, 0.3, 0.5]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0260a8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.153329</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.186379</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 12, 'max_f...</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.284308</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 12, 'max_f...</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.111190</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 12, 'max_f...</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.096852</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 15, 'max_...</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0.078942</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.15, 'max_depth': 9, 'max_f...</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.043739</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.049988</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.160371</td>\n",
       "      <td>0.014055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.101958</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.091380</td>\n",
       "      <td>0.008018</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.107082</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.106225</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 15, 'max_...</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.103974</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.15, 'max_depth': 15, 'max_...</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.100134</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "60         0.153329      0.006370         0.003126        0.006251   \n",
       "31         0.040616      0.007653         0.000000        0.000000   \n",
       "596        0.186379      0.012315         0.001422        0.002843   \n",
       "598        0.284308      0.015305         0.003124        0.006249   \n",
       "594        0.111190      0.023211         0.004436        0.006143   \n",
       "312        0.096852      0.006248         0.000000        0.000000   \n",
       "24         0.053112      0.021190         0.003124        0.006248   \n",
       "30         0.046864      0.009880         0.006249        0.007654   \n",
       "894        0.078942      0.009520         0.000598        0.000798   \n",
       "25         0.043739      0.015306         0.006248        0.007653   \n",
       "18         0.043740      0.006249         0.000000        0.000000   \n",
       "19         0.049988      0.018217         0.000000        0.000000   \n",
       "66         0.155011      0.003309         0.000399        0.000798   \n",
       "54         0.160371      0.014055         0.000000        0.000000   \n",
       "235        0.101958      0.008406         0.000000        0.000000   \n",
       "234        0.091380      0.008018         0.003922        0.005917   \n",
       "241        0.107082      0.018786         0.000399        0.000798   \n",
       "319        0.106225      0.006248         0.000000        0.000000   \n",
       "1032       0.103974      0.008242         0.001396        0.001197   \n",
       "42         0.100134      0.007524         0.000000        0.000000   \n",
       "\n",
       "     param_learning_rate param_max_depth param_max_features  \\\n",
       "60                  0.05               3                0.5   \n",
       "31                  0.05               3                0.1   \n",
       "596                  0.1              12                0.1   \n",
       "598                  0.1              12                0.1   \n",
       "594                  0.1              12                0.1   \n",
       "312                 0.05              15                0.1   \n",
       "24                  0.05               3                0.1   \n",
       "30                  0.05               3                0.1   \n",
       "894                 0.15               9                0.1   \n",
       "25                  0.05               3                0.1   \n",
       "18                  0.05               3                0.1   \n",
       "19                  0.05               3                0.1   \n",
       "66                  0.05               3                0.5   \n",
       "54                  0.05               3                0.5   \n",
       "235                 0.05              12                0.1   \n",
       "234                 0.05              12                0.1   \n",
       "241                 0.05              12                0.1   \n",
       "319                 0.05              15                0.1   \n",
       "1032                0.15              15                0.1   \n",
       "42                  0.05               3                0.3   \n",
       "\n",
       "     param_min_samples_split param_n_estimators param_subsample  \\\n",
       "60                         6                 50             0.8   \n",
       "31                        10                 50               1   \n",
       "596                        2                100             0.8   \n",
       "598                        2                150             0.8   \n",
       "594                        2                 50             0.8   \n",
       "312                        6                 50             0.8   \n",
       "24                         6                 50             0.8   \n",
       "30                        10                 50             0.8   \n",
       "894                       10                 50             0.8   \n",
       "25                         6                 50               1   \n",
       "18                         2                 50             0.8   \n",
       "19                         2                 50               1   \n",
       "66                        10                 50             0.8   \n",
       "54                         2                 50             0.8   \n",
       "235                        2                 50               1   \n",
       "234                        2                 50             0.8   \n",
       "241                        6                 50               1   \n",
       "319                       10                 50               1   \n",
       "1032                       6                 50             0.8   \n",
       "42                         6                 50             0.8   \n",
       "\n",
       "                                                 params  split0_test_score  \\\n",
       "60    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000086   \n",
       "31    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000082   \n",
       "596   {'learning_rate': 0.1, 'max_depth': 12, 'max_f...          -0.000098   \n",
       "598   {'learning_rate': 0.1, 'max_depth': 12, 'max_f...          -0.000098   \n",
       "594   {'learning_rate': 0.1, 'max_depth': 12, 'max_f...          -0.000100   \n",
       "312   {'learning_rate': 0.05, 'max_depth': 15, 'max_...          -0.000095   \n",
       "24    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "30    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "894   {'learning_rate': 0.15, 'max_depth': 9, 'max_f...          -0.000078   \n",
       "25    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "18    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "19    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000085   \n",
       "66    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000087   \n",
       "54    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000087   \n",
       "235   {'learning_rate': 0.05, 'max_depth': 12, 'max_...          -0.000089   \n",
       "234   {'learning_rate': 0.05, 'max_depth': 12, 'max_...          -0.000073   \n",
       "241   {'learning_rate': 0.05, 'max_depth': 12, 'max_...          -0.000090   \n",
       "319   {'learning_rate': 0.05, 'max_depth': 15, 'max_...          -0.000076   \n",
       "1032  {'learning_rate': 0.15, 'max_depth': 15, 'max_...          -0.000080   \n",
       "42    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "\n",
       "      split1_test_score  split2_test_score  split3_test_score  \\\n",
       "60            -0.000377          -0.000121          -0.000198   \n",
       "31            -0.000400          -0.000111          -0.000196   \n",
       "596           -0.000309          -0.000142          -0.000239   \n",
       "598           -0.000310          -0.000143          -0.000239   \n",
       "594           -0.000314          -0.000138          -0.000234   \n",
       "312           -0.000345          -0.000136          -0.000225   \n",
       "24            -0.000420          -0.000109          -0.000205   \n",
       "30            -0.000417          -0.000108          -0.000204   \n",
       "894           -0.000336          -0.000202          -0.000215   \n",
       "25            -0.000442          -0.000110          -0.000196   \n",
       "18            -0.000425          -0.000109          -0.000204   \n",
       "19            -0.000442          -0.000111          -0.000200   \n",
       "66            -0.000427          -0.000127          -0.000198   \n",
       "54            -0.000442          -0.000119          -0.000200   \n",
       "235           -0.000409          -0.000132          -0.000210   \n",
       "234           -0.000394          -0.000129          -0.000251   \n",
       "241           -0.000416          -0.000147          -0.000224   \n",
       "319           -0.000442          -0.000157          -0.000212   \n",
       "1032          -0.000292          -0.000206          -0.000264   \n",
       "42            -0.000488          -0.000108          -0.000198   \n",
       "\n",
       "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "60            -0.000234        -0.000203        0.000102                1  \n",
       "31            -0.000227        -0.000203        0.000112                2  \n",
       "596           -0.000249        -0.000207        0.000076                3  \n",
       "598           -0.000249        -0.000208        0.000077                4  \n",
       "594           -0.000256        -0.000208        0.000079                5  \n",
       "312           -0.000247        -0.000210        0.000088                6  \n",
       "24            -0.000238        -0.000211        0.000119                7  \n",
       "30            -0.000242        -0.000211        0.000118                8  \n",
       "894           -0.000226        -0.000211        0.000082                9  \n",
       "25            -0.000229        -0.000212        0.000127               10  \n",
       "18            -0.000243        -0.000213        0.000121               11  \n",
       "19            -0.000227        -0.000213        0.000126               12  \n",
       "66            -0.000240        -0.000216        0.000118               13  \n",
       "54            -0.000241        -0.000218        0.000125               14  \n",
       "235           -0.000256        -0.000219        0.000111               15  \n",
       "234           -0.000250        -0.000220        0.000112               16  \n",
       "241           -0.000229        -0.000221        0.000110               17  \n",
       "319           -0.000224        -0.000222        0.000122               18  \n",
       "1032          -0.000272        -0.000223        0.000077               19  \n",
       "42            -0.000237        -0.000223        0.000144               20  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "start = time.time()\n",
    "gb = GradientBoostingRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2377abf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 0.5,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "405b3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.03, 0.05, 0.07],\n",
       " 'n_estimators': [50],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [6, 8, 10],\n",
       " 'max_features': ['auto', 0.1, 0.3, 0.5]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second sweep with finer learning rate\n",
    "grid = {\n",
    "    'learning_rate': [0.03, 0.05, 0.07],\n",
    "    'n_estimators': [50],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [6, 8, 10],\n",
    "    'max_features': ['auto', 0.1, 0.3, 0.5]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d63d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "start = time.time()\n",
    "gb = GradientBoostingRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)\n",
    "print(tune_time)\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "785d850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.13749122619629\n"
     ]
    }
   ],
   "source": [
    "print(tune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba27fbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.034348</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.040620</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.028451</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032579</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.068018</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 6, 'max_f...</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.081231</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 9, 'max_f...</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.087498</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299244</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.074936</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 9, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.109350</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.103101</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.096852</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 15, 'max_...</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.074060</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 9, 'max_f...</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.176206</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.162460</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8         0.049300      0.003610         0.001197        0.000746   \n",
       "6         0.042205      0.003375         0.000798        0.000977   \n",
       "10        0.034348      0.006062         0.003124        0.006247   \n",
       "11        0.040620      0.007654         0.000000        0.000000   \n",
       "7         0.028451      0.003767         0.009373        0.007653   \n",
       "9         0.032579      0.008097         0.003401        0.005855   \n",
       "32        0.068018      0.016562         0.001596        0.000489   \n",
       "58        0.081231      0.006249         0.000000        0.000000   \n",
       "78        0.087498      0.011632         0.003523        0.006098   \n",
       "4         0.299244      0.014106         0.000798        0.000977   \n",
       "20        0.176100      0.019045         0.000599        0.000798   \n",
       "54        0.074936      0.008921         0.000798        0.000977   \n",
       "12        0.109350      0.009879         0.000000        0.000000   \n",
       "14        0.103101      0.007653         0.000000        0.000000   \n",
       "16        0.103100      0.007653         0.003124        0.006249   \n",
       "129       0.040615      0.007653         0.000000        0.000000   \n",
       "102       0.096852      0.006248         0.003124        0.006249   \n",
       "55        0.074060      0.006057         0.003124        0.006248   \n",
       "22        0.176206      0.007851         0.002393        0.000488   \n",
       "18        0.162460      0.015930         0.000000        0.000000   \n",
       "\n",
       "    param_learning_rate param_max_depth param_max_features  \\\n",
       "8                  0.03               3                0.1   \n",
       "6                  0.03               3                0.1   \n",
       "10                 0.03               3                0.1   \n",
       "11                 0.03               3                0.1   \n",
       "7                  0.03               3                0.1   \n",
       "9                  0.03               3                0.1   \n",
       "32                 0.03               6                0.1   \n",
       "58                 0.03               9                0.1   \n",
       "78                 0.03              12                0.1   \n",
       "4                  0.03               3               auto   \n",
       "20                 0.03               3                0.5   \n",
       "54                 0.03               9                0.1   \n",
       "12                 0.03               3                0.3   \n",
       "14                 0.03               3                0.3   \n",
       "16                 0.03               3                0.3   \n",
       "129                0.05               3                0.1   \n",
       "102                0.03              15                0.1   \n",
       "55                 0.03               9                0.1   \n",
       "22                 0.03               3                0.5   \n",
       "18                 0.03               3                0.5   \n",
       "\n",
       "    param_min_samples_split param_n_estimators param_subsample  \\\n",
       "8                         8                 50             0.8   \n",
       "6                         6                 50             0.8   \n",
       "10                       10                 50             0.8   \n",
       "11                       10                 50               1   \n",
       "7                         6                 50               1   \n",
       "9                         8                 50               1   \n",
       "32                        8                 50             0.8   \n",
       "58                       10                 50             0.8   \n",
       "78                        6                 50             0.8   \n",
       "4                        10                 50             0.8   \n",
       "20                        8                 50             0.8   \n",
       "54                        6                 50             0.8   \n",
       "12                        6                 50             0.8   \n",
       "14                        8                 50             0.8   \n",
       "16                       10                 50             0.8   \n",
       "129                       8                 50               1   \n",
       "102                       6                 50             0.8   \n",
       "55                        6                 50               1   \n",
       "22                       10                 50             0.8   \n",
       "18                        6                 50             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "8    {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "6    {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "10   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "11   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "7    {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "9    {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "32   {'learning_rate': 0.03, 'max_depth': 6, 'max_f...          -0.000082   \n",
       "58   {'learning_rate': 0.03, 'max_depth': 9, 'max_f...          -0.000085   \n",
       "78   {'learning_rate': 0.03, 'max_depth': 12, 'max_...          -0.000083   \n",
       "4    {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "20   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "54   {'learning_rate': 0.03, 'max_depth': 9, 'max_f...          -0.000084   \n",
       "12   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "14   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "16   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "129  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "102  {'learning_rate': 0.03, 'max_depth': 15, 'max_...          -0.000080   \n",
       "55   {'learning_rate': 0.03, 'max_depth': 9, 'max_f...          -0.000085   \n",
       "22   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "18   {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8            -0.000297          -0.000106          -0.000201   \n",
       "6            -0.000298          -0.000106          -0.000200   \n",
       "10           -0.000297          -0.000106          -0.000201   \n",
       "11           -0.000338          -0.000109          -0.000197   \n",
       "7            -0.000338          -0.000108          -0.000198   \n",
       "9            -0.000340          -0.000108          -0.000199   \n",
       "32           -0.000344          -0.000107          -0.000195   \n",
       "58           -0.000325          -0.000117          -0.000200   \n",
       "78           -0.000336          -0.000116          -0.000199   \n",
       "4            -0.000351          -0.000109          -0.000198   \n",
       "20           -0.000350          -0.000113          -0.000198   \n",
       "54           -0.000350          -0.000110          -0.000200   \n",
       "12           -0.000359          -0.000108          -0.000199   \n",
       "14           -0.000360          -0.000108          -0.000199   \n",
       "16           -0.000359          -0.000108          -0.000199   \n",
       "129          -0.000379          -0.000111          -0.000198   \n",
       "102          -0.000371          -0.000122          -0.000210   \n",
       "55           -0.000371          -0.000110          -0.000202   \n",
       "22           -0.000381          -0.000113          -0.000197   \n",
       "18           -0.000379          -0.000113          -0.000198   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "8            -0.000240        -0.000185        0.000080                1  \n",
       "6            -0.000240        -0.000186        0.000081                2  \n",
       "10           -0.000240        -0.000186        0.000081                3  \n",
       "11           -0.000233        -0.000192        0.000091                4  \n",
       "7            -0.000234        -0.000192        0.000091                5  \n",
       "9            -0.000234        -0.000193        0.000092                6  \n",
       "32           -0.000242        -0.000194        0.000095                7  \n",
       "58           -0.000244        -0.000194        0.000087                8  \n",
       "78           -0.000243        -0.000195        0.000091                9  \n",
       "4            -0.000237        -0.000196        0.000096               10  \n",
       "20           -0.000238        -0.000196        0.000095               11  \n",
       "54           -0.000241        -0.000197        0.000096               12  \n",
       "12           -0.000235        -0.000197        0.000099               13  \n",
       "14           -0.000235        -0.000197        0.000099               14  \n",
       "16           -0.000237        -0.000197        0.000099               15  \n",
       "129          -0.000227        -0.000200        0.000104               16  \n",
       "102          -0.000226        -0.000202        0.000101               17  \n",
       "55           -0.000242        -0.000202        0.000102               18  \n",
       "22           -0.000237        -0.000202        0.000105               19  \n",
       "18           -0.000238        -0.000202        0.000105               20  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "28146c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 0.1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d1adb748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.02, 0.025, 0.03, 0.035],\n",
       " 'n_estimators': [50],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [6, 8, 10],\n",
       " 'max_features': ['auto', 0.1, 0.3, 0.5]}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third sweep with finer learning rate\n",
    "grid = {\n",
    "    'learning_rate': [0.02, 0.025, 0.03, 0.035],\n",
    "    'n_estimators': [50],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [6, 8, 10],\n",
    "    'max_features': ['auto', 0.1, 0.3, 0.5]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d3e7b235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.95606756210327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>7.653332e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.046864</td>\n",
       "      <td>8.176054e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040616</td>\n",
       "      <td>7.652086e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.040616</td>\n",
       "      <td>7.653001e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>7.652553e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.248760e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031244</td>\n",
       "      <td>3.989506e-07</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037492</td>\n",
       "      <td>7.653760e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.034366</td>\n",
       "      <td>6.249666e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.081231</td>\n",
       "      <td>6.248951e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.02</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.053113</td>\n",
       "      <td>7.653001e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 6, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.062485</td>\n",
       "      <td>9.608003e-07</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 9, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.096852</td>\n",
       "      <td>6.248665e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.106224</td>\n",
       "      <td>6.248379e-03</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.053113</td>\n",
       "      <td>7.652378e-03</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 6, 'max_f...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.034367</td>\n",
       "      <td>6.248570e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.034367</td>\n",
       "      <td>6.248832e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.037491</td>\n",
       "      <td>7.652767e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.025, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.084356</td>\n",
       "      <td>7.653118e-03</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.02</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 12, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.040577</td>\n",
       "      <td>7.616341e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6         0.040615  7.653332e-03         0.003124        0.006248   \n",
       "8         0.046864  8.176054e-07         0.000000        0.000000   \n",
       "10        0.040616  7.652086e-03         0.000000        0.000000   \n",
       "126       0.040616  7.653001e-03         0.000000        0.000000   \n",
       "130       0.040615  7.652553e-03         0.003124        0.006248   \n",
       "128       0.043740  6.248760e-03         0.000000        0.000000   \n",
       "7         0.031244  3.989506e-07         0.003124        0.006248   \n",
       "9         0.037492  7.653760e-03         0.003124        0.006248   \n",
       "11        0.034366  6.249666e-03         0.003124        0.006249   \n",
       "80        0.081231  6.248951e-03         0.003124        0.006249   \n",
       "30        0.053113  7.653001e-03         0.003124        0.006248   \n",
       "56        0.062485  9.608003e-07         0.006249        0.007653   \n",
       "14        0.096852  6.248665e-03         0.003124        0.006249   \n",
       "12        0.106224  6.248379e-03         0.006248        0.007653   \n",
       "34        0.053113  7.652378e-03         0.006248        0.007652   \n",
       "129       0.034367  6.248570e-03         0.003124        0.006249   \n",
       "127       0.034367  6.248832e-03         0.000000        0.000000   \n",
       "131       0.037491  7.652767e-03         0.003124        0.006249   \n",
       "82        0.084356  7.653118e-03         0.006249        0.007653   \n",
       "248       0.040577  7.616341e-03         0.003124        0.006249   \n",
       "\n",
       "    param_learning_rate param_max_depth param_max_features  \\\n",
       "6                  0.02               3                0.1   \n",
       "8                  0.02               3                0.1   \n",
       "10                 0.02               3                0.1   \n",
       "126               0.025               3                0.1   \n",
       "130               0.025               3                0.1   \n",
       "128               0.025               3                0.1   \n",
       "7                  0.02               3                0.1   \n",
       "9                  0.02               3                0.1   \n",
       "11                 0.02               3                0.1   \n",
       "80                 0.02              12                0.1   \n",
       "30                 0.02               6                0.1   \n",
       "56                 0.02               9                0.1   \n",
       "14                 0.02               3                0.3   \n",
       "12                 0.02               3                0.3   \n",
       "34                 0.02               6                0.1   \n",
       "129               0.025               3                0.1   \n",
       "127               0.025               3                0.1   \n",
       "131               0.025               3                0.1   \n",
       "82                 0.02              12                0.1   \n",
       "248                0.03               3                0.1   \n",
       "\n",
       "    param_min_samples_split param_n_estimators param_subsample  \\\n",
       "6                         6                 50             0.8   \n",
       "8                         8                 50             0.8   \n",
       "10                       10                 50             0.8   \n",
       "126                       6                 50             0.8   \n",
       "130                      10                 50             0.8   \n",
       "128                       8                 50             0.8   \n",
       "7                         6                 50               1   \n",
       "9                         8                 50               1   \n",
       "11                       10                 50               1   \n",
       "80                        8                 50             0.8   \n",
       "30                        6                 50             0.8   \n",
       "56                        8                 50             0.8   \n",
       "14                        8                 50             0.8   \n",
       "12                        6                 50             0.8   \n",
       "34                       10                 50             0.8   \n",
       "129                       8                 50               1   \n",
       "127                       6                 50               1   \n",
       "131                      10                 50               1   \n",
       "82                       10                 50             0.8   \n",
       "248                       8                 50             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "6    {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "8    {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "10   {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "126  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000083   \n",
       "130  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000083   \n",
       "128  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000083   \n",
       "7    {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "9    {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000084   \n",
       "11   {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "80   {'learning_rate': 0.02, 'max_depth': 12, 'max_...          -0.000079   \n",
       "30   {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          -0.000083   \n",
       "56   {'learning_rate': 0.02, 'max_depth': 9, 'max_f...          -0.000083   \n",
       "14   {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "12   {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "34   {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          -0.000084   \n",
       "129  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000083   \n",
       "127  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000084   \n",
       "131  {'learning_rate': 0.025, 'max_depth': 3, 'max_...          -0.000083   \n",
       "82   {'learning_rate': 0.02, 'max_depth': 12, 'max_...          -0.000083   \n",
       "248  {'learning_rate': 0.03, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "6            -0.000252          -0.000105          -0.000199   \n",
       "8            -0.000258          -0.000105          -0.000200   \n",
       "10           -0.000258          -0.000106          -0.000200   \n",
       "126          -0.000276          -0.000106          -0.000200   \n",
       "130          -0.000276          -0.000106          -0.000201   \n",
       "128          -0.000276          -0.000106          -0.000201   \n",
       "7            -0.000286          -0.000107          -0.000198   \n",
       "9            -0.000289          -0.000107          -0.000198   \n",
       "11           -0.000289          -0.000107          -0.000198   \n",
       "80           -0.000284          -0.000115          -0.000206   \n",
       "30           -0.000288          -0.000106          -0.000200   \n",
       "56           -0.000294          -0.000112          -0.000202   \n",
       "14           -0.000292          -0.000105          -0.000199   \n",
       "12           -0.000292          -0.000106          -0.000199   \n",
       "34           -0.000293          -0.000107          -0.000201   \n",
       "129          -0.000298          -0.000107          -0.000198   \n",
       "127          -0.000300          -0.000107          -0.000199   \n",
       "131          -0.000301          -0.000107          -0.000198   \n",
       "82           -0.000290          -0.000116          -0.000199   \n",
       "248          -0.000297          -0.000106          -0.000201   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "6            -0.000239        -0.000176        0.000069                1  \n",
       "8            -0.000240        -0.000177        0.000071                2  \n",
       "10           -0.000240        -0.000177        0.000071                3  \n",
       "126          -0.000239        -0.000181        0.000075                4  \n",
       "130          -0.000240        -0.000181        0.000075                5  \n",
       "128          -0.000241        -0.000181        0.000075                6  \n",
       "7            -0.000234        -0.000182        0.000076                7  \n",
       "9            -0.000234        -0.000182        0.000077                8  \n",
       "11           -0.000234        -0.000182        0.000077                9  \n",
       "80           -0.000231        -0.000183        0.000075               10  \n",
       "30           -0.000240        -0.000183        0.000078               11  \n",
       "56           -0.000226        -0.000183        0.000077               12  \n",
       "14           -0.000239        -0.000184        0.000079               13  \n",
       "12           -0.000240        -0.000184        0.000079               14  \n",
       "34           -0.000234        -0.000184        0.000078               15  \n",
       "129          -0.000233        -0.000184        0.000079               16  \n",
       "127          -0.000233        -0.000184        0.000080               17  \n",
       "131          -0.000233        -0.000184        0.000081               18  \n",
       "82           -0.000238        -0.000185        0.000076               19  \n",
       "248          -0.000240        -0.000185        0.000080               20  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "start = time.time()\n",
    "gb = GradientBoostingRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)\n",
    "print(tune_time)\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "695cd52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 0.1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6dc80a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.005, 0.01, 0.015, 0.02],\n",
       " 'n_estimators': [50],\n",
       " 'subsample': [0.8],\n",
       " 'max_depth': [3, 6],\n",
       " 'min_samples_split': [6, 8],\n",
       " 'max_features': ['auto', 0.1, 0.3]}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fourth sweep with finer learning rate\n",
    "grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.015, 0.02],\n",
    "    'n_estimators': [50],\n",
    "    'subsample': [0.8],\n",
    "    'max_depth': [3, 6],\n",
    "    'min_samples_split': [6, 8],\n",
    "    'max_features': ['auto', 0.1, 0.3]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7b5f133b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.11021614074707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.062486</td>\n",
       "      <td>1.540708e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053193</td>\n",
       "      <td>7.588595e-03</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059361</td>\n",
       "      <td>1.821768e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059362</td>\n",
       "      <td>1.168886e-02</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.115598</td>\n",
       "      <td>7.651774e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.112474</td>\n",
       "      <td>6.248450e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.046864</td>\n",
       "      <td>9.880534e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.046865</td>\n",
       "      <td>9.879479e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.053191</td>\n",
       "      <td>7.750812e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328730</td>\n",
       "      <td>3.213264e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334297</td>\n",
       "      <td>1.593026e-02</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>7.653176e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.015, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.046863</td>\n",
       "      <td>9.879856e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.015, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.053112</td>\n",
       "      <td>7.652942e-03</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 6, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.162460</td>\n",
       "      <td>7.653351e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.093729</td>\n",
       "      <td>7.008046e-07</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.096853</td>\n",
       "      <td>6.249285e-03</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.168711</td>\n",
       "      <td>6.248999e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.053113</td>\n",
       "      <td>1.249672e-02</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.248689e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        0.062486  1.540708e-06         0.000000        0.000000   \n",
       "2        0.053193  7.588595e-03         0.000601        0.001203   \n",
       "3        0.059361  1.821768e-02         0.000000        0.000000   \n",
       "8        0.059362  1.168886e-02         0.003124        0.006249   \n",
       "4        0.115598  7.651774e-03         0.000000        0.000000   \n",
       "5        0.112474  6.248450e-03         0.003124        0.006249   \n",
       "14       0.046864  9.880534e-03         0.000000        0.000000   \n",
       "15       0.046865  9.879479e-03         0.003124        0.006248   \n",
       "21       0.053191  7.750812e-03         0.003124        0.006249   \n",
       "1        0.328730  3.213264e-02         0.000000        0.000000   \n",
       "0        0.334297  1.593026e-02         0.006248        0.007653   \n",
       "26       0.040615  7.653176e-03         0.000000        0.000000   \n",
       "27       0.046863  9.879856e-03         0.000000        0.000000   \n",
       "20       0.053112  7.652942e-03         0.003124        0.006249   \n",
       "10       0.162460  7.653351e-03         0.000000        0.000000   \n",
       "16       0.093729  7.008046e-07         0.003124        0.006248   \n",
       "17       0.096853  6.249285e-03         0.006249        0.007653   \n",
       "11       0.168711  6.248999e-03         0.000000        0.000000   \n",
       "38       0.053113  1.249672e-02         0.006249        0.007653   \n",
       "39       0.043740  6.248689e-03         0.000000        0.000000   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features  \\\n",
       "9                0.005               6                0.1   \n",
       "2                0.005               3                0.1   \n",
       "3                0.005               3                0.1   \n",
       "8                0.005               6                0.1   \n",
       "4                0.005               3                0.3   \n",
       "5                0.005               3                0.3   \n",
       "14                0.01               3                0.1   \n",
       "15                0.01               3                0.1   \n",
       "21                0.01               6                0.1   \n",
       "1                0.005               3               auto   \n",
       "0                0.005               3               auto   \n",
       "26               0.015               3                0.1   \n",
       "27               0.015               3                0.1   \n",
       "20                0.01               6                0.1   \n",
       "10               0.005               6                0.3   \n",
       "16                0.01               3                0.3   \n",
       "17                0.01               3                0.3   \n",
       "11               0.005               6                0.3   \n",
       "38                0.02               3                0.1   \n",
       "39                0.02               3                0.1   \n",
       "\n",
       "   param_min_samples_split param_n_estimators param_subsample  \\\n",
       "9                        8                 50             0.8   \n",
       "2                        6                 50             0.8   \n",
       "3                        8                 50             0.8   \n",
       "8                        6                 50             0.8   \n",
       "4                        6                 50             0.8   \n",
       "5                        8                 50             0.8   \n",
       "14                       6                 50             0.8   \n",
       "15                       8                 50             0.8   \n",
       "21                       8                 50             0.8   \n",
       "1                        8                 50             0.8   \n",
       "0                        6                 50             0.8   \n",
       "26                       6                 50             0.8   \n",
       "27                       8                 50             0.8   \n",
       "20                       6                 50             0.8   \n",
       "10                       6                 50             0.8   \n",
       "16                       6                 50             0.8   \n",
       "17                       8                 50             0.8   \n",
       "11                       8                 50             0.8   \n",
       "38                       6                 50             0.8   \n",
       "39                       8                 50             0.8   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'learning_rate': 0.005, 'max_depth': 6, 'max_...          -0.000083   \n",
       "2   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "3   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "8   {'learning_rate': 0.005, 'max_depth': 6, 'max_...          -0.000083   \n",
       "4   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "5   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "21  {'learning_rate': 0.01, 'max_depth': 6, 'max_f...          -0.000083   \n",
       "1   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "0   {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "26  {'learning_rate': 0.015, 'max_depth': 3, 'max_...          -0.000083   \n",
       "27  {'learning_rate': 0.015, 'max_depth': 3, 'max_...          -0.000083   \n",
       "20  {'learning_rate': 0.01, 'max_depth': 6, 'max_f...          -0.000083   \n",
       "10  {'learning_rate': 0.005, 'max_depth': 6, 'max_...          -0.000083   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "11  {'learning_rate': 0.005, 'max_depth': 6, 'max_...          -0.000083   \n",
       "38  {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "39  {'learning_rate': 0.02, 'max_depth': 3, 'max_f...          -0.000083   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9           -0.000235          -0.000105          -0.000199   \n",
       "2           -0.000233          -0.000105          -0.000199   \n",
       "3           -0.000234          -0.000105          -0.000199   \n",
       "8           -0.000235          -0.000104          -0.000199   \n",
       "4           -0.000236          -0.000104          -0.000198   \n",
       "5           -0.000236          -0.000105          -0.000198   \n",
       "14          -0.000237          -0.000105          -0.000199   \n",
       "15          -0.000237          -0.000105          -0.000199   \n",
       "21          -0.000244          -0.000104          -0.000197   \n",
       "1           -0.000242          -0.000105          -0.000199   \n",
       "0           -0.000243          -0.000105          -0.000199   \n",
       "26          -0.000245          -0.000105          -0.000199   \n",
       "27          -0.000245          -0.000105          -0.000199   \n",
       "20          -0.000246          -0.000104          -0.000199   \n",
       "10          -0.000250          -0.000106          -0.000198   \n",
       "16          -0.000252          -0.000105          -0.000198   \n",
       "17          -0.000252          -0.000105          -0.000198   \n",
       "11          -0.000253          -0.000105          -0.000198   \n",
       "38          -0.000252          -0.000105          -0.000199   \n",
       "39          -0.000258          -0.000105          -0.000200   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9           -0.000236        -0.000171        0.000065                1  \n",
       "2           -0.000239        -0.000172        0.000066                2  \n",
       "3           -0.000240        -0.000172        0.000066                3  \n",
       "8           -0.000240        -0.000172        0.000066                4  \n",
       "4           -0.000240        -0.000172        0.000066                5  \n",
       "5           -0.000240        -0.000172        0.000066                6  \n",
       "14          -0.000239        -0.000172        0.000066                7  \n",
       "15          -0.000240        -0.000173        0.000066                8  \n",
       "21          -0.000236        -0.000173        0.000067                9  \n",
       "1           -0.000239        -0.000174        0.000067               10  \n",
       "0           -0.000239        -0.000174        0.000067               11  \n",
       "26          -0.000239        -0.000174        0.000068               12  \n",
       "27          -0.000240        -0.000174        0.000068               13  \n",
       "20          -0.000241        -0.000174        0.000068               14  \n",
       "10          -0.000240        -0.000175        0.000069               15  \n",
       "16          -0.000240        -0.000175        0.000069               16  \n",
       "17          -0.000240        -0.000176        0.000069               17  \n",
       "11          -0.000240        -0.000176        0.000069               18  \n",
       "38          -0.000239        -0.000176        0.000069               19  \n",
       "39          -0.000240        -0.000177        0.000071               20  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "start = time.time()\n",
    "gb = GradientBoostingRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)\n",
    "print(tune_time)\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2b272dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005,\n",
       " 'max_depth': 6,\n",
       " 'max_features': 0.1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cafe692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.001, 0.003, 0.005, 0.007],\n",
       " 'n_estimators': [50],\n",
       " 'subsample': [0.8],\n",
       " 'max_depth': [3, 6],\n",
       " 'min_samples_split': [6, 8],\n",
       " 'max_features': ['auto', 0.1, 0.3]}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fifth sweep with finer learning rate\n",
    "grid = {\n",
    "    'learning_rate': [0.001, 0.003, 0.005, 0.007],\n",
    "    'n_estimators': [50],\n",
    "    'subsample': [0.8],\n",
    "    'max_depth': [3, 6],\n",
    "    'min_samples_split': [6, 8],\n",
    "    'max_features': ['auto', 0.1, 0.3]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1a6d58ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.365339756011963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.051090</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.007, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.165587</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290114</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.049988</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.007, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.040772</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.005, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.092462</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.099191</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.003, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.574870</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.560470</td>\n",
       "      <td>0.010590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.056236</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.168710</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.007, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094485</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'max_...</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "33       0.051090      0.006085         0.005226        0.006602   \n",
       "21       0.053113      0.007653         0.000000        0.000000   \n",
       "45       0.053112      0.007652         0.000000        0.000000   \n",
       "26       0.040615      0.007653         0.003124        0.006249   \n",
       "11       0.165587      0.007653         0.003124        0.006249   \n",
       "20       0.053795      0.006084         0.000000        0.000000   \n",
       "14       0.040615      0.007654         0.000000        0.000000   \n",
       "1        0.294723      0.011941         0.000000        0.000000   \n",
       "0        0.290114      0.006898         0.003418        0.006836   \n",
       "38       0.049988      0.015305         0.000000        0.000000   \n",
       "27       0.040772      0.006041         0.000000        0.000000   \n",
       "16       0.092462      0.006220         0.003523        0.006098   \n",
       "17       0.099191      0.006034         0.000798        0.000977   \n",
       "15       0.045470      0.010266         0.004135        0.007314   \n",
       "6        0.574870      0.018222         0.000000        0.000000   \n",
       "7        0.560470      0.010590         0.000000        0.000000   \n",
       "9        0.056236      0.007654         0.003125        0.006249   \n",
       "10       0.168710      0.011689         0.000000        0.000000   \n",
       "39       0.040615      0.007653         0.000000        0.000000   \n",
       "4        0.094485      0.002203         0.000000        0.000000   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features  \\\n",
       "33               0.005               6                0.1   \n",
       "21               0.003               6                0.1   \n",
       "45               0.007               6                0.1   \n",
       "26               0.005               3                0.1   \n",
       "11               0.001               6                0.3   \n",
       "20               0.003               6                0.1   \n",
       "14               0.003               3                0.1   \n",
       "1                0.001               3               auto   \n",
       "0                0.001               3               auto   \n",
       "38               0.007               3                0.1   \n",
       "27               0.005               3                0.1   \n",
       "16               0.003               3                0.3   \n",
       "17               0.003               3                0.3   \n",
       "15               0.003               3                0.1   \n",
       "6                0.001               6               auto   \n",
       "7                0.001               6               auto   \n",
       "9                0.001               6                0.1   \n",
       "10               0.001               6                0.3   \n",
       "39               0.007               3                0.1   \n",
       "4                0.001               3                0.3   \n",
       "\n",
       "   param_min_samples_split param_n_estimators param_subsample  \\\n",
       "33                       8                 50             0.8   \n",
       "21                       8                 50             0.8   \n",
       "45                       8                 50             0.8   \n",
       "26                       6                 50             0.8   \n",
       "11                       8                 50             0.8   \n",
       "20                       6                 50             0.8   \n",
       "14                       6                 50             0.8   \n",
       "1                        8                 50             0.8   \n",
       "0                        6                 50             0.8   \n",
       "38                       6                 50             0.8   \n",
       "27                       8                 50             0.8   \n",
       "16                       6                 50             0.8   \n",
       "17                       8                 50             0.8   \n",
       "15                       8                 50             0.8   \n",
       "6                        6                 50             0.8   \n",
       "7                        8                 50             0.8   \n",
       "9                        8                 50             0.8   \n",
       "10                       6                 50             0.8   \n",
       "39                       8                 50             0.8   \n",
       "4                        6                 50             0.8   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "33  {'learning_rate': 0.005, 'max_depth': 6, 'max_...          -0.000083   \n",
       "21  {'learning_rate': 0.003, 'max_depth': 6, 'max_...          -0.000083   \n",
       "45  {'learning_rate': 0.007, 'max_depth': 6, 'max_...          -0.000083   \n",
       "26  {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "11  {'learning_rate': 0.001, 'max_depth': 6, 'max_...          -0.000083   \n",
       "20  {'learning_rate': 0.003, 'max_depth': 6, 'max_...          -0.000083   \n",
       "14  {'learning_rate': 0.003, 'max_depth': 3, 'max_...          -0.000083   \n",
       "1   {'learning_rate': 0.001, 'max_depth': 3, 'max_...          -0.000083   \n",
       "0   {'learning_rate': 0.001, 'max_depth': 3, 'max_...          -0.000083   \n",
       "38  {'learning_rate': 0.007, 'max_depth': 3, 'max_...          -0.000083   \n",
       "27  {'learning_rate': 0.005, 'max_depth': 3, 'max_...          -0.000083   \n",
       "16  {'learning_rate': 0.003, 'max_depth': 3, 'max_...          -0.000083   \n",
       "17  {'learning_rate': 0.003, 'max_depth': 3, 'max_...          -0.000083   \n",
       "15  {'learning_rate': 0.003, 'max_depth': 3, 'max_...          -0.000083   \n",
       "6   {'learning_rate': 0.001, 'max_depth': 6, 'max_...          -0.000083   \n",
       "7   {'learning_rate': 0.001, 'max_depth': 6, 'max_...          -0.000083   \n",
       "9   {'learning_rate': 0.001, 'max_depth': 6, 'max_...          -0.000083   \n",
       "10  {'learning_rate': 0.001, 'max_depth': 6, 'max_...          -0.000083   \n",
       "39  {'learning_rate': 0.007, 'max_depth': 3, 'max_...          -0.000083   \n",
       "4   {'learning_rate': 0.001, 'max_depth': 3, 'max_...          -0.000083   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "33          -0.000235          -0.000105          -0.000199   \n",
       "21          -0.000233          -0.000105          -0.000198   \n",
       "45          -0.000236          -0.000105          -0.000198   \n",
       "26          -0.000233          -0.000105          -0.000199   \n",
       "11          -0.000234          -0.000105          -0.000198   \n",
       "20          -0.000234          -0.000104          -0.000198   \n",
       "14          -0.000234          -0.000105          -0.000198   \n",
       "1           -0.000234          -0.000105          -0.000198   \n",
       "0           -0.000234          -0.000105          -0.000198   \n",
       "38          -0.000234          -0.000104          -0.000199   \n",
       "27          -0.000234          -0.000105          -0.000199   \n",
       "16          -0.000234          -0.000105          -0.000198   \n",
       "17          -0.000234          -0.000105          -0.000198   \n",
       "15          -0.000234          -0.000105          -0.000199   \n",
       "6           -0.000234          -0.000105          -0.000198   \n",
       "7           -0.000234          -0.000105          -0.000198   \n",
       "9           -0.000235          -0.000104          -0.000198   \n",
       "10          -0.000234          -0.000105          -0.000198   \n",
       "39          -0.000234          -0.000104          -0.000199   \n",
       "4           -0.000235          -0.000105          -0.000198   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "33          -0.000236        -0.000171        0.000065                1  \n",
       "21          -0.000238        -0.000172        0.000065                2  \n",
       "45          -0.000236        -0.000172        0.000065                3  \n",
       "26          -0.000239        -0.000172        0.000066                4  \n",
       "11          -0.000240        -0.000172        0.000066                5  \n",
       "20          -0.000240        -0.000172        0.000066                6  \n",
       "14          -0.000240        -0.000172        0.000066                7  \n",
       "1           -0.000240        -0.000172        0.000066                8  \n",
       "0           -0.000240        -0.000172        0.000066                9  \n",
       "38          -0.000239        -0.000172        0.000066               10  \n",
       "27          -0.000240        -0.000172        0.000066               11  \n",
       "16          -0.000240        -0.000172        0.000066               12  \n",
       "17          -0.000240        -0.000172        0.000066               13  \n",
       "15          -0.000240        -0.000172        0.000066               14  \n",
       "6           -0.000240        -0.000172        0.000066               15  \n",
       "7           -0.000240        -0.000172        0.000066               16  \n",
       "9           -0.000239        -0.000172        0.000066               17  \n",
       "10          -0.000240        -0.000172        0.000066               18  \n",
       "39          -0.000240        -0.000172        0.000066               19  \n",
       "4           -0.000240        -0.000172        0.000066               20  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for \"neg_mean_squared_error\"\n",
    "start = time.time()\n",
    "gb = GradientBoostingRegressor(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=sliding_cv,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)\n",
    "print(tune_time)\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d95934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005,\n",
       " 'max_depth': 6,\n",
       " 'max_features': 0.1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313635d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f540cc",
   "metadata": {},
   "source": [
    "#### Test performance and check for sign of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b4266966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model with best hyperparameters for 1260 days (5 years) before test set \n",
    "gb = GradientBoostingRegressor(learning_rate=0.005, max_depth=6, max_features=0.1, min_samples_split=8,\n",
    "        n_estimators=50, subsample=0.8, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "97ca3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0359790135206669\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train.iloc[-1260:, :], y_train.iloc[-1260:])\n",
    "print(gb.score(X_train.iloc[-1260:, :], y_train.iloc[-1260:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fb68ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.013498089187059303\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "79f90ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.0359790135206669\n",
      "Train mean_squared_error          : 0.00025874205843243994\n",
      "Train roof of mean_squared_error  : 0.016085461088586796\n",
      "Train mean_absolute_error         : 0.011967819408342198\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = gb.predict(X_train.iloc[-1260:, :])\n",
    "print('Train r-square                    :', r2_score(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train.iloc[-1260:], y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train.iloc[-1260:], y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "34ddd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.013498089187059303\n",
      "Test mean_squared_error          : 0.00020869022951916033\n",
      "Test roof of mean_squared_error  : 0.014446114685934082\n",
      "Test mean_absolute_error         : 0.010840268525999716\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = gb.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c9d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d84838",
   "metadata": {},
   "source": [
    "## 5.3) Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e288507",
   "metadata": {},
   "source": [
    "#### Explore Ridge() without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "885282b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression\n",
    "model = Ridge() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cb643ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004863206379965456 [-3.62497203e-05 -5.81688916e-05  1.14942022e-03 -9.59784122e-04\n",
      "  1.36349787e-02 -6.08119531e-03  5.17037669e-03 -9.42726764e-03\n",
      " -4.75417906e-03 -3.41007270e-03  2.84595587e-03 -3.42922648e-03\n",
      "  2.48079306e-03  9.43970432e-03  3.90862869e-03 -9.60658534e-03\n",
      "  3.13050081e-03  5.61116982e-03 -7.02831253e-03] 0.00546435415678459\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cf46f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score -0.042872384586940315\n"
     ]
    }
   ],
   "source": [
    "print('test score', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5640854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.00546435415678459\n",
      "Train mean_squared_error          : 0.00028227053574506153\n",
      "Train roof of mean_squared_error  : 0.016800908777356703\n",
      "Train mean_absolute_error         : 0.01245732688285812\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = model.predict(X_train)\n",
    "print('Train r-square                    :', r2_score(y_train, y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train, y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93f95e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.042872384586940315\n",
      "Test mean_squared_error          : 0.00021473871497203559\n",
      "Test roof of mean_squared_error  : 0.014653965844508973\n",
      "Test mean_absolute_error         : 0.011215445904034966\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = model.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3423406b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.000758\n",
       "1   0.000758\n",
       "2   0.000758\n",
       "3   0.000758\n",
       "4   0.000758\n",
       "5   0.000758\n",
       "6   0.000758\n",
       "7   0.000758\n",
       "8   0.000758\n",
       "9   0.000758\n",
       "10  0.000758\n",
       "11  0.000758\n",
       "12  0.000758\n",
       "13  0.000758\n",
       "14  0.000758\n",
       "15  0.000758\n",
       "16  0.000758\n",
       "17  0.000758\n",
       "18  0.000758\n",
       "19  0.000758\n",
       "20  0.000758\n",
       "21  0.000758\n",
       "22  0.000758\n",
       "23  0.000758\n",
       "24  0.000758"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive predictor should be average of y_train (random walk with drift)\n",
    "# Later we will only use 1260 days of rtn \n",
    "y_dummy = pd.DataFrame(np.ones((len(y_test)))*y_train.mean())\n",
    "y_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8f9d3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy r-square                    : -0.015377146309147216\n",
      "Dummy mean_squared_error          : 0.00020907714772480066\n",
      "Dummy roof of mean_squared_error  : 0.014459500258473689\n",
      "Dummy mean_absolute_error         : 0.010867509738256365\n"
     ]
    }
   ],
   "source": [
    "# Naive performance \n",
    "print('Dummy r-square                    :', r2_score(y_test, y_dummy))\n",
    "print('Dummy mean_squared_error          :', mean_squared_error(y_test, y_dummy))\n",
    "print('Dummy roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_dummy)))\n",
    "print('Dummy mean_absolute_error         :', mean_absolute_error(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bf747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "effcf777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong way to check if R-square = 0. Prediction is y_test.mean()\n",
    "y_wrong = pd.DataFrame(np.ones((len(y_test)))*y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2176a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong r-square                    : 0.0\n",
      "Wrong mean_squared_error          : 0.0002059108268142406\n",
      "Wrong roof of mean_squared_error  : 0.014349593263024586\n",
      "Wrong mean_absolute_error         : 0.010708747751731829\n"
     ]
    }
   ],
   "source": [
    "# Wrong-way performance \n",
    "print('Wrong r-square                    :', r2_score(y_test, y_wrong))\n",
    "print('Wrong mean_squared_error          :', mean_squared_error(y_test, y_wrong))\n",
    "print('Wrong roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_wrong)))\n",
    "print('Wrong mean_absolute_error         :', mean_absolute_error(y_test, y_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09373f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ebce9de",
   "metadata": {},
   "source": [
    "#### Explore Ridge() with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cf91c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3ed1cb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.52334898e-16, -1.33815741e-15,  1.36937323e-17,  2.41480870e-17,\n",
       "        2.35591093e-18, -1.88472874e-17, -2.35591093e-17,  0.00000000e+00,\n",
       "       -1.41354656e-17, -1.41354656e-17,  1.17795546e-17,  7.06773278e-18,\n",
       "        4.71182186e-18,  2.35591093e-18,  3.06268421e-17, -7.06773278e-18,\n",
       "        1.17795546e-18, -2.59150202e-17, -2.35591093e-18])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d61af486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_train_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6c87575c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.75833183,  1.13758664,  0.10283418,  0.49943925,  0.0313948 ,\n",
       "       -0.01945304,  0.10951254,  0.13870843,  0.07508294,  0.06415567,\n",
       "        0.10851931,  0.09281854,  0.04235439,  0.12136762,  0.17795915,\n",
       "        0.15129941,  0.09941031,  0.08626705,  0.06027163])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_test_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2d6f186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10', 'log_rtn_lag_0',\n",
       "       'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3', 'log_rtn_lag_4',\n",
       "       'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7', 'log_rtn_lag_8',\n",
       "       'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11', 'log_rtn_lag_12',\n",
       "       'log_rtn_lag_13', 'log_rtn_lag_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6ca0e0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13407713, 0.34533211, 0.91688997, 0.77755319, 0.7938011 ,\n",
       "       0.79422977, 0.61423928, 0.58028839, 0.57038724, 0.57280123,\n",
       "       0.58367649, 0.58730094, 0.55337838, 0.55822118, 0.56199374,\n",
       "       0.58622368, 0.61650102, 0.60148233, 0.64136623])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_test_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e8b27",
   "metadata": {},
   "source": [
    "One can see that X-test has different distribution as compared to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154753a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9111f303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression with scaled data\n",
    "model = Ridge() \n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "678c0be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007577216204191669 [-2.62752029e-04 -3.78274896e-04  4.59294762e-04 -4.47299980e-05\n",
      "  7.97380163e-04 -3.51990656e-04  3.24337556e-04 -5.51158519e-04\n",
      " -1.85661617e-04 -1.81921171e-04  1.83337871e-04 -2.14313577e-04\n",
      "  1.54889581e-04  5.03462683e-04  2.09259811e-04 -5.37670599e-04\n",
      "  1.99627256e-04  3.27791796e-04 -3.66652587e-04] 0.009227869700477287\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train_scaled, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "94f93242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score -0.05754887770947059\n"
     ]
    }
   ],
   "source": [
    "print('test score', model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1647d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03ccd773",
   "metadata": {},
   "source": [
    "#### Explore make_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "037e5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1c9580e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9556c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009227869700477287"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d16c9c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05754887770947059"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81201b",
   "metadata": {},
   "source": [
    "Yes, the results are the same as scale and Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54f003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00daa4be",
   "metadata": {},
   "source": [
    "#### Explore make_pipeline() with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "10d32099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression),\n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7008e75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(score_func=<function f_regression at 0x000001D5FB173940>)),\n",
       "                ('ridge', Ridge())])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e1edb422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007846978132115767"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7bf4cec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06416875114748533"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b52c3",
   "metadata": {},
   "source": [
    "Default value K=10 makes performance a little bit worse.\n",
    "We will not search for the best K here. Our features seem to be reasonable. And Ridge() regression will regularize the coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb94b4b",
   "metadata": {},
   "source": [
    "#### Your own loop for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "35c2d0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesSplit(gap=0, max_train_size=1260, n_splits=5, test_size=25)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliding_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8f99233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a0558771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores_mse: [8.43370109390319e-05, 0.0002433139301285659, 0.00011397579904436861, 0.000200012656651408, 0.00023050699172999352]\n",
      "Avg. score_mse: 0.00017442927769867358\n",
      "Scores_r2: [-0.020007715713973084, -0.07342072284648093, -0.14169032578985052, -0.009420191435117742, 0.003388689541106382]\n",
      "Avg. score_r2: -0.04823005324886318\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipe. This is with scaling.\n",
    "scores_mse = [] \n",
    "scores_r2 = []\n",
    "\n",
    "for main_ind, valid_ind in sliding_cv.split(X_train):\n",
    "    pipe.fit(X_train.iloc[main_ind], y_train.iloc[main_ind])\n",
    "    y_valid_pred = pipe.predict(X_train.iloc[valid_ind])\n",
    "    scores_mse.append(mean_squared_error(y_train.iloc[valid_ind], y_valid_pred))\n",
    "    scores_r2.append(r2_score(y_train.iloc[valid_ind], y_valid_pred))\n",
    "print(f\"Scores_mse: {scores_mse}\")\n",
    "print(f\"Avg. score_mse: {np.mean(scores_mse)}\")\n",
    "print(f\"Scores_r2: {scores_r2}\")\n",
    "print(f\"Avg. score_r2: {np.mean(scores_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f330453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.020008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.073421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.141690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error   test_r2\n",
       "0  0.003989    0.001995                    -0.000084 -0.020008\n",
       "1  0.003990    0.001994                    -0.000243 -0.073421\n",
       "2  0.002992    0.001994                    -0.000114 -0.141690\n",
       "3  0.002992    0.000997                    -0.000200 -0.009420\n",
       "4  0.002993    0.000997                    -0.000231  0.003389"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_validate() for cross-validation:\n",
    "cv_scores = cross_validate(\n",
    "    pipe, \n",
    "    X_train, y_train, \n",
    "    cv=sliding_cv, \n",
    "    scoring=[\"neg_mean_squared_error\", \n",
    "             \"r2\"]\n",
    ")\n",
    "pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97006d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59069e7f",
   "metadata": {},
   "source": [
    "#### Explore GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c5ce962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2c87c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ridge__alpha': 1}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.640474           0.0              0.0             0.0   \n",
       "\n",
       "  param_ridge__alpha               params  split0_test_score  \\\n",
       "0                  1  {'ridge__alpha': 1}          -0.000084   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.000243          -0.000114            -0.0002          -0.000231   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.000174        0.000064                1  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV with default hyperparameters\n",
    "param = {'ridge__alpha': [1]}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Yes, the numbers are the same as I had above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eef998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3750d113",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years), without month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "57da0db6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05,\n",
       " 2.3357214690901213e-05,\n",
       " 5.4555947811685143e-05,\n",
       " 0.00012742749857031334,\n",
       " 0.00029763514416313193,\n",
       " 0.0006951927961775605,\n",
       " 0.001623776739188721,\n",
       " 0.00379269019073225,\n",
       " 0.008858667904100823,\n",
       " 0.02069138081114788,\n",
       " 0.04832930238571752,\n",
       " 0.11288378916846883,\n",
       " 0.26366508987303555,\n",
       " 0.6158482110660255,\n",
       " 1.438449888287663,\n",
       " 3.359818286283781,\n",
       " 7.847599703514606,\n",
       " 18.32980710832434,\n",
       " 42.81332398719387,\n",
       " 100.0]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [n for n in np.logspace(-5, 2, num=20, endpoint=True, base=10.0)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c2a03115",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "061c76e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'ridge__alpha': 100.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42.813324</td>\n",
       "      <td>{'ridge__alpha': 42.81332398719387}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>18.329807</td>\n",
       "      <td>{'ridge__alpha': 18.32980710832434}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>8.664155e-04</td>\n",
       "      <td>7.8476</td>\n",
       "      <td>{'ridge__alpha': 7.847599703514606}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.995184e-04</td>\n",
       "      <td>3.359818</td>\n",
       "      <td>{'ridge__alpha': 3.359818286283781}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.876637e-04</td>\n",
       "      <td>1.43845</td>\n",
       "      <td>{'ridge__alpha': 1.438449888287663}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.884998e-04</td>\n",
       "      <td>0.615848</td>\n",
       "      <td>{'ridge__alpha': 0.6158482110660255}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>3.021572e-03</td>\n",
       "      <td>0.263665</td>\n",
       "      <td>{'ridge__alpha': 0.26366508987303555}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>3.725184e-03</td>\n",
       "      <td>0.112884</td>\n",
       "      <td>{'ridge__alpha': 0.11288378916846883}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>3.308511e-03</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>{'ridge__alpha': 0.04832930238571752}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>9.770774e-04</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>{'ridge__alpha': 0.02069138081114788}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>9.635802e-04</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>{'ridge__alpha': 0.008858667904100823}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.989487e-04</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>{'ridge__alpha': 0.00379269019073225}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.890840e-04</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>{'ridge__alpha': 0.001623776739188721}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.385292e-06</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>{'ridge__alpha': 0.0006951927961775605}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.983981e-04</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>{'ridge__alpha': 0.00029763514416313193}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>9.464947e-07</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>{'ridge__alpha': 0.00012742749857031334}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.993116e-04</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>{'ridge__alpha': 5.4555947811685143e-05}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.885779e-04</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>{'ridge__alpha': 2.3357214690901213e-05}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295794</td>\n",
       "      <td>0.357792</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>6.677773e-03</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'ridge__alpha': 1e-05}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "19       0.003124      0.006248         0.000000    0.000000e+00   \n",
       "18       0.009372      0.007653         0.000000    0.000000e+00   \n",
       "17       0.000000      0.000000         0.000000    0.000000e+00   \n",
       "16       0.003907      0.001034         0.000716    8.664155e-04   \n",
       "15       0.004786      0.000747         0.001795    3.995184e-04   \n",
       "14       0.006370      0.003891         0.001596    4.876637e-04   \n",
       "13       0.007550      0.003622         0.001596    4.884998e-04   \n",
       "12       0.005518      0.004872         0.003178    3.021572e-03   \n",
       "11       0.006078      0.004519         0.002780    3.725184e-03   \n",
       "10       0.004786      0.002556         0.002548    3.308511e-03   \n",
       "9        0.007519      0.003236         0.001197    9.770774e-04   \n",
       "8        0.005259      0.001607         0.001356    9.635802e-04   \n",
       "7        0.004985      0.000631         0.001795    3.989487e-04   \n",
       "6        0.005186      0.000746         0.001595    4.890840e-04   \n",
       "5        0.004986      0.000630         0.001995    1.385292e-06   \n",
       "4        0.004986      0.000630         0.001795    3.983981e-04   \n",
       "3        0.005186      0.000399         0.001995    9.464947e-07   \n",
       "2        0.005188      0.000399         0.001795    3.993116e-04   \n",
       "1        0.004588      0.000488         0.001396    4.885779e-04   \n",
       "0        0.295794      0.357792         0.007447    6.677773e-03   \n",
       "\n",
       "   param_ridge__alpha                                    params  \\\n",
       "19              100.0                   {'ridge__alpha': 100.0}   \n",
       "18          42.813324       {'ridge__alpha': 42.81332398719387}   \n",
       "17          18.329807       {'ridge__alpha': 18.32980710832434}   \n",
       "16             7.8476       {'ridge__alpha': 7.847599703514606}   \n",
       "15           3.359818       {'ridge__alpha': 3.359818286283781}   \n",
       "14            1.43845       {'ridge__alpha': 1.438449888287663}   \n",
       "13           0.615848      {'ridge__alpha': 0.6158482110660255}   \n",
       "12           0.263665     {'ridge__alpha': 0.26366508987303555}   \n",
       "11           0.112884     {'ridge__alpha': 0.11288378916846883}   \n",
       "10           0.048329     {'ridge__alpha': 0.04832930238571752}   \n",
       "9            0.020691     {'ridge__alpha': 0.02069138081114788}   \n",
       "8            0.008859    {'ridge__alpha': 0.008858667904100823}   \n",
       "7            0.003793     {'ridge__alpha': 0.00379269019073225}   \n",
       "6            0.001624    {'ridge__alpha': 0.001623776739188721}   \n",
       "5            0.000695   {'ridge__alpha': 0.0006951927961775605}   \n",
       "4            0.000298  {'ridge__alpha': 0.00029763514416313193}   \n",
       "3            0.000127  {'ridge__alpha': 0.00012742749857031334}   \n",
       "2            0.000055  {'ridge__alpha': 5.4555947811685143e-05}   \n",
       "1            0.000023  {'ridge__alpha': 2.3357214690901213e-05}   \n",
       "0             0.00001                   {'ridge__alpha': 1e-05}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "19          -0.000084          -0.000242          -0.000113   \n",
       "18          -0.000084          -0.000243          -0.000114   \n",
       "17          -0.000084          -0.000243          -0.000114   \n",
       "16          -0.000084          -0.000243          -0.000114   \n",
       "15          -0.000084          -0.000243          -0.000114   \n",
       "14          -0.000084          -0.000243          -0.000114   \n",
       "13          -0.000084          -0.000243          -0.000114   \n",
       "12          -0.000084          -0.000243          -0.000114   \n",
       "11          -0.000084          -0.000243          -0.000114   \n",
       "10          -0.000084          -0.000243          -0.000114   \n",
       "9           -0.000084          -0.000243          -0.000114   \n",
       "8           -0.000084          -0.000243          -0.000114   \n",
       "7           -0.000084          -0.000243          -0.000114   \n",
       "6           -0.000084          -0.000243          -0.000114   \n",
       "5           -0.000084          -0.000243          -0.000114   \n",
       "4           -0.000084          -0.000243          -0.000114   \n",
       "3           -0.000084          -0.000243          -0.000114   \n",
       "2           -0.000084          -0.000243          -0.000114   \n",
       "1           -0.000084          -0.000243          -0.000114   \n",
       "0           -0.000084          -0.000243          -0.000114   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "19            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "18            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "17            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "16            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "15            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "14            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "13            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "12            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "11            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "10            -0.0002          -0.000231        -0.000174        0.000064   \n",
       "9             -0.0002          -0.000231        -0.000174        0.000064   \n",
       "8             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "7             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "6             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "5             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "4             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "3             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "2             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "1             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "0             -0.0002          -0.000230        -0.000174        0.000064   \n",
       "\n",
       "    rank_test_score  \n",
       "19                1  \n",
       "18                2  \n",
       "17                3  \n",
       "16                4  \n",
       "15                5  \n",
       "14                6  \n",
       "13                7  \n",
       "12                8  \n",
       "11                9  \n",
       "10               10  \n",
       "9                11  \n",
       "8                12  \n",
       "7                13  \n",
       "6                14  \n",
       "5                15  \n",
       "4                16  \n",
       "3                17  \n",
       "2                18  \n",
       "1                19  \n",
       "0                20  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# From this results, all have similar mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e283528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 100.0}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6121d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6deb5cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'ridge__alpha': 100.0}</td>\n",
       "      <td>-0.016842</td>\n",
       "      <td>-0.068997</td>\n",
       "      <td>-0.132925</td>\n",
       "      <td>-0.008234</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>-0.045271</td>\n",
       "      <td>0.050068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>42.813324</td>\n",
       "      <td>{'ridge__alpha': 42.81332398719387}</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>-0.071416</td>\n",
       "      <td>-0.137805</td>\n",
       "      <td>-0.008888</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>-0.046906</td>\n",
       "      <td>0.051997</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.329807</td>\n",
       "      <td>{'ridge__alpha': 18.32980710832434}</td>\n",
       "      <td>-0.019400</td>\n",
       "      <td>-0.072563</td>\n",
       "      <td>-0.140046</td>\n",
       "      <td>-0.009194</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>-0.047667</td>\n",
       "      <td>0.052890</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.8476</td>\n",
       "      <td>{'ridge__alpha': 7.847599703514606}</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.073077</td>\n",
       "      <td>-0.141035</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>-0.048005</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>3.359818</td>\n",
       "      <td>{'ridge__alpha': 3.359818286283781}</td>\n",
       "      <td>-0.019923</td>\n",
       "      <td>-0.073302</td>\n",
       "      <td>-0.141464</td>\n",
       "      <td>-0.009389</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>-0.048152</td>\n",
       "      <td>0.053456</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1.43845</td>\n",
       "      <td>{'ridge__alpha': 1.438449888287663}</td>\n",
       "      <td>-0.019992</td>\n",
       "      <td>-0.073399</td>\n",
       "      <td>-0.141648</td>\n",
       "      <td>-0.009414</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>-0.048216</td>\n",
       "      <td>0.053530</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.615848</td>\n",
       "      <td>{'ridge__alpha': 0.6158482110660255}</td>\n",
       "      <td>-0.020021</td>\n",
       "      <td>-0.073440</td>\n",
       "      <td>-0.141727</td>\n",
       "      <td>-0.009425</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>-0.048243</td>\n",
       "      <td>0.053562</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.263665</td>\n",
       "      <td>{'ridge__alpha': 0.26366508987303555}</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>-0.073458</td>\n",
       "      <td>-0.141761</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>-0.048254</td>\n",
       "      <td>0.053576</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.112884</td>\n",
       "      <td>{'ridge__alpha': 0.11288378916846883}</td>\n",
       "      <td>-0.020040</td>\n",
       "      <td>-0.073466</td>\n",
       "      <td>-0.141776</td>\n",
       "      <td>-0.009432</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>-0.048259</td>\n",
       "      <td>0.053582</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>{'ridge__alpha': 0.04832930238571752}</td>\n",
       "      <td>-0.020042</td>\n",
       "      <td>-0.073469</td>\n",
       "      <td>-0.141782</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>-0.048262</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>{'ridge__alpha': 0.02069138081114788}</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>-0.141785</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048262</td>\n",
       "      <td>0.053585</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>{'ridge__alpha': 0.008858667904100823}</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141786</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>{'ridge__alpha': 0.00379269019073225}</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141786</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>{'ridge__alpha': 0.001623776739188721}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>{'ridge__alpha': 0.0006951927961775605}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009433</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>{'ridge__alpha': 0.00029763514416313193}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>{'ridge__alpha': 0.00012742749857031334}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>{'ridge__alpha': 5.4555947811685143e-05}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>{'ridge__alpha': 2.3357214690901213e-05}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'ridge__alpha': 1e-05}</td>\n",
       "      <td>-0.020044</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.141787</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.048263</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "19       0.003125      0.006249         0.000000        0.000000   \n",
       "18       0.006249      0.007654         0.003125        0.006249   \n",
       "17       0.000000      0.000000         0.000000        0.000000   \n",
       "16       0.001449      0.001341         0.000000        0.000000   \n",
       "15       0.003191      0.000399         0.001197        0.000399   \n",
       "14       0.003591      0.000797         0.001197        0.000399   \n",
       "13       0.003591      0.000799         0.001595        0.000488   \n",
       "12       0.005848      0.003301         0.001795        0.000399   \n",
       "11       0.006709      0.003140         0.001596        0.000488   \n",
       "10       0.003151      0.004032         0.003913        0.003263   \n",
       "9        0.005764      0.003294         0.001599        0.001356   \n",
       "8        0.004537      0.001446         0.002161        0.001534   \n",
       "7        0.005923      0.000593         0.001241        0.000797   \n",
       "6        0.005240      0.000989         0.001397        0.000798   \n",
       "5        0.005076      0.000567         0.002003        0.001209   \n",
       "4        0.004588      0.000798         0.002194        0.000399   \n",
       "3        0.004588      0.000489         0.001396        0.000488   \n",
       "2        0.004588      0.000798         0.001795        0.000400   \n",
       "1        0.004188      0.000746         0.001197        0.000399   \n",
       "0        0.004788      0.000399         0.001596        0.000489   \n",
       "\n",
       "   param_ridge__alpha                                    params  \\\n",
       "19              100.0                   {'ridge__alpha': 100.0}   \n",
       "18          42.813324       {'ridge__alpha': 42.81332398719387}   \n",
       "17          18.329807       {'ridge__alpha': 18.32980710832434}   \n",
       "16             7.8476       {'ridge__alpha': 7.847599703514606}   \n",
       "15           3.359818       {'ridge__alpha': 3.359818286283781}   \n",
       "14            1.43845       {'ridge__alpha': 1.438449888287663}   \n",
       "13           0.615848      {'ridge__alpha': 0.6158482110660255}   \n",
       "12           0.263665     {'ridge__alpha': 0.26366508987303555}   \n",
       "11           0.112884     {'ridge__alpha': 0.11288378916846883}   \n",
       "10           0.048329     {'ridge__alpha': 0.04832930238571752}   \n",
       "9            0.020691     {'ridge__alpha': 0.02069138081114788}   \n",
       "8            0.008859    {'ridge__alpha': 0.008858667904100823}   \n",
       "7            0.003793     {'ridge__alpha': 0.00379269019073225}   \n",
       "6            0.001624    {'ridge__alpha': 0.001623776739188721}   \n",
       "5            0.000695   {'ridge__alpha': 0.0006951927961775605}   \n",
       "4            0.000298  {'ridge__alpha': 0.00029763514416313193}   \n",
       "3            0.000127  {'ridge__alpha': 0.00012742749857031334}   \n",
       "2            0.000055  {'ridge__alpha': 5.4555947811685143e-05}   \n",
       "1            0.000023  {'ridge__alpha': 2.3357214690901213e-05}   \n",
       "0             0.00001                   {'ridge__alpha': 1e-05}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "19          -0.016842          -0.068997          -0.132925   \n",
       "18          -0.018582          -0.071416          -0.137805   \n",
       "17          -0.019400          -0.072563          -0.140046   \n",
       "16          -0.019764          -0.073077          -0.141035   \n",
       "15          -0.019923          -0.073302          -0.141464   \n",
       "14          -0.019992          -0.073399          -0.141648   \n",
       "13          -0.020021          -0.073440          -0.141727   \n",
       "12          -0.020034          -0.073458          -0.141761   \n",
       "11          -0.020040          -0.073466          -0.141776   \n",
       "10          -0.020042          -0.073469          -0.141782   \n",
       "9           -0.020043          -0.073470          -0.141785   \n",
       "8           -0.020043          -0.073471          -0.141786   \n",
       "7           -0.020043          -0.073471          -0.141786   \n",
       "6           -0.020044          -0.073471          -0.141787   \n",
       "5           -0.020044          -0.073471          -0.141787   \n",
       "4           -0.020044          -0.073471          -0.141787   \n",
       "3           -0.020044          -0.073471          -0.141787   \n",
       "2           -0.020044          -0.073471          -0.141787   \n",
       "1           -0.020044          -0.073471          -0.141787   \n",
       "0           -0.020044          -0.073471          -0.141787   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "19          -0.008234           0.000641        -0.045271        0.050068   \n",
       "18          -0.008888           0.002161        -0.046906        0.051997   \n",
       "17          -0.009194           0.002866        -0.047667        0.052890   \n",
       "16          -0.009330           0.003180        -0.048005        0.053285   \n",
       "15          -0.009389           0.003316        -0.048152        0.053456   \n",
       "14          -0.009414           0.003375        -0.048216        0.053530   \n",
       "13          -0.009425           0.003401        -0.048243        0.053562   \n",
       "12          -0.009430           0.003411        -0.048254        0.053576   \n",
       "11          -0.009432           0.003416        -0.048259        0.053582   \n",
       "10          -0.009433           0.003418        -0.048262        0.053584   \n",
       "9           -0.009433           0.003419        -0.048262        0.053585   \n",
       "8           -0.009433           0.003419        -0.048263        0.053586   \n",
       "7           -0.009433           0.003419        -0.048263        0.053586   \n",
       "6           -0.009433           0.003419        -0.048263        0.053586   \n",
       "5           -0.009433           0.003419        -0.048263        0.053586   \n",
       "4           -0.009434           0.003419        -0.048263        0.053586   \n",
       "3           -0.009434           0.003419        -0.048263        0.053586   \n",
       "2           -0.009434           0.003419        -0.048263        0.053586   \n",
       "1           -0.009434           0.003419        -0.048263        0.053586   \n",
       "0           -0.009434           0.003419        -0.048263        0.053586   \n",
       "\n",
       "    rank_test_score  \n",
       "19                1  \n",
       "18                2  \n",
       "17                3  \n",
       "16                4  \n",
       "15                5  \n",
       "14                6  \n",
       "13                7  \n",
       "12                8  \n",
       "11                9  \n",
       "10               10  \n",
       "9                11  \n",
       "8                12  \n",
       "7                13  \n",
       "6                14  \n",
       "5                15  \n",
       "4                16  \n",
       "3                17  \n",
       "2                18  \n",
       "1                19  \n",
       "0                20  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV with default scoring of R-square\n",
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  )\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# alpha = 100 does have better R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff003ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dcc612",
   "metadata": {},
   "source": [
    "Sweep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "70c74e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let investigate for bigger value of alpha\n",
    "alpha = [n for n in np.logspace(1, 8, num=8, endpoint=True, base=10.0)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "77af98d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>5.352484e-07</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.997565e-04</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>{'ridge__alpha': 10000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>4.884031e-04</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.300739e-04</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>{'ridge__alpha': 100000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005783</td>\n",
       "      <td>3.992336e-04</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.572747e-07</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>{'ridge__alpha': 1000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>4.884805e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.990174e-04</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>{'ridge__alpha': 10000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004587</td>\n",
       "      <td>4.884806e-04</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.884220e-04</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>{'ridge__alpha': 100000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>4.888893e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.992799e-04</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'ridge__alpha': 1000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.885972e-04</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.988029e-04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'ridge__alpha': 100.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>1.016354e-03</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.989936e-04</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'ridge__alpha': 10.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.004988  5.352484e-07         0.001795    3.997565e-04   \n",
       "4       0.005386  4.884031e-04         0.001994    6.300739e-04   \n",
       "5       0.005783  3.992336e-04         0.001995    6.572747e-07   \n",
       "6       0.005385  4.884805e-04         0.001795    3.990174e-04   \n",
       "7       0.004587  4.884806e-04         0.001396    4.884220e-04   \n",
       "2       0.005386  4.888893e-04         0.001795    3.992799e-04   \n",
       "1       0.004388  4.885972e-04         0.001796    3.988029e-04   \n",
       "0       0.004389  1.016354e-03         0.001197    3.989936e-04   \n",
       "\n",
       "  param_ridge__alpha                         params  split0_test_score  \\\n",
       "3            10000.0      {'ridge__alpha': 10000.0}          -0.000083   \n",
       "4           100000.0     {'ridge__alpha': 100000.0}          -0.000083   \n",
       "5          1000000.0    {'ridge__alpha': 1000000.0}          -0.000083   \n",
       "6         10000000.0   {'ridge__alpha': 10000000.0}          -0.000083   \n",
       "7        100000000.0  {'ridge__alpha': 100000000.0}          -0.000083   \n",
       "2             1000.0       {'ridge__alpha': 1000.0}          -0.000083   \n",
       "1              100.0        {'ridge__alpha': 100.0}          -0.000084   \n",
       "0               10.0         {'ridge__alpha': 10.0}          -0.000084   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3          -0.000236          -0.000105          -0.000198          -0.000238   \n",
       "4          -0.000236          -0.000105          -0.000198          -0.000240   \n",
       "5          -0.000236          -0.000105          -0.000198          -0.000240   \n",
       "6          -0.000236          -0.000105          -0.000198          -0.000240   \n",
       "7          -0.000236          -0.000105          -0.000198          -0.000240   \n",
       "2          -0.000239          -0.000109          -0.000199          -0.000234   \n",
       "1          -0.000242          -0.000113          -0.000200          -0.000231   \n",
       "0          -0.000243          -0.000114          -0.000200          -0.000231   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3        -0.000172        0.000066                1  \n",
       "4        -0.000172        0.000066                2  \n",
       "5        -0.000172        0.000066                3  \n",
       "6        -0.000172        0.000066                4  \n",
       "7        -0.000172        0.000066                5  \n",
       "2        -0.000173        0.000065                6  \n",
       "1        -0.000174        0.000064                7  \n",
       "0        -0.000174        0.000064                8  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d059500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seem like between e4 and e8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3dd828",
   "metadata": {},
   "source": [
    "Sweep 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "055c816b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000.0,\n",
       " 1832.9807108324355,\n",
       " 3359.818286283781,\n",
       " 6158.482110660267,\n",
       " 11288.378916846883,\n",
       " 20691.3808111479,\n",
       " 37926.901907322535,\n",
       " 69519.27961775605,\n",
       " 127427.49857031321,\n",
       " 233572.14690901214,\n",
       " 428133.2398719396,\n",
       " 784759.9703514606,\n",
       " 1438449.888287663,\n",
       " 2636650.8987303553,\n",
       " 4832930.238571752,\n",
       " 8858667.904100832,\n",
       " 16237767.391887208,\n",
       " 29763514.416313194,\n",
       " 54555947.811685145,\n",
       " 100000000.0]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [n for n in np.logspace(3, 8, num=20, endpoint=True, base=10.0)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "06e61458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.990420e-04</td>\n",
       "      <td>6158.482111</td>\n",
       "      <td>{'ridge__alpha': 6158.482110660267}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.884220e-04</td>\n",
       "      <td>11288.378917</td>\n",
       "      <td>{'ridge__alpha': 11288.378916846883}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.998286e-04</td>\n",
       "      <td>20691.380811</td>\n",
       "      <td>{'ridge__alpha': 20691.3808111479}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>1.811981e-06</td>\n",
       "      <td>37926.901907</td>\n",
       "      <td>{'ridge__alpha': 37926.901907322535}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>8.971638e-07</td>\n",
       "      <td>3359.818286</td>\n",
       "      <td>{'ridge__alpha': 3359.818286283781}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.891814e-04</td>\n",
       "      <td>69519.279618</td>\n",
       "      <td>{'ridge__alpha': 69519.27961775605}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>7.976415e-04</td>\n",
       "      <td>127427.49857</td>\n",
       "      <td>{'ridge__alpha': 127427.49857031321}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>5.211530e-03</td>\n",
       "      <td>233572.146909</td>\n",
       "      <td>{'ridge__alpha': 233572.14690901214}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.006556</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>6.797372e-03</td>\n",
       "      <td>428133.239872</td>\n",
       "      <td>{'ridge__alpha': 428133.2398719396}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>5.072463e-03</td>\n",
       "      <td>784759.970351</td>\n",
       "      <td>{'ridge__alpha': 784759.9703514606}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>3.047708e-04</td>\n",
       "      <td>1438449.888288</td>\n",
       "      <td>{'ridge__alpha': 1438449.888287663}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>7.978201e-04</td>\n",
       "      <td>2636650.89873</td>\n",
       "      <td>{'ridge__alpha': 2636650.8987303553}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.309019e-04</td>\n",
       "      <td>4832930.238572</td>\n",
       "      <td>{'ridge__alpha': 4832930.238571752}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.988266e-04</td>\n",
       "      <td>8858667.904101</td>\n",
       "      <td>{'ridge__alpha': 8858667.904100832}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.886166e-04</td>\n",
       "      <td>16237767.391887</td>\n",
       "      <td>{'ridge__alpha': 16237767.391887208}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.991366e-04</td>\n",
       "      <td>29763514.416313</td>\n",
       "      <td>{'ridge__alpha': 29763514.416313194}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.986359e-04</td>\n",
       "      <td>54555947.811685</td>\n",
       "      <td>{'ridge__alpha': 54555947.811685145}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>3.936648e-04</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>{'ridge__alpha': 100000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>3.986837e-04</td>\n",
       "      <td>1832.980711</td>\n",
       "      <td>{'ridge__alpha': 1832.9807108324355}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.991604e-04</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'ridge__alpha': 1000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.005386      0.000489         0.001796    3.990420e-04   \n",
       "4        0.004987      0.000631         0.001596    4.884220e-04   \n",
       "5        0.005188      0.000745         0.001795    3.998286e-04   \n",
       "6        0.004790      0.000399         0.001993    1.811981e-06   \n",
       "2        0.004587      0.000798         0.001995    8.971638e-07   \n",
       "7        0.005385      0.000491         0.001596    4.891814e-04   \n",
       "8        0.003572      0.001527         0.001396    7.976415e-04   \n",
       "9        0.002677      0.005354         0.003077    5.211530e-03   \n",
       "10       0.003278      0.006556         0.003874    6.797372e-03   \n",
       "11       0.008148      0.005941         0.004274    5.072463e-03   \n",
       "12       0.011825      0.006928         0.001842    3.047708e-04   \n",
       "13       0.003931      0.001828         0.000598    7.978201e-04   \n",
       "14       0.005033      0.001812         0.000997    6.309019e-04   \n",
       "15       0.003191      0.000399         0.001197    3.988266e-04   \n",
       "16       0.003590      0.000798         0.001396    4.886166e-04   \n",
       "17       0.003590      0.000798         0.001197    3.991366e-04   \n",
       "18       0.003191      0.000399         0.001197    3.986359e-04   \n",
       "19       0.002219      0.001463         0.000212    3.936648e-04   \n",
       "1        0.004387      0.000798         0.001196    3.986837e-04   \n",
       "0        0.004390      0.000797         0.001795    3.991604e-04   \n",
       "\n",
       "   param_ridge__alpha                                params  \\\n",
       "3         6158.482111   {'ridge__alpha': 6158.482110660267}   \n",
       "4        11288.378917  {'ridge__alpha': 11288.378916846883}   \n",
       "5        20691.380811    {'ridge__alpha': 20691.3808111479}   \n",
       "6        37926.901907  {'ridge__alpha': 37926.901907322535}   \n",
       "2         3359.818286   {'ridge__alpha': 3359.818286283781}   \n",
       "7        69519.279618   {'ridge__alpha': 69519.27961775605}   \n",
       "8        127427.49857  {'ridge__alpha': 127427.49857031321}   \n",
       "9       233572.146909  {'ridge__alpha': 233572.14690901214}   \n",
       "10      428133.239872   {'ridge__alpha': 428133.2398719396}   \n",
       "11      784759.970351   {'ridge__alpha': 784759.9703514606}   \n",
       "12     1438449.888288   {'ridge__alpha': 1438449.888287663}   \n",
       "13      2636650.89873  {'ridge__alpha': 2636650.8987303553}   \n",
       "14     4832930.238572   {'ridge__alpha': 4832930.238571752}   \n",
       "15     8858667.904101   {'ridge__alpha': 8858667.904100832}   \n",
       "16    16237767.391887  {'ridge__alpha': 16237767.391887208}   \n",
       "17    29763514.416313  {'ridge__alpha': 29763514.416313194}   \n",
       "18    54555947.811685  {'ridge__alpha': 54555947.811685145}   \n",
       "19        100000000.0         {'ridge__alpha': 100000000.0}   \n",
       "1         1832.980711  {'ridge__alpha': 1832.9807108324355}   \n",
       "0              1000.0              {'ridge__alpha': 1000.0}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "3           -0.000083          -0.000237          -0.000106   \n",
       "4           -0.000083          -0.000236          -0.000105   \n",
       "5           -0.000083          -0.000236          -0.000105   \n",
       "6           -0.000083          -0.000236          -0.000105   \n",
       "2           -0.000083          -0.000237          -0.000106   \n",
       "7           -0.000083          -0.000236          -0.000105   \n",
       "8           -0.000083          -0.000236          -0.000105   \n",
       "9           -0.000083          -0.000236          -0.000105   \n",
       "10          -0.000083          -0.000236          -0.000105   \n",
       "11          -0.000083          -0.000236          -0.000105   \n",
       "12          -0.000083          -0.000236          -0.000105   \n",
       "13          -0.000083          -0.000236          -0.000105   \n",
       "14          -0.000083          -0.000236          -0.000105   \n",
       "15          -0.000083          -0.000236          -0.000105   \n",
       "16          -0.000083          -0.000236          -0.000105   \n",
       "17          -0.000083          -0.000236          -0.000105   \n",
       "18          -0.000083          -0.000236          -0.000105   \n",
       "19          -0.000083          -0.000236          -0.000105   \n",
       "1           -0.000083          -0.000238          -0.000108   \n",
       "0           -0.000083          -0.000239          -0.000109   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "3           -0.000198          -0.000238        -0.000172        0.000066   \n",
       "4           -0.000198          -0.000239        -0.000172        0.000066   \n",
       "5           -0.000198          -0.000239        -0.000172        0.000066   \n",
       "6           -0.000198          -0.000239        -0.000172        0.000066   \n",
       "2           -0.000198          -0.000237        -0.000172        0.000065   \n",
       "7           -0.000198          -0.000240        -0.000172        0.000066   \n",
       "8           -0.000198          -0.000240        -0.000172        0.000066   \n",
       "9           -0.000198          -0.000240        -0.000172        0.000066   \n",
       "10          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "11          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "12          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "13          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "14          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "15          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "16          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "17          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "18          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "19          -0.000198          -0.000240        -0.000172        0.000066   \n",
       "1           -0.000199          -0.000236        -0.000172        0.000065   \n",
       "0           -0.000199          -0.000234        -0.000173        0.000065   \n",
       "\n",
       "    rank_test_score  \n",
       "3                 1  \n",
       "4                 2  \n",
       "5                 3  \n",
       "6                 4  \n",
       "2                 5  \n",
       "7                 6  \n",
       "8                 7  \n",
       "9                 8  \n",
       "10                9  \n",
       "11               10  \n",
       "12               11  \n",
       "13               12  \n",
       "14               13  \n",
       "15               14  \n",
       "16               15  \n",
       "17               16  \n",
       "18               17  \n",
       "19               18  \n",
       "1                19  \n",
       "0                20  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "23953d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 6158.482110660267}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seem like between 5000 and 20000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733917b6",
   "metadata": {},
   "source": [
    "Sweep 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8eaa2981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000.0,\n",
       " 5750.0,\n",
       " 6500.0,\n",
       " 7250.0,\n",
       " 8000.0,\n",
       " 8750.0,\n",
       " 9500.0,\n",
       " 10250.0,\n",
       " 11000.0,\n",
       " 11750.0,\n",
       " 12500.0,\n",
       " 13250.0,\n",
       " 14000.0,\n",
       " 14750.0,\n",
       " 15500.0,\n",
       " 16250.0,\n",
       " 17000.0,\n",
       " 17750.0,\n",
       " 18500.0,\n",
       " 19250.0,\n",
       " 20000.0]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [n for n in np.linspace(5000, 20000, num=21, endpoint=True)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ff406c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>1.934028e-03</td>\n",
       "      <td>7250.0</td>\n",
       "      <td>{'ridge__alpha': 7250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.988270e-04</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>{'ridge__alpha': 6500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.887727e-04</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>{'ridge__alpha': 8000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.308264e-04</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>{'ridge__alpha': 8750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>1.017130e-03</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>{'ridge__alpha': 5750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>1.620446e-03</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>{'ridge__alpha': 9500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>2.848299e-03</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>{'ridge__alpha': 10250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>3.991134e-04</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>{'ridge__alpha': 11000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>1.933600e-03</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>{'ridge__alpha': 5000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.991605e-04</td>\n",
       "      <td>11750.0</td>\n",
       "      <td>{'ridge__alpha': 11750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.988992e-04</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>{'ridge__alpha': 12500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>4.877212e-04</td>\n",
       "      <td>13250.0</td>\n",
       "      <td>{'ridge__alpha': 13250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>2.780415e-07</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>{'ridge__alpha': 14000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.887335e-04</td>\n",
       "      <td>14750.0</td>\n",
       "      <td>{'ridge__alpha': 14750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.143617e-07</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>{'ridge__alpha': 15500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.984933e-04</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>{'ridge__alpha': 16250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>7.294206e-07</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>{'ridge__alpha': 17000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>3.115659e-03</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>{'ridge__alpha': 17750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>{'ridge__alpha': 18500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>9.770969e-04</td>\n",
       "      <td>19250.0</td>\n",
       "      <td>{'ridge__alpha': 19250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.886362e-04</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>{'ridge__alpha': 20000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        0.009973      0.006016         0.003192    1.934028e-03   \n",
       "2        0.009574      0.003602         0.002194    3.988270e-04   \n",
       "4        0.007180      0.002474         0.002394    4.887727e-04   \n",
       "5        0.006582      0.001353         0.001995    6.308264e-04   \n",
       "1        0.008430      0.002543         0.001596    1.017130e-03   \n",
       "6        0.009773      0.002394         0.003590    1.620446e-03   \n",
       "7        0.007779      0.001163         0.004189    2.848299e-03   \n",
       "8        0.008377      0.002932         0.002793    3.991134e-04   \n",
       "0        0.020345      0.005069         0.003192    1.933600e-03   \n",
       "9        0.006982      0.001784         0.001795    3.991605e-04   \n",
       "10       0.005785      0.000399         0.002194    3.988992e-04   \n",
       "11       0.006982      0.001996         0.002392    4.877212e-04   \n",
       "12       0.005785      0.000399         0.001994    2.780415e-07   \n",
       "13       0.006183      0.000977         0.002394    4.887335e-04   \n",
       "14       0.005984      0.000631         0.001995    6.143617e-07   \n",
       "15       0.005385      0.000489         0.002194    3.984933e-04   \n",
       "16       0.005784      0.000398         0.001995    7.294206e-07   \n",
       "17       0.006782      0.002222         0.003789    3.115659e-03   \n",
       "18       0.006383      0.000488         0.002194    3.991850e-04   \n",
       "19       0.005385      0.000488         0.002194    9.770969e-04   \n",
       "20       0.005585      0.000798         0.002394    4.886362e-04   \n",
       "\n",
       "   param_ridge__alpha                     params  split0_test_score  \\\n",
       "3              7250.0   {'ridge__alpha': 7250.0}          -0.000083   \n",
       "2              6500.0   {'ridge__alpha': 6500.0}          -0.000083   \n",
       "4              8000.0   {'ridge__alpha': 8000.0}          -0.000083   \n",
       "5              8750.0   {'ridge__alpha': 8750.0}          -0.000083   \n",
       "1              5750.0   {'ridge__alpha': 5750.0}          -0.000083   \n",
       "6              9500.0   {'ridge__alpha': 9500.0}          -0.000083   \n",
       "7             10250.0  {'ridge__alpha': 10250.0}          -0.000083   \n",
       "8             11000.0  {'ridge__alpha': 11000.0}          -0.000083   \n",
       "0              5000.0   {'ridge__alpha': 5000.0}          -0.000083   \n",
       "9             11750.0  {'ridge__alpha': 11750.0}          -0.000083   \n",
       "10            12500.0  {'ridge__alpha': 12500.0}          -0.000083   \n",
       "11            13250.0  {'ridge__alpha': 13250.0}          -0.000083   \n",
       "12            14000.0  {'ridge__alpha': 14000.0}          -0.000083   \n",
       "13            14750.0  {'ridge__alpha': 14750.0}          -0.000083   \n",
       "14            15500.0  {'ridge__alpha': 15500.0}          -0.000083   \n",
       "15            16250.0  {'ridge__alpha': 16250.0}          -0.000083   \n",
       "16            17000.0  {'ridge__alpha': 17000.0}          -0.000083   \n",
       "17            17750.0  {'ridge__alpha': 17750.0}          -0.000083   \n",
       "18            18500.0  {'ridge__alpha': 18500.0}          -0.000083   \n",
       "19            19250.0  {'ridge__alpha': 19250.0}          -0.000083   \n",
       "20            20000.0  {'ridge__alpha': 20000.0}          -0.000083   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "3           -0.000237          -0.000106          -0.000198   \n",
       "2           -0.000237          -0.000106          -0.000198   \n",
       "4           -0.000237          -0.000105          -0.000198   \n",
       "5           -0.000237          -0.000105          -0.000198   \n",
       "1           -0.000237          -0.000106          -0.000198   \n",
       "6           -0.000237          -0.000105          -0.000198   \n",
       "7           -0.000236          -0.000105          -0.000198   \n",
       "8           -0.000236          -0.000105          -0.000198   \n",
       "0           -0.000237          -0.000106          -0.000198   \n",
       "9           -0.000236          -0.000105          -0.000198   \n",
       "10          -0.000236          -0.000105          -0.000198   \n",
       "11          -0.000236          -0.000105          -0.000198   \n",
       "12          -0.000236          -0.000105          -0.000198   \n",
       "13          -0.000236          -0.000105          -0.000198   \n",
       "14          -0.000236          -0.000105          -0.000198   \n",
       "15          -0.000236          -0.000105          -0.000198   \n",
       "16          -0.000236          -0.000105          -0.000198   \n",
       "17          -0.000236          -0.000105          -0.000198   \n",
       "18          -0.000236          -0.000105          -0.000198   \n",
       "19          -0.000236          -0.000105          -0.000198   \n",
       "20          -0.000236          -0.000105          -0.000198   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3           -0.000238        -0.000172        0.000066                1  \n",
       "2           -0.000238        -0.000172        0.000066                2  \n",
       "4           -0.000238        -0.000172        0.000066                3  \n",
       "5           -0.000238        -0.000172        0.000066                4  \n",
       "1           -0.000238        -0.000172        0.000066                5  \n",
       "6           -0.000238        -0.000172        0.000066                6  \n",
       "7           -0.000239        -0.000172        0.000066                7  \n",
       "8           -0.000239        -0.000172        0.000066                8  \n",
       "0           -0.000238        -0.000172        0.000066                9  \n",
       "9           -0.000239        -0.000172        0.000066               10  \n",
       "10          -0.000239        -0.000172        0.000066               11  \n",
       "11          -0.000239        -0.000172        0.000066               12  \n",
       "12          -0.000239        -0.000172        0.000066               13  \n",
       "13          -0.000239        -0.000172        0.000066               14  \n",
       "14          -0.000239        -0.000172        0.000066               15  \n",
       "15          -0.000239        -0.000172        0.000066               16  \n",
       "16          -0.000239        -0.000172        0.000066               17  \n",
       "17          -0.000239        -0.000172        0.000066               18  \n",
       "18          -0.000239        -0.000172        0.000066               19  \n",
       "19          -0.000239        -0.000172        0.000066               20  \n",
       "20          -0.000239        -0.000172        0.000066               21  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5f3c706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 7250.0}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2802ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ecaa9a",
   "metadata": {},
   "source": [
    "#### Compare performance of alpha 7250 and 1 (default value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4b77abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge(alpha=7250)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6e9ed945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('ridge', Ridge(alpha=7250))])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d51ec4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029702548778173243"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9c7ed683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022187121498531415"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d026bd",
   "metadata": {},
   "source": [
    "Yes performance is better. Compared to \"Explore make_pipeline()\", train performance is less but test performance is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be421f7d",
   "metadata": {},
   "source": [
    "#### Test performance and check for sign of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "05a816bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge(alpha=7250)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5fc2f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030592112852093623\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train.iloc[-1260:, :], y_train.iloc[-1260:])\n",
    "print(pipe.score(X_train.iloc[-1260:, :], y_train.iloc[-1260:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "213bd338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.018442688587898548\n"
     ]
    }
   ],
   "source": [
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "45b587ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r-square                    : 0.0030592112852093623\n",
      "Train mean_squared_error          : 0.000267577693250618\n",
      "Train roof of mean_squared_error  : 0.016357802213335933\n",
      "Train mean_absolute_error         : 0.012132191117046458\n"
     ]
    }
   ],
   "source": [
    "# Train performance \n",
    "y_train_pred = pipe.predict(X_train.iloc[-1260:, :])\n",
    "print('Train r-square                    :', r2_score(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train mean_squared_error          :', mean_squared_error(y_train.iloc[-1260:], y_train_pred))\n",
    "print('Train roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_train.iloc[-1260:], y_train_pred)))\n",
    "print('Train mean_absolute_error         :', mean_absolute_error(y_train.iloc[-1260:], y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8e93601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r-square                    : -0.018442688587898548\n",
      "Test mean_squared_error          : 0.00020970837607005237\n",
      "Test roof of mean_squared_error  : 0.014481311269013327\n",
      "Test mean_absolute_error         : 0.010924758675441288\n"
     ]
    }
   ],
   "source": [
    "# Test performance \n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('Test r-square                    :', r2_score(y_test, y_test_pred))\n",
    "print('Test mean_squared_error          :', mean_squared_error(y_test, y_test_pred))\n",
    "print('Test roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('Test mean_absolute_error         :', mean_absolute_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f258cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "034726e3",
   "metadata": {},
   "source": [
    "#### Naive predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "49144562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.000722\n",
       "1   0.000722\n",
       "2   0.000722\n",
       "3   0.000722\n",
       "4   0.000722\n",
       "5   0.000722\n",
       "6   0.000722\n",
       "7   0.000722\n",
       "8   0.000722\n",
       "9   0.000722\n",
       "10  0.000722\n",
       "11  0.000722\n",
       "12  0.000722\n",
       "13  0.000722\n",
       "14  0.000722\n",
       "15  0.000722\n",
       "16  0.000722\n",
       "17  0.000722\n",
       "18  0.000722\n",
       "19  0.000722\n",
       "20  0.000722\n",
       "21  0.000722\n",
       "22  0.000722\n",
       "23  0.000722\n",
       "24  0.000722"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive predictor should be average of y_train (random walk with drift)\n",
    "# Use 1260 days of rtn \n",
    "y_dummy = pd.DataFrame(np.ones((len(y_test)))*y_train.iloc[-1260:].mean())\n",
    "y_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6c9fc764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy r-square                    : -0.01600820847852491\n",
      "Dummy mean_squared_error          : 0.00020920709025786842\n",
      "Dummy roof of mean_squared_error  : 0.014463992887784079\n",
      "Dummy mean_absolute_error         : 0.010871847207568317\n"
     ]
    }
   ],
   "source": [
    "# Naive performance \n",
    "print('Dummy r-square                    :', r2_score(y_test, y_dummy))\n",
    "print('Dummy mean_squared_error          :', mean_squared_error(y_test, y_dummy))\n",
    "print('Dummy roof of mean_squared_error  :', np.sqrt(mean_squared_error(y_test, y_dummy)))\n",
    "print('Dummy mean_absolute_error         :', mean_absolute_error(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9e981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1225cf0",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years), with month sine and cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec2fc2",
   "metadata": {},
   "source": [
    "Prepare new X_train with month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8c510826",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10',\n",
    "       'log_rtn_lag_0', 'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3',\n",
    "       'log_rtn_lag_4', 'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7',\n",
    "       'log_rtn_lag_8', 'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11',\n",
    "       'log_rtn_lag_12', 'log_rtn_lag_13', 'log_rtn_lag_14', '1d_future_month_sin', '1d_future_month_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "396e5ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 21) (1508,)\n"
     ]
    }
   ],
   "source": [
    "# Take X_train and y_train \n",
    "X_train = zion_1.loc[\"2012\":\"2017\", col_list].copy()\n",
    "y_train = zion_1.loc[\"2012\":\"2017\", '1d_future_log_rtn'].copy()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "654747bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 21) (25,)\n"
     ]
    }
   ],
   "source": [
    "# Take X_test and y_test \n",
    "X_test = zion_1.loc[\"2018-01-02\":\"2018-02-06\", col_list].copy()\n",
    "y_test = zion_1.loc[\"2018-01-02\":\"2018-02-06\", '1d_future_log_rtn'].copy()\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a30a55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10', 'log_rtn_lag_0',\n",
       "       'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3', 'log_rtn_lag_4',\n",
       "       'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7', 'log_rtn_lag_8',\n",
       "       'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11', 'log_rtn_lag_12',\n",
       "       'log_rtn_lag_13', 'log_rtn_lag_14', '1d_future_month_sin',\n",
       "       '1d_future_month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f7b2c",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7ac425a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "29fed964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05,\n",
       " 0.0001,\n",
       " 0.001,\n",
       " 0.01,\n",
       " 0.1,\n",
       " 1.0,\n",
       " 10.0,\n",
       " 100.0,\n",
       " 1000.0,\n",
       " 10000.0,\n",
       " 100000.0,\n",
       " 1000000.0,\n",
       " 10000000.0,\n",
       " 100000000.0]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [n for n in np.logspace(-5, 8, num=14, endpoint=True, base=10.0)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3b46a5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>{'ridge__alpha': 10000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>{'ridge__alpha': 100000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>{'ridge__alpha': 1000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>{'ridge__alpha': 10000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>{'ridge__alpha': 100000000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>{'ridge__alpha': 1000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'ridge__alpha': 100.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'ridge__alpha': 10.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'ridge__alpha': 1.0}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'ridge__alpha': 0.1}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'ridge__alpha': 0.01}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480911</td>\n",
       "      <td>0.586376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'ridge__alpha': 0.001}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.199071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'ridge__alpha': 0.0001}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.199071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'ridge__alpha': 1e-05}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        0.006249      0.007654         0.000000        0.000000   \n",
       "10       0.000000      0.000000         0.000000        0.000000   \n",
       "11       0.009373      0.007653         0.003124        0.006249   \n",
       "12       0.000000      0.000000         0.003124        0.006248   \n",
       "13       0.009372      0.007652         0.000000        0.000000   \n",
       "8        0.000000      0.000000         0.000000        0.000000   \n",
       "7        0.012496      0.006248         0.000000        0.000000   \n",
       "6        0.003124      0.006248         0.003124        0.006248   \n",
       "5        0.003124      0.006249         0.000000        0.000000   \n",
       "4        0.012497      0.006249         0.003124        0.006249   \n",
       "3        0.000000      0.000000         0.000000        0.000000   \n",
       "2        0.480911      0.586376         0.000000        0.000000   \n",
       "1        1.199071      0.000000         0.000000        0.000000   \n",
       "0        1.199071      0.000000         0.000000        0.000000   \n",
       "\n",
       "   param_ridge__alpha                         params  split0_test_score  \\\n",
       "9             10000.0      {'ridge__alpha': 10000.0}          -0.000083   \n",
       "10           100000.0     {'ridge__alpha': 100000.0}          -0.000083   \n",
       "11          1000000.0    {'ridge__alpha': 1000000.0}          -0.000083   \n",
       "12         10000000.0   {'ridge__alpha': 10000000.0}          -0.000083   \n",
       "13        100000000.0  {'ridge__alpha': 100000000.0}          -0.000083   \n",
       "8              1000.0       {'ridge__alpha': 1000.0}          -0.000083   \n",
       "7               100.0        {'ridge__alpha': 100.0}          -0.000084   \n",
       "6                10.0         {'ridge__alpha': 10.0}          -0.000084   \n",
       "5                 1.0          {'ridge__alpha': 1.0}          -0.000084   \n",
       "4                 0.1          {'ridge__alpha': 0.1}          -0.000084   \n",
       "3                0.01         {'ridge__alpha': 0.01}          -0.000084   \n",
       "2               0.001        {'ridge__alpha': 0.001}          -0.000084   \n",
       "1              0.0001       {'ridge__alpha': 0.0001}          -0.000084   \n",
       "0             0.00001        {'ridge__alpha': 1e-05}          -0.000084   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9           -0.000237          -0.000105          -0.000198   \n",
       "10          -0.000236          -0.000105          -0.000198   \n",
       "11          -0.000236          -0.000105          -0.000198   \n",
       "12          -0.000236          -0.000105          -0.000198   \n",
       "13          -0.000236          -0.000105          -0.000198   \n",
       "8           -0.000239          -0.000109          -0.000199   \n",
       "7           -0.000243          -0.000115          -0.000200   \n",
       "6           -0.000243          -0.000116          -0.000201   \n",
       "5           -0.000243          -0.000116          -0.000201   \n",
       "4           -0.000243          -0.000116          -0.000201   \n",
       "3           -0.000243          -0.000116          -0.000201   \n",
       "2           -0.000243          -0.000116          -0.000201   \n",
       "1           -0.000243          -0.000116          -0.000201   \n",
       "0           -0.000243          -0.000116          -0.000201   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9           -0.000239        -0.000172        0.000066                1  \n",
       "10          -0.000240        -0.000172        0.000066                2  \n",
       "11          -0.000240        -0.000172        0.000066                3  \n",
       "12          -0.000240        -0.000172        0.000066                4  \n",
       "13          -0.000240        -0.000172        0.000066                5  \n",
       "8           -0.000236        -0.000173        0.000065                6  \n",
       "7           -0.000234        -0.000175        0.000064                7  \n",
       "6           -0.000233        -0.000175        0.000064                8  \n",
       "5           -0.000233        -0.000175        0.000064                9  \n",
       "4           -0.000233        -0.000175        0.000064               10  \n",
       "3           -0.000233        -0.000175        0.000064               11  \n",
       "2           -0.000233        -0.000175        0.000064               12  \n",
       "1           -0.000233        -0.000175        0.000064               13  \n",
       "0           -0.000233        -0.000175        0.000064               14  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Does not seem to improve with month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "49ad6234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000.0,\n",
       " 5750.0,\n",
       " 6500.0,\n",
       " 7250.0,\n",
       " 8000.0,\n",
       " 8750.0,\n",
       " 9500.0,\n",
       " 10250.0,\n",
       " 11000.0,\n",
       " 11750.0,\n",
       " 12500.0,\n",
       " 13250.0,\n",
       " 14000.0,\n",
       " 14750.0,\n",
       " 15500.0,\n",
       " 16250.0,\n",
       " 17000.0,\n",
       " 17750.0,\n",
       " 18500.0,\n",
       " 19250.0,\n",
       " 20000.0]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sweep 2\n",
    "alpha = [n for n in np.linspace(5000, 20000, num=21, endpoint=True)]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ce96f5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>6.306003e-04</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.992339e-04</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>{'ridge__alpha': 17000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>7.972488e-04</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.889888e-04</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>{'ridge__alpha': 17750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.006713</td>\n",
       "      <td>5.004429e-03</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>3.989506e-07</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>{'ridge__alpha': 16250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004188</td>\n",
       "      <td>7.455884e-04</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.887335e-04</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>{'ridge__alpha': 18500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005863</td>\n",
       "      <td>6.408948e-03</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>5.726980e-03</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>{'ridge__alpha': 15500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>1.642504e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19250.0</td>\n",
       "      <td>{'ridge__alpha': 19250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>6.248093e-03</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>{'ridge__alpha': 20000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004104</td>\n",
       "      <td>6.366423e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>14750.0</td>\n",
       "      <td>{'ridge__alpha': 14750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006575</td>\n",
       "      <td>6.957659e-03</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>5.176134e-03</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>{'ridge__alpha': 14000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003365</td>\n",
       "      <td>5.175283e-03</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>4.806116e-03</td>\n",
       "      <td>13250.0</td>\n",
       "      <td>{'ridge__alpha': 13250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003580</td>\n",
       "      <td>1.972321e-03</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>9.762793e-04</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>{'ridge__alpha': 12500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004283</td>\n",
       "      <td>6.060869e-04</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>8.645072e-04</td>\n",
       "      <td>11750.0</td>\n",
       "      <td>{'ridge__alpha': 11750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>7.456156e-04</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.881533e-04</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>{'ridge__alpha': 11000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005185</td>\n",
       "      <td>7.469145e-04</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.886754e-04</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>{'ridge__alpha': 10250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>4.884226e-04</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>8.714517e-07</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>{'ridge__alpha': 9500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>1.097762e-06</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.987556e-04</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>{'ridge__alpha': 8750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005584</td>\n",
       "      <td>4.883830e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.990896e-04</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>{'ridge__alpha': 8000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>3.989000e-04</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>4.156970e-07</td>\n",
       "      <td>7250.0</td>\n",
       "      <td>{'ridge__alpha': 7250.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>6.397442e-07</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>9.933790e-07</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>{'ridge__alpha': 6500.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>1.162361e-03</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.310527e-04</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>{'ridge__alpha': 5750.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.884220e-04</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.880521e-04</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>{'ridge__alpha': 5000.0}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       0.004987  6.306003e-04         0.001796    3.992339e-04   \n",
       "17       0.004389  7.972488e-04         0.001596    4.889888e-04   \n",
       "15       0.006713  5.004429e-03         0.001995    3.989506e-07   \n",
       "18       0.004188  7.455884e-04         0.001596    4.887335e-04   \n",
       "14       0.005863  6.408948e-03         0.005647    5.726980e-03   \n",
       "19       0.001629  1.642504e-03         0.000000    0.000000e+00   \n",
       "20       0.000000  0.000000e+00         0.003124    6.248093e-03   \n",
       "13       0.004104  6.366423e-03         0.000000    0.000000e+00   \n",
       "12       0.006575  6.957659e-03         0.003288    5.176134e-03   \n",
       "11       0.003365  5.175283e-03         0.002870    4.806116e-03   \n",
       "10       0.003580  1.972321e-03         0.000797    9.762793e-04   \n",
       "9        0.004283  6.060869e-04         0.001690    8.645072e-04   \n",
       "8        0.004787  7.456156e-04         0.001596    4.881533e-04   \n",
       "7        0.005185  7.469145e-04         0.001396    4.886754e-04   \n",
       "6        0.005386  4.884226e-04         0.001994    8.714517e-07   \n",
       "5        0.005984  1.097762e-06         0.001796    3.987556e-04   \n",
       "4        0.005584  4.883830e-04         0.001795    3.990896e-04   \n",
       "3        0.005186  3.989000e-04         0.001994    4.156970e-07   \n",
       "2        0.004986  6.397442e-07         0.001995    9.933790e-07   \n",
       "1        0.004189  1.162361e-03         0.001994    6.310527e-04   \n",
       "0        0.004388  4.884220e-04         0.001596    4.880521e-04   \n",
       "\n",
       "   param_ridge__alpha                     params  split0_test_score  \\\n",
       "16            17000.0  {'ridge__alpha': 17000.0}          -0.000083   \n",
       "17            17750.0  {'ridge__alpha': 17750.0}          -0.000083   \n",
       "15            16250.0  {'ridge__alpha': 16250.0}          -0.000083   \n",
       "18            18500.0  {'ridge__alpha': 18500.0}          -0.000083   \n",
       "14            15500.0  {'ridge__alpha': 15500.0}          -0.000083   \n",
       "19            19250.0  {'ridge__alpha': 19250.0}          -0.000083   \n",
       "20            20000.0  {'ridge__alpha': 20000.0}          -0.000083   \n",
       "13            14750.0  {'ridge__alpha': 14750.0}          -0.000083   \n",
       "12            14000.0  {'ridge__alpha': 14000.0}          -0.000083   \n",
       "11            13250.0  {'ridge__alpha': 13250.0}          -0.000083   \n",
       "10            12500.0  {'ridge__alpha': 12500.0}          -0.000083   \n",
       "9             11750.0  {'ridge__alpha': 11750.0}          -0.000083   \n",
       "8             11000.0  {'ridge__alpha': 11000.0}          -0.000083   \n",
       "7             10250.0  {'ridge__alpha': 10250.0}          -0.000083   \n",
       "6              9500.0   {'ridge__alpha': 9500.0}          -0.000083   \n",
       "5              8750.0   {'ridge__alpha': 8750.0}          -0.000083   \n",
       "4              8000.0   {'ridge__alpha': 8000.0}          -0.000083   \n",
       "3              7250.0   {'ridge__alpha': 7250.0}          -0.000083   \n",
       "2              6500.0   {'ridge__alpha': 6500.0}          -0.000083   \n",
       "1              5750.0   {'ridge__alpha': 5750.0}          -0.000083   \n",
       "0              5000.0   {'ridge__alpha': 5000.0}          -0.000083   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "16          -0.000236          -0.000105          -0.000198   \n",
       "17          -0.000236          -0.000105          -0.000198   \n",
       "15          -0.000237          -0.000105          -0.000198   \n",
       "18          -0.000236          -0.000105          -0.000198   \n",
       "14          -0.000237          -0.000105          -0.000198   \n",
       "19          -0.000236          -0.000105          -0.000198   \n",
       "20          -0.000236          -0.000105          -0.000198   \n",
       "13          -0.000237          -0.000105          -0.000198   \n",
       "12          -0.000237          -0.000105          -0.000198   \n",
       "11          -0.000237          -0.000105          -0.000198   \n",
       "10          -0.000237          -0.000105          -0.000198   \n",
       "9           -0.000237          -0.000105          -0.000198   \n",
       "8           -0.000237          -0.000105          -0.000198   \n",
       "7           -0.000237          -0.000105          -0.000198   \n",
       "6           -0.000237          -0.000105          -0.000198   \n",
       "5           -0.000237          -0.000105          -0.000198   \n",
       "4           -0.000237          -0.000105          -0.000198   \n",
       "3           -0.000237          -0.000106          -0.000198   \n",
       "2           -0.000237          -0.000106          -0.000198   \n",
       "1           -0.000237          -0.000106          -0.000198   \n",
       "0           -0.000237          -0.000106          -0.000198   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "16          -0.000239        -0.000172        0.000066                1  \n",
       "17          -0.000239        -0.000172        0.000066                2  \n",
       "15          -0.000239        -0.000172        0.000066                3  \n",
       "18          -0.000239        -0.000172        0.000066                4  \n",
       "14          -0.000239        -0.000172        0.000066                5  \n",
       "19          -0.000239        -0.000172        0.000066                6  \n",
       "20          -0.000239        -0.000172        0.000066                7  \n",
       "13          -0.000239        -0.000172        0.000066                8  \n",
       "12          -0.000239        -0.000172        0.000066                9  \n",
       "11          -0.000239        -0.000172        0.000066               10  \n",
       "10          -0.000239        -0.000172        0.000066               11  \n",
       "9           -0.000239        -0.000172        0.000066               12  \n",
       "8           -0.000239        -0.000172        0.000066               13  \n",
       "7           -0.000239        -0.000172        0.000066               14  \n",
       "6           -0.000239        -0.000172        0.000066               15  \n",
       "5           -0.000239        -0.000172        0.000066               16  \n",
       "4           -0.000238        -0.000172        0.000066               17  \n",
       "3           -0.000238        -0.000172        0.000066               18  \n",
       "2           -0.000238        -0.000172        0.000066               19  \n",
       "1           -0.000238        -0.000172        0.000066               20  \n",
       "0           -0.000238        -0.000172        0.000066               21  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'ridge__alpha': alpha}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Does not seem to improve with month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839d5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e623b689",
   "metadata": {},
   "source": [
    "## 5.4) KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e94e2",
   "metadata": {},
   "source": [
    "#### Explore KNN with make_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d70e0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    KNeighborsRegressor(n_neighbors=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "34480c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('kneighborsregressor', KNeighborsRegressor())])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9bbdaef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22716022965669558"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a8170585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2586259281959269"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49ca06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c2b63a",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years), without month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cd0acf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = [int(n) for n in np.linspace(1, 20, num=20, endpoint=True)]\n",
    "n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b2d54410",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    KNeighborsRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "88656b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsregressor__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>6.304495e-04</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>4.886172e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 14}</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>7.989057e-04</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>7.460990e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 13}</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>4.884999e-04</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>7.460217e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 15}</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>7.980113e-04</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>3.995673e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 12}</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>7.979157e-04</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>4.889282e-04</td>\n",
       "      <td>16</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 16}</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003390</td>\n",
       "      <td>1.016597e-03</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.888113e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 17}</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>3.992559e-04</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.309774e-04</td>\n",
       "      <td>18</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 18}</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>3.990174e-04</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>7.466971e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 11}</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002991</td>\n",
       "      <td>5.519789e-07</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.888891e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 20}</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>4.889281e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.993751e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 19}</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>7.970693e-04</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>5.436780e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 10}</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>1.092232e-03</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.891033e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 9}</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004188</td>\n",
       "      <td>7.462898e-04</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.893175e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 8}</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.887731e-04</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>3.990892e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 6}</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>7.971527e-04</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>4.884222e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 7}</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>4.881884e-04</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>7.469775e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 5}</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>4.885387e-04</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>6.304495e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 4}</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.465320e-04</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>4.731484e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 3}</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>7.970096e-04</td>\n",
       "      <td>0.102925</td>\n",
       "      <td>1.715778e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 2}</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>7.970097e-04</td>\n",
       "      <td>0.110304</td>\n",
       "      <td>2.053336e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 1}</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "13       0.003989  6.304495e-04         0.002593    4.886172e-04   \n",
       "12       0.004388  7.989057e-04         0.002194    7.460990e-04   \n",
       "14       0.003590  4.884999e-04         0.002194    7.460217e-04   \n",
       "11       0.004389  7.980113e-04         0.002792    3.995673e-04   \n",
       "15       0.003590  7.979157e-04         0.001397    4.889282e-04   \n",
       "16       0.003390  1.016597e-03         0.002394    4.888113e-04   \n",
       "17       0.003192  3.992559e-04         0.001995    6.309774e-04   \n",
       "10       0.003192  3.990174e-04         0.002195    7.466971e-04   \n",
       "19       0.002991  5.519789e-07         0.001396    4.888891e-04   \n",
       "18       0.003391  4.889281e-04         0.001795    3.993751e-04   \n",
       "9        0.003591  7.970693e-04         0.001995    5.436780e-07   \n",
       "8        0.003989  1.092232e-03         0.002394    4.891033e-04   \n",
       "7        0.004188  7.462898e-04         0.002394    4.893175e-04   \n",
       "5        0.004388  4.887731e-04         0.002195    3.990892e-04   \n",
       "6        0.004389  7.971527e-04         0.002593    4.884222e-04   \n",
       "4        0.004588  4.881884e-04         0.002793    7.469775e-04   \n",
       "3        0.004588  4.885387e-04         0.002992    6.304495e-04   \n",
       "2        0.003790  7.465320e-04         0.041290    4.731484e-02   \n",
       "1        0.004388  7.970096e-04         0.102925    1.715778e-03   \n",
       "0        0.004389  7.970097e-04         0.110304    2.053336e-03   \n",
       "\n",
       "   param_kneighborsregressor__n_neighbors  \\\n",
       "13                                     14   \n",
       "12                                     13   \n",
       "14                                     15   \n",
       "11                                     12   \n",
       "15                                     16   \n",
       "16                                     17   \n",
       "17                                     18   \n",
       "10                                     11   \n",
       "19                                     20   \n",
       "18                                     19   \n",
       "9                                      10   \n",
       "8                                       9   \n",
       "7                                       8   \n",
       "5                                       6   \n",
       "6                                       7   \n",
       "4                                       5   \n",
       "3                                       4   \n",
       "2                                       3   \n",
       "1                                       2   \n",
       "0                                       1   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "13  {'kneighborsregressor__n_neighbors': 14}          -0.000101   \n",
       "12  {'kneighborsregressor__n_neighbors': 13}          -0.000099   \n",
       "14  {'kneighborsregressor__n_neighbors': 15}          -0.000100   \n",
       "11  {'kneighborsregressor__n_neighbors': 12}          -0.000099   \n",
       "15  {'kneighborsregressor__n_neighbors': 16}          -0.000104   \n",
       "16  {'kneighborsregressor__n_neighbors': 17}          -0.000105   \n",
       "17  {'kneighborsregressor__n_neighbors': 18}          -0.000110   \n",
       "10  {'kneighborsregressor__n_neighbors': 11}          -0.000109   \n",
       "19  {'kneighborsregressor__n_neighbors': 20}          -0.000109   \n",
       "18  {'kneighborsregressor__n_neighbors': 19}          -0.000114   \n",
       "9   {'kneighborsregressor__n_neighbors': 10}          -0.000114   \n",
       "8    {'kneighborsregressor__n_neighbors': 9}          -0.000119   \n",
       "7    {'kneighborsregressor__n_neighbors': 8}          -0.000122   \n",
       "5    {'kneighborsregressor__n_neighbors': 6}          -0.000140   \n",
       "6    {'kneighborsregressor__n_neighbors': 7}          -0.000138   \n",
       "4    {'kneighborsregressor__n_neighbors': 5}          -0.000135   \n",
       "3    {'kneighborsregressor__n_neighbors': 4}          -0.000158   \n",
       "2    {'kneighborsregressor__n_neighbors': 3}          -0.000165   \n",
       "1    {'kneighborsregressor__n_neighbors': 2}          -0.000155   \n",
       "0    {'kneighborsregressor__n_neighbors': 1}          -0.000443   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "13          -0.000287          -0.000122          -0.000171   \n",
       "12          -0.000287          -0.000123          -0.000168   \n",
       "14          -0.000288          -0.000116          -0.000178   \n",
       "11          -0.000281          -0.000127          -0.000173   \n",
       "15          -0.000283          -0.000119          -0.000184   \n",
       "16          -0.000292          -0.000115          -0.000189   \n",
       "17          -0.000287          -0.000114          -0.000194   \n",
       "10          -0.000293          -0.000134          -0.000172   \n",
       "19          -0.000288          -0.000125          -0.000196   \n",
       "18          -0.000284          -0.000121          -0.000197   \n",
       "9           -0.000277          -0.000141          -0.000176   \n",
       "8           -0.000286          -0.000138          -0.000176   \n",
       "7           -0.000276          -0.000145          -0.000184   \n",
       "5           -0.000302          -0.000148          -0.000207   \n",
       "6           -0.000290          -0.000141          -0.000208   \n",
       "4           -0.000301          -0.000147          -0.000219   \n",
       "3           -0.000295          -0.000155          -0.000226   \n",
       "2           -0.000320          -0.000187          -0.000214   \n",
       "1           -0.000400          -0.000207          -0.000283   \n",
       "0           -0.000302          -0.000396          -0.000366   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "13          -0.000244        -0.000185        0.000071                1  \n",
       "12          -0.000256        -0.000187        0.000073                2  \n",
       "14          -0.000253        -0.000187        0.000074                3  \n",
       "11          -0.000260        -0.000188        0.000072                4  \n",
       "15          -0.000256        -0.000189        0.000071                5  \n",
       "16          -0.000251        -0.000190        0.000073                6  \n",
       "17          -0.000254        -0.000192        0.000072                7  \n",
       "10          -0.000254        -0.000193        0.000070                8  \n",
       "19          -0.000253        -0.000194        0.000069                9  \n",
       "18          -0.000257        -0.000194        0.000069               10  \n",
       "9           -0.000265        -0.000195        0.000066               11  \n",
       "8           -0.000281        -0.000200        0.000071               12  \n",
       "7           -0.000277        -0.000201        0.000065               13  \n",
       "5           -0.000270        -0.000213        0.000064               14  \n",
       "6           -0.000305        -0.000217        0.000071               15  \n",
       "4           -0.000283        -0.000217        0.000068               16  \n",
       "3           -0.000292        -0.000225        0.000062               17  \n",
       "2           -0.000263        -0.000230        0.000056               18  \n",
       "1           -0.000290        -0.000267        0.000083               19  \n",
       "0           -0.000257        -0.000353        0.000066               20  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'kneighborsregressor__n_neighbors': n_neighbors}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3e4c0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kneighborsregressor__n_neighbors': 14}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take best parameters\n",
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a76f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03b4647",
   "metadata": {},
   "source": [
    "#### GridSearchCV with 1260 days training window (5 years), with month sine and cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caa014",
   "metadata": {},
   "source": [
    "We have updated X_train and X_test to include month sine and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e6c4f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ma50', 'rsi50', 'vol_1d_change', 'vol_1d_change_ma10', 'log_rtn_lag_0',\n",
       "       'log_rtn_lag_1', 'log_rtn_lag_2', 'log_rtn_lag_3', 'log_rtn_lag_4',\n",
       "       'log_rtn_lag_5', 'log_rtn_lag_6', 'log_rtn_lag_7', 'log_rtn_lag_8',\n",
       "       'log_rtn_lag_9', 'log_rtn_lag_10', 'log_rtn_lag_11', 'log_rtn_lag_12',\n",
       "       'log_rtn_lag_13', 'log_rtn_lag_14', '1d_future_month_sin',\n",
       "       '1d_future_month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f503054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    KNeighborsRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "37bb7f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = [int(n) for n in np.linspace(1, 20, num=20, endpoint=True)]\n",
    "n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9f7c52fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsregressor__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.461108e-04</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.883832e-04</td>\n",
       "      <td>16</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 16}</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>6.143617e-07</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>7.776979e-07</td>\n",
       "      <td>17</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 17}</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>4.888311e-04</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>7.464549e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 15}</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005187</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>3.989956e-04</td>\n",
       "      <td>18</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 18}</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>9.768051e-04</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.993278e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 14}</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>3.990651e-04</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>4.880343e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 19}</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004786</td>\n",
       "      <td>7.465953e-04</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>4.205422e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 20}</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>5.642013e-07</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.986362e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 13}</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>4.888715e-04</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.885975e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 12}</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003392</td>\n",
       "      <td>7.978202e-04</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2.132481e-07</td>\n",
       "      <td>11</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 11}</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>6.302989e-04</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>7.466973e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 7}</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>4.885000e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>7.464423e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 10}</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.887918e-04</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.309018e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 9}</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>4.882274e-04</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>4.888703e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 8}</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.887724e-04</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>4.889282e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 6}</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>4.879751e-04</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>4.882467e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 5}</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.461236e-04</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.991370e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 4}</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002793</td>\n",
       "      <td>2.309018e-03</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>1.319665e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 3}</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.275159</td>\n",
       "      <td>6.250477e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 2}</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.272034</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>{'kneighborsregressor__n_neighbors': 1}</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       0.003790  7.461108e-04         0.002394    4.883832e-04   \n",
       "16       0.004987  6.143617e-07         0.002992    7.776979e-07   \n",
       "14       0.003391  4.888311e-04         0.001796    7.464549e-04   \n",
       "17       0.005187  3.991850e-04         0.002793    3.989956e-04   \n",
       "13       0.003790  9.768051e-04         0.002194    3.993278e-04   \n",
       "18       0.004787  3.990651e-04         0.002593    4.880343e-04   \n",
       "19       0.004786  7.465953e-04         0.002221    4.205422e-04   \n",
       "12       0.002992  5.642013e-07         0.001795    3.986362e-04   \n",
       "11       0.003590  4.888715e-04         0.001396    4.885975e-04   \n",
       "10       0.003392  7.978202e-04         0.001995    2.132481e-07   \n",
       "6        0.003989  6.302989e-04         0.002194    7.466973e-04   \n",
       "9        0.003391  4.885000e-04         0.001795    7.464423e-04   \n",
       "8        0.004388  4.887918e-04         0.001994    6.309018e-04   \n",
       "7        0.004588  4.882274e-04         0.002593    4.888703e-04   \n",
       "5        0.004388  4.887724e-04         0.002594    4.889282e-04   \n",
       "4        0.003591  4.879751e-04         0.002393    4.882467e-04   \n",
       "3        0.003790  7.461236e-04         0.002194    3.991370e-04   \n",
       "2        0.002793  2.309018e-03         0.110410    1.319665e-01   \n",
       "1        0.000000  0.000000e+00         0.275159    6.250477e-03   \n",
       "0        0.000000  0.000000e+00         0.272034    0.000000e+00   \n",
       "\n",
       "   param_kneighborsregressor__n_neighbors  \\\n",
       "15                                     16   \n",
       "16                                     17   \n",
       "14                                     15   \n",
       "17                                     18   \n",
       "13                                     14   \n",
       "18                                     19   \n",
       "19                                     20   \n",
       "12                                     13   \n",
       "11                                     12   \n",
       "10                                     11   \n",
       "6                                       7   \n",
       "9                                      10   \n",
       "8                                       9   \n",
       "7                                       8   \n",
       "5                                       6   \n",
       "4                                       5   \n",
       "3                                       4   \n",
       "2                                       3   \n",
       "1                                       2   \n",
       "0                                       1   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "15  {'kneighborsregressor__n_neighbors': 16}          -0.000080   \n",
       "16  {'kneighborsregressor__n_neighbors': 17}          -0.000080   \n",
       "14  {'kneighborsregressor__n_neighbors': 15}          -0.000083   \n",
       "17  {'kneighborsregressor__n_neighbors': 18}          -0.000084   \n",
       "13  {'kneighborsregressor__n_neighbors': 14}          -0.000086   \n",
       "18  {'kneighborsregressor__n_neighbors': 19}          -0.000088   \n",
       "19  {'kneighborsregressor__n_neighbors': 20}          -0.000086   \n",
       "12  {'kneighborsregressor__n_neighbors': 13}          -0.000097   \n",
       "11  {'kneighborsregressor__n_neighbors': 12}          -0.000101   \n",
       "10  {'kneighborsregressor__n_neighbors': 11}          -0.000103   \n",
       "6    {'kneighborsregressor__n_neighbors': 7}          -0.000117   \n",
       "9   {'kneighborsregressor__n_neighbors': 10}          -0.000113   \n",
       "8    {'kneighborsregressor__n_neighbors': 9}          -0.000106   \n",
       "7    {'kneighborsregressor__n_neighbors': 8}          -0.000119   \n",
       "5    {'kneighborsregressor__n_neighbors': 6}          -0.000130   \n",
       "4    {'kneighborsregressor__n_neighbors': 5}          -0.000176   \n",
       "3    {'kneighborsregressor__n_neighbors': 4}          -0.000188   \n",
       "2    {'kneighborsregressor__n_neighbors': 3}          -0.000172   \n",
       "1    {'kneighborsregressor__n_neighbors': 2}          -0.000207   \n",
       "0    {'kneighborsregressor__n_neighbors': 1}          -0.000384   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15          -0.000233          -0.000122          -0.000188   \n",
       "16          -0.000233          -0.000125          -0.000189   \n",
       "14          -0.000238          -0.000121          -0.000193   \n",
       "17          -0.000238          -0.000123          -0.000196   \n",
       "13          -0.000229          -0.000125          -0.000196   \n",
       "18          -0.000240          -0.000124          -0.000198   \n",
       "19          -0.000235          -0.000125          -0.000203   \n",
       "12          -0.000232          -0.000127          -0.000191   \n",
       "11          -0.000247          -0.000131          -0.000193   \n",
       "10          -0.000254          -0.000129          -0.000193   \n",
       "6           -0.000295          -0.000136          -0.000177   \n",
       "9           -0.000257          -0.000131          -0.000208   \n",
       "8           -0.000264          -0.000133          -0.000207   \n",
       "7           -0.000279          -0.000135          -0.000198   \n",
       "5           -0.000309          -0.000142          -0.000182   \n",
       "4           -0.000311          -0.000153          -0.000202   \n",
       "3           -0.000340          -0.000154          -0.000180   \n",
       "2           -0.000320          -0.000178          -0.000172   \n",
       "1           -0.000342          -0.000253          -0.000258   \n",
       "0           -0.000279          -0.000460          -0.000276   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15          -0.000264        -0.000177        0.000068                1  \n",
       "16          -0.000264        -0.000178        0.000068                2  \n",
       "14          -0.000267        -0.000180        0.000069                3  \n",
       "17          -0.000263        -0.000181        0.000068                4  \n",
       "13          -0.000273        -0.000182        0.000068                5  \n",
       "18          -0.000261        -0.000182        0.000066                6  \n",
       "19          -0.000263        -0.000182        0.000067                7  \n",
       "12          -0.000276        -0.000185        0.000066                8  \n",
       "11          -0.000271        -0.000189        0.000065                9  \n",
       "10          -0.000274        -0.000191        0.000067               10  \n",
       "6           -0.000242        -0.000193        0.000066               11  \n",
       "9           -0.000276        -0.000197        0.000065               12  \n",
       "8           -0.000286        -0.000199        0.000071               13  \n",
       "7           -0.000265        -0.000199        0.000065               14  \n",
       "5           -0.000236        -0.000200        0.000066               15  \n",
       "4           -0.000237        -0.000216        0.000055               16  \n",
       "3           -0.000269        -0.000226        0.000068               17  \n",
       "2           -0.000290        -0.000226        0.000065               18  \n",
       "1           -0.000394        -0.000291        0.000067               19  \n",
       "0           -0.000550        -0.000390        0.000106               20  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'kneighborsregressor__n_neighbors': n_neighbors}\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = param,\n",
    "                  cv = sliding_cv,\n",
    "                  n_jobs = -1,\n",
    "                  scoring = 'neg_mean_squared_error')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74105f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6327f647",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed6fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa634b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fe0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e75c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7112a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24fce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb03ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a857a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e758857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95c565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb4dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852d608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818c3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7e373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738be14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e7281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943edece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57538f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5601c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ab2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0a0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32373ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092630b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79dfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e946d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51307499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42281ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736feaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a1dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510cbcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f932b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cec96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d467ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f2671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce82b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9736fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05987c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b81d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75164fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef7c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23b9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b77178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b769674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416d28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8c0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287705a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e514e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
